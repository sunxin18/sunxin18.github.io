<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[双向BFS]]></title>
    <url>%2F2021%2F09%2F09%2Ftwo-direction-bfs%2F</url>
    <content type="text"><![CDATA[190.字串变换 概述：如何用最少的次数根据现有规则，将字符串A变为字符串B 题目连接：https://www.acwing.com/problem/content/description/192/ 一个朴素的思想就是，把A字符串的所有能转变规则的地方都转变一次，就相当于从A字符串拓展出几条不同的通路来到达一个新的节点，然后依次类推，最后与B字符串连接，这样的问题其实还是一个最短路的问题，可以用DFS也可以BFS，以BFS为例，假设每次决策数量是 K，那么如果直接BFS，最坏情况下的搜索空间是O(K10)O(K^10)O(K10)，如果我们用双向BFS，复杂度可以降到O(2K5)O(2K^5)O(2K5) 思路：从初始字符串和结果字符串同时进行bfs，一层的一层的进行，通过判断bfs树的大小来决定下一次bfs拓展哪个方向，用一个map来记录各种枚举的字符串需要几次转换，然后直到两端相遇 题外话：扩展要一层一层的扩展，只扩展一层中的一部分可能结果不对 c++123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;unordered_map&gt;#include &lt;vector&gt;#include &lt;queue&gt;using namespace std;int n;vector&lt;string&gt; a;vector&lt;string&gt; b;string A, B;int extend(queue&lt;string&gt;&amp; q, unordered_map&lt;string, int&gt;&amp;da, unordered_map&lt;string, int&gt;&amp; db, vector&lt;string&gt; &amp;a, vector&lt;string&gt; &amp;b)&#123; int d = da[q.front()]; while (q.size() &amp;&amp; da[q.front()] == d) &#123; auto t = q.front(); q.pop(); for (int i = 0; i &lt; n; i ++ ) for (int j = 0; j &lt; t.size(); j ++ ) if (t.substr(j, a[i].size()) == a[i]) &#123; string r = t.substr(0, j) + b[i] + t.substr(j + a[i].size()); //string r = t.replace(j, a[i].size(), b[i]); if (db.count(r)) return da[t] + db[r] + 1; if (da.count(r)) continue; da[r] = da[t] + 1; q.push(r); &#125; &#125; return 11;&#125;int bfs() &#123; if (A == B) return 0; queue&lt;string&gt; qa, qb; unordered_map&lt;string, int&gt; da, db; qa.push(A); qb.push(B); da[A] = 0, db[B] = 0; while (!qa.empty() &amp;&amp; !qb.empty()) &#123; int t; if (qa.size() &lt; qb.size()) &#123; t = extend(qa, da, db, a, b); &#125; else &#123; t = extend(qb, db, da, b, a); &#125; if (t &lt;= 10) return t; &#125; return -1;&#125;int main() &#123; string s1, s2; cin &gt;&gt; A &gt;&gt; B; while (cin &gt;&gt; s1 &gt;&gt; s2) &#123; n++; a.push_back(s1); b.push_back(s2); &#125; int t = bfs(); if (t == -1) puts("NO ANSWER!"); else cout &lt;&lt; t &lt;&lt; endl; return 0; &#125;]]></content>
      <tags>
        <tag>双向BFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现一个简单的智能指针]]></title>
    <url>%2F2021%2F08%2F09%2Frealizze-shared-ptr%2F</url>
    <content type="text"><![CDATA[智能指针主要是做了两件事情： 申请内存，我们用模板指针 T* ptr 另一个进行计数并销毁清理对象 注意多个智能指针里的ptr可能会指向同一快内存，所以计数的变量也是要同步的，在这里我们用一个指针int* count来计数，每次新建一个共享指针就对count进行浅拷贝，这样多个指针指针就能同步进行更新计数了 当我们重载operator=的时候，要注意如果原来的共享指针已经有对象，需要将原来的引用计数减一并判断是否需要释放内存 c++12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include&lt;iostream&gt;#include &lt;memory&gt;using namespace std;template&lt;class T&gt;class S_ptr&#123;public: S_ptr(); S_ptr(T *p); ~S_ptr(); S_ptr(const S_ptr&lt;T&gt; &amp;org); S_ptr&lt;T&gt;&amp; operator = (const S_ptr&lt;T&gt; &amp;org); int get_count(); void get();private: int *use_count; T *ptr;&#125;;template&lt;class T&gt;S_ptr&lt;T&gt;::S_ptr() : ptr(), use_count(new int (1)) &#123; cout &lt;&lt; "Allocation11" &lt;&lt; endl;&#125;;template&lt;class T&gt;S_ptr&lt;T&gt;::S_ptr(T *p) : ptr(p) &#123; use_count = new int(1); cout &lt;&lt; "Allocation22" &lt;&lt; endl; if (use_count == nullptr) &#123; p = nullptr; cout &lt;&lt; "Allocation Error" &lt;&lt; endl; return; &#125;&#125;template&lt;class T&gt;S_ptr&lt;T&gt;::~S_ptr() &#123; if (--*use_count == 0) &#123; delete ptr; ptr = nullptr; delete use_count; use_count = nullptr; &#125;&#125;template&lt;class T&gt;S_ptr&lt;T&gt;::S_ptr(const S_ptr&lt;T&gt; &amp;org) &#123; ptr = org.ptr; use_count = org.use_count; (*use_count)++;&#125;template&lt;class T&gt;S_ptr&lt;T&gt;&amp; S_ptr&lt;T&gt;::operator = (const S_ptr &amp;org) &#123; if (this-&gt;ptr) &#123; if (--this-&gt;use_count == 0) &#123; delete this-&gt;ptr; delete this-&gt;count; &#125; this-&gt;ptr = org.ptr; this-&gt;use_count = org.use_count; (*use_count)++; &#125; return *this; &#125;template&lt;class T&gt;S_ptr&lt;T&gt;::get_count() &#123; return *use_count;&#125;int main() &#123; //S_ptr&lt;string&gt; p1 = new string("hello"); S_ptr&lt;string&gt; p1(new string("hello")); shared_ptr&lt;int&gt; p(new int(2)); cout &lt;&lt; p1.get_count() &lt;&lt; endl; S_ptr&lt;string&gt; p2(p1); cout &lt;&lt; p1.get_count() &lt;&lt; endl; &#123; S_ptr&lt;string&gt; p3(p1); cout &lt;&lt; p1.get_count() &lt;&lt; endl; &#125; cout &lt;&lt; p1.get_count() &lt;&lt; endl; return 0;&#125;]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>智能指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static变量的存储与初始化时间]]></title>
    <url>%2F2021%2F08%2F03%2Fstatic%2F</url>
    <content type="text"><![CDATA[数据段探究 数据段主要分为.bss(Block Started by Symbol)和.data(data segment)段，前者指用来存放程序中未初始化的全局变量的一块内存区域，后者是指用来存放程序中已初始化的全局变量的一块内存区域。 text和data段都在可执行文件中（在嵌入式系统里一般是固化在镜像文件中），由系统从可执行文件中加载 ，我们用段代码来确定 程序1： c++12345int ar[30000];int main()&#123; return 0;&#125; 程序二： c++12345int ar[30000];void main()&#123; return 0;&#125; 程序一的大小： 程序二的大小： 全局静态变量 我们先来看全局的静态变量，我们考虑初始化和未初始化两种情况，很明显他们存在.data段，并且是在程序加载进入main函数之前就初始化了，比如单例模式里的恶汉模式，所以就不必担心多线程问题 初始化： c++1234static int test = 1;int main() &#123; return 0;&#125; Code1234567sunxin@sunxin-KLVC-WXX9:~/static$ g++ test.cpp -gsunxin@sunxin-KLVC-WXX9:~/static$ gdb a.out (gdb) info addr testSymbol &quot;test&quot; is static storage at address 0x201010.(gdb) info symbol 0x201010test in section .data 可以看到初始化的静态变量存在.data段，所以是在程序加载进入main函数之前就初始化了，由此也可以联想到单例模式里的恶汉模式，所以就不必担心多线程问题 如果没有赋值的全局静态变量是初始化在.bss里的： c++1234static int test;int main() &#123; return 0;&#125; Code1234(gdb) info addr testSymbol &quot;test&quot; is static storage at address 0x201018.(gdb) info symbol 0x201018test in section .bss 接下来看一种在函数中初始化的全局静态变量,发现也是存在.bss区。 c++1234567int foo() &#123; return 1;&#125;static int test = foo();int main() &#123; return 0;&#125; Code1234(gdb) info addr testSymbol &quot;test&quot; is static storage at address 0x201138.(gdb) info symbol 0x201138test in section .bss 对于以上代码，通过调试，我发现进入main函数前，test的值已经初始化为0了，进入main函数后test为1，说明 .bbs存储的是全局未初始化的变量，系统初始化为0当做一个占位符，而.data存的是初始化为自定义的变量 局部静态变量 关于局部静态变量的初始化就有些疑惑了，在c里静态变量都是在编译期间初始化完成，但是c++里就不太清楚了，网上很多答复是对象首次用到的时候构造初始化，接下来的代码我们来探究一下： 首先写个简单的局部静态变量 c++12345678#include&lt;iostream&gt;using namespace std;int main() &#123; static int test = 1; //存在.data static int no_test; //存在.bss static int no_test_2 = 0；//存在.bss return 0;&#125; Code12345678(gdb) disas mainDump of assembler code for function main(): 0x000000000000073a &lt;+0&gt;: push %rbp 0x000000000000073b &lt;+1&gt;: mov %rsp,%rbp 0x000000000000073e &lt;+4&gt;: mov $0x0,%eax 0x0000000000000743 &lt;+9&gt;: pop %rbp 0x0000000000000744 &lt;+10&gt;: retq End of assembler dump. 通过汇编看不到main函数里对static变量初始化的语句，但进main函数前是查不到test的值的，说明局部静态变量是程序第一次碰到他的定义的时候，之后通过类似上面的办法，得出了静态变量的存储位置详见注释 类中静态变量 不多废话，直接通过代码分析： c++123456789101112131415161718192021222324252627class test&#123;public: test(const char *name) : _name(name) &#123; cout &lt;&lt; _name &lt;&lt; " created" &lt;&lt; endl; &#125; ~test()&#123; cout &lt;&lt; _name &lt;&lt; " destroyed" &lt;&lt; endl; &#125; string _name;&#125;;test t("global variable");void f()&#123; static test t("static variable"); test t2("Local variable"); cout &lt;&lt; "Function executed" &lt;&lt; endl;&#125;int main()&#123; test t("local to main"); cout &lt;&lt; "Program start" &lt;&lt; endl; f(); cout &lt;&lt; "Program end" &lt;&lt; endl; return 0;&#125; Code1234567891011global variable createdlocal to main createdProgram startstatic variable createdLocal variable createdFunction executedLocal variable destroyedProgram endlocal to main destroyedstatic variable destroyedglobal variable destroyed 参考文献：https://www.cnblogs.com/mylinux/p/5611225.html https://stackoverflow.com/questions/55510/when-do-function-level-static-variables-get-allocated-initialized]]></content>
      <tags>
        <tag>static</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时间统计特性开发]]></title>
    <url>%2F2021%2F06%2F07%2Frecord-time%2F</url>
    <content type="text"><![CDATA[设计思路 总体思路：首先设计一个类 SingleConvertTime， 利用这个类的构造和析构进行单次 convert 的时间的计算，将这个类的实例化加入到 convert 模板中，之后设计一个单例 SingleConvertTime 进行管理，统计各个消息实时转化的最值。 计算采用纳秒级别的精准度，最后文件输出统一以微妙精度。 由于消息存在嵌套，并且同一种消息类型可能会有不同的父消息类型，所以如果只按照 message type 为单位区分统计时间，会导致下层消息混乱统计（同名的消息都会被统一计算，他们可能来自于不同的父消息），结果容易造成误导，而最外层的消息类型统计是不存在这种情况，所以暂时提供最外层消息 convert 时间统计。 准备 单例模式：使用懒汉式单例(magic static )——局部静态变量 详细思路 c++123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960struct TimeTrace &#123; uint64_t max_time = 0; uint64_t min_time = LONG_MAX; uint64_t sum_time = 0; uint64_t convert_times = 0;&#125;; struct ConvertTimeSettings &#123; //可提供用户外部自定义 std::string path = "/home/ros/convert_time"; std::string file_name = "time_record"; int time_interval = 5000;&#125;; class ConvertTimeTrace &#123;public: ConvertTimeTrace(const std::string &amp;str) : message_type_(str) &#123; //记录当前消息初始时间 &#125; ~ConvertTimeTrace() &#123; ConvertTimeRecorder&amp; instance = ConvertTimeRecorder::get_instance(); //记录当前消息结束时间，计算时间差，调用单例update 接口更新 &#125; class ConvertTimeRecorder &#123;public: static ConvertTimeRecorder&amp; get_instance()&#123; static ConvertTimeRecorder instance; return instance; &#125; ConvertTimeRecorder(ConvertTimeRecorder&amp;) = delete; ConvertTimeRecorder&amp; operator = (const ConvertTimeRecorder&amp;) = delete; void update(const std::string &amp;message_type, const uint64_t &amp;time) &#123; //更新最大值，最小值，sum, convert次数 这里写容器上锁，同时这里触发时判断是否和上次写文件达到5000ms，达到就调用写文件 &#125; void print_time() &#123; //求平均值，进行输出文件，以 txt 格式输出，文件名加进行id进行区分不同模块 &#125; void update_layer(const std::thread::id &amp;thread_id, const int &amp;number) &#123; layer_count_[thread_id] += number;&#125; //这个和下面的函数用于实现只统计最外层消息 int get_layer_number(const std::thread::id &amp;thread_id ) &#123; return layer_count_[thread_id];&#125; void set_settings(ConvertTimeSettings settings) &#123; settings_ = settings; &#125; ConvertTimeSettings&amp; get_settings() &#123; return settings_; &#125; ~ConvertTimeRecorder() &#123; print_time() &#125;private: ConvertTimeRecorder() &#123;&#125; std::chrono::steady_clock::time_point print_start_time_; //用于记录打印的时间 std::mutex mutex_; std::map&lt;std::string, TimeTrace&gt; record_time_; ConvertTimeSettings settings_; std::map&lt;std::thread::id, int&gt; layer_count_;&#125;]]></content>
      <tags>
        <tag>单例模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shared_ptr用法与线程安全性]]></title>
    <url>%2F2021%2F05%2F14%2Fshared-ptr%2F</url>
    <content type="text"><![CDATA[概念 共享指针，即多个指针指向同一个内存；具体实现方式是采用的引用计数，即这块地址上每多一个指针指向他，计数加一； 引用计数可以跟踪对象所有权，并能够自动销毁对象。可以说引用计数是个简单的垃圾回收体系。 智能指针是模板类而不是指针。创建一个智能指针时，必须指针可以指向的类型,, ……等。 智能指针实质就是重载了-&gt;和\操作符的类，由类来实现对内存的管理，确保即使有异常产生，也可以通过智能指针类的析构函数完成内存的释放。 可以认为每个shared_ptr都有一个关联的计数器，通常称其为引用计数(reference count)。无论何时拷贝一个shared_ptr，计数器都会递增。例如，当用一个shared_ptr初始化另一个shared_ptr，或将它作为参数传递给一个函数以及作为函数的返回值时，它所关联的计数器就会递增。当给shared_ptr赋予一个新值或是shared_ptr被销毁(例如一个局部的shared_ptr离开其作用域)时，计数器就会递减。一旦一个shared_ptr的计数器变为0，它就会自动释放自己所管理的对象。 当指向一个对象的最后一个shared_ptr被销毁时，shared_ptr类会自动销毁此对象。它是通过另一个特殊的成员函数析构函数(destructor)来完成销毁工作的。类似于构造函数，每个类都有一个析构函数。就像构造函数控制初始化一样，析构函数控制此类型的对象销毁时做什么操作。shared_ptr的析构函数会递减它所指向的对象的引用计数。如果引用计数变为0，shared_ptr的析构函数就会销毁对象，并释放它占用的内存。 完整的例子 c++12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;struct BigObj &#123; BigObj() &#123; std::cout &lt;&lt; "big object has been constructed" &lt;&lt; std::endl; &#125; ~BigObj() &#123; std::cout &lt;&lt; "big object has been destructed" &lt;&lt; std::endl; &#125;&#125;;void test_ref1() &#123; std::shared_ptr&lt;BigObj&gt; sp1 = std::make_shared&lt;BigObj&gt;(); std::cout &lt;&lt; sp1.use_count() &lt;&lt; std::endl; &#123; std::shared_ptr&lt;BigObj&gt; sp2 = sp1; std::cout &lt;&lt; sp1.use_count() &lt;&lt; std::endl; &#125; std::cout &lt;&lt; sp1.use_count() &lt;&lt; std::endl; BigObj* ptr = sp1.get(); sp1 = nullptr; std::cout &lt;&lt; sp1.use_count() &lt;&lt; std::endl;&#125;int main()&#123; //构建 2 个智能指针 std::shared_ptr&lt;int&gt; p1(new int(10)); //shared_ptr&lt;T&gt; 类模板中，提供了多种实用的构造函数 std::shared_ptr&lt;int&gt; p3 = std::make_shared&lt;int&gt;(10); // std::shared_ptr&lt;int&gt; p2(p1); //输出 p2 指向的数据 使用方法例子：可以当作一个指针使用 cout &lt;&lt; "p2:" &lt;&lt; *p2 &lt;&lt; endl; int *p = p3.get(); //shared_ptr 关联的原始指针 cout &lt;&lt; "p3:" &lt;&lt; *p &lt;&lt; endl; p1.reset();//引用计数减 1,p1为空指针 if (p1) &#123; cout &lt;&lt; "p1 不为空" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; "p1 为空" &lt;&lt; endl; &#125; //以上操作，并不会影响 p2 cout &lt;&lt; *p2 &lt;&lt; endl; //判断当前和 p2 同指向的智能指针有多少个 cout &lt;&lt; p2.use_count() &lt;&lt; endl; // test_ref1(); //我们可以清晰地看到引用计数增加和减少的情况，当减少为 0 的时候就会释放指针对象。把 shared_ptr 设置为 nullptr 就可以让 shared_ptr 去释放所管理的裸指针。 通过 shared_ptr 的 get 方法可以获取它所管理的裸指针。 return 0;&#125; 析构 析构函数中删除内部原始指针，默认调用的是delete()函数。 Code1delete point; 像这样申请的数组，应该调用delete []释放内存，而shared_ptr析构函数中默认delete并不能满足需求。 给shared_ptr添加自定义删除器: c++1234567891011121314151617181920212223#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;struct BigObj &#123; BigObj() &#123; std::cout &lt;&lt; "big object has been constructed" &lt;&lt; std::endl; &#125; ~BigObj() &#123; std::cout &lt;&lt; "big object has been destructed" &lt;&lt; std::endl; &#125;&#125;;void deleter(BigObj *p) &#123; std::cout &lt;&lt; "Custom Deleter\n"; delete[] p;&#125;int main() &#123; std::shared_ptr&lt;BigObj&gt; p(new BigObj[2], deleter); std::shared_ptr&lt;BigObj&gt; p2(new BigObj[4], [](BigObj *p) &#123; std::cout &lt;&lt; "Custom Deleter\n"; delete[] p;&#125;); return 0;&#125; 误区： 不从 new 的返回值直接构造共享指针 c++123T *a = new T();shared_ptr&lt;T&gt; ptr1(a);shared_ptr&lt;T&gt; ptr2(a); 这样的话，ptr1 和 ptr2 的引用计数是单独算的，它们任意一个对象在析构的时候，都会销毁 a 所指的对象，a就为悬空指针，所以，这个对象会被“销毁两次”。因此报错。（make_shared类模板可以避免） http://c.biancheng.net/view/7898.html https://www.cnblogs.com/bandaoyu/p/14625038.html 线程安全探究 共享指针的线程安全问题 All member functions (including copy constructor and copy assignment) can be called by multiple threads on different instances of shared_ptr without additional synchronization even if these instances are copies and share ownership of the same object. If multiple threads of execution access the same shared_ptr without synchronization and any of those accesses uses a non-const member function of shared_ptr then a data race will occur; the shared_ptr overloads of atomic functions can be used to prevent the data race. &quot;Multiple threads can simultaneously read and write different shared_ptr objects, even when the objects are copies that share ownership 解释一下以上的说话，比如我们建立一个共享指针管理的对象： c++1shared_ptr&lt;int&gt; ptr1 = make_shared&lt;int&gt;(); 此时有两个逻辑块，不应该对待同样的处理。 一个是存储实际值的int，另一个是控制块，它存储使其工作的所有Shared_ptr &lt;&gt;工作原理。 只有控制块本身是线程安全的，也就是共享指针实体可以在不同的线程建立和销毁，共享指针的计数原则都是原子操作，但是如果对指向对象有写操作，那么就需要加锁了，看如下代码 c++12345678910111213141516171819202122232425262728293031323334shared_ptr&lt;int&gt; global_instance = make_shared&lt;int&gt;(0);void thread_fcn();int main(int argc, char** argv)&#123; thread thread1(thread_fcn); thread thread2(thread_fcn); ... thread thread10(thread_fcn); chrono::milliseconds duration(10000); this_thread::sleep_for(duration); return;&#125;void thread_fcn()&#123; // This is thread-safe and will work fine, though it's useless. Many // short-lived pointers will be created and destroyed. for(int i = 0; i &lt; 10000; i++) &#123; shared_ptr&lt;int&gt; temp = global_instance; &#125; // This is not thread-safe. While all the threads are the same, the // "final" value of this is almost certainly NOT going to be // number_of_threads*10000 = 100,000. It'll be something else. for(int i = 0; i &lt; 10000; i++) &#123; *global_instance = *global_instance + 1; &#125;&#125; 综上，共享指针的机制并不能保证多线程可以准确地访问资源，我们还是需要用同步机制比如st::mutex来使其线程安全。使用时我们要明确多个副本访问同一块内存有没有同步的问题 参考文献： https://ofstack.com/C++/8983/full-analysis-of-shared_ptr-thread-safety.html https://stackoverflow.com/questions/14482830/stdshared-ptr-thread-safety https://en.cppreference.com/w/cpp/memory/shared_ptr]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>共享指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优雅的写一个文件读取]]></title>
    <url>%2F2021%2F05%2F14%2Fread-file%2F</url>
    <content type="text"><![CDATA[用到的函数 fseek 函数原型： c++1int fseek(FILE * stream, long offset, int whence); SEEK_SET：文件开头 SEEK_CUR:文件当前位置 SEEK_END：文件末尾 该函数用于实现以任意顺序访问文件的不同位置 ftell：函数原型: c++1long ftell(FILE *fp); 该函数用于得到文件位置指针当前位置相对于文件首的偏移字节数。 data():返回内置vecotr所指的数组内存的第一个元素的指针 c++1size_t fread(void *ptr, size_t size, size_t nmemb, FILE *stream) C 库函数 从给定流 stream 读取数据到 ptr 所指向的数组中。 ptr – 这是指向带有最小尺寸 size*nmemb 字节的内存块的指针。 size – 这是要读取的每个元素的大小，以字节为单位。 nmemb – 这是元素的个数，每个元素的大小为 size 字节。 stream – 这是指向 FILE 对象的指针，该 FILE 对象指定了一个输入流。 代码 c++123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;vector&gt;#include &lt;memory&gt;std::string read_file(const std::string &amp;path) &#123; FILE *file = fopen(path.c_str(), "r"); if (file == nullptr) &#123; printf("Fail to open file '%s'", path.c_str()); return ""; &#125; std::shared_ptr&lt;FILE&gt; fp(file, [](FILE *file) &#123; fclose(file); &#125;); fseek(fp.get(), 0, SEEK_END); std::vector&lt;char&gt; content(ftell(fp.get())); fseek(fp.get(), 0, SEEK_SET); int n = fread(content.data(), 1, content.size(), fp.get()); return n &gt; 0 ? std::string(content.begin(), content.end()) : std::string();&#125;int main(int argc, char *argv[]) &#123; if (argc &lt; 2) &#123; std::cout &lt;&lt; "[usage]:" &lt;&lt; argv[0] &lt;&lt; " output_path" &lt;&lt; std::endl; return 0; &#125; auto file_path = std::string(argv[1]) + "/test.txt"; std::string result = read_file(file_path); std::cout &lt;&lt; result &lt;&lt;std::endl; return 0;&#125; 参考内容：https://www.runoob.com/cprogramming/c-function-fread.html]]></content>
      <tags>
        <tag>文件读取</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[418]]></title>
    <url>%2F2021%2F04%2F18%2F418%2F</url>
    <content type="text"><![CDATA[题目地址：https://leetcode-cn.com/problems/contains-duplicate-iii/ 由于要判断的两个数的下标的距离小于k，很容易想到使用滑动窗口，对每个窗口内的数进行判断，然后移动窗口，复杂度就是O(kn)O(kn)O(kn)，这会超出时间限制 因此降低复杂度就要从滑动窗口入手，使用一种数据结构可以满足一下几点 能够用更短的时间判断 还可以动态维护，即进行插入删除 想到使用 set 来维护，set可以自动对滑动窗口内的数进行排序，总体复杂度O(logkn)O(log_{k}n)O(logk​n) 设窗口又端点的数为x，使用lower_bound 函数找到窗口内最小的一个大于等于x-t的数，如果这个数也小于等于x+t，那么就找到了这一对数。 c++123456789101112131415class Solution &#123;public: bool containsNearbyAlmostDuplicate(vector&lt;int&gt;&amp; nums, int k, int t) &#123; set&lt;long&gt; st; for (int i = 0; i &lt; nums.size(); i++) &#123; auto iter = st.lower_bound((long)nums[i] - t); if (iter != st.end() &amp;&amp; *iter &lt;= (long)nums[i] + t) return true; st.insert(nums[i]); if (st.size() &gt; k) st.erase(nums[i - k]); &#125; return false; &#125;&#125;; 使用set仍然无法达到线性时间，我们可以使用桶排序在O(1)的时候进行类似窗口内判断的操作。 我们将桶的大小设为t+1(因为判断的两个数的差小于等于t，那么桶里放t+1个数就一个都不会漏了)。如果两个元素同属一个桶，那么这两个元素必然符合条件。如果两个元素属于相邻桶，那么我们需要校验这两个元素是否差值不超过 t。如果两个元素既不属于同一个桶，也不属于相邻桶，那么这两个元素必然不符合条件。 难点在于怎么给桶编号，如果是非负数，那么id就是x/t+1, 可以看下这个题解：https://leetcode-cn.com/problems/contains-duplicate-iii/solution/c-li-yong-tong-fen-zu-xiang-xi-jie-shi-b-ofj6/ c++12345678910111213141516171819202122class Solution &#123;public: int getID (long x, long t) &#123; return x &gt;= 0 ? x / (t + 1) : (x + 1) / (t + 1) - 1; &#125; bool containsNearbyAlmostDuplicate(vector&lt;int&gt;&amp; nums, int k, int t) &#123; unordered_map &lt;long, long&gt; map;//由于桶如果有两个相同的就满足返回true了，所以每个桶里最多放一个元素，使用map就合适 for (int i = 0; i &lt; nums.size(); i++) &#123; int id = getID(nums[i], t); if (map.find(id) != map.end()) return true; int l = id - 1; int r = id + 1; if (map.find(l) != map.end() &amp;&amp; nums[i] - map[l] &lt;= t) return true; if (map.find(r) != map.end() &amp;&amp; map[r] - nums[i] &lt;= t) return true; map[id] = nums[i]; if(i - k &gt;= 0) &#123; map.erase(getID(nums[i - k], t)); &#125; &#125; return false; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>桶排序</tag>
        <tag>滑动窗口</tag>
        <tag>复杂度优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cmake报错以及解决办法集]]></title>
    <url>%2F2021%2F02%2F27%2Fcmake%2F</url>
    <content type="text"><![CDATA[1 报错内容： 报错的代码 Code123483:install(84: TARGETS $&#123;TARGET&#125;85: ARCHIVE DESTINATION $&#123;CMAKE_INSTALL_LIBDIR&#125;86: LIBRARY DESTINATION $&#123;CMAKE_INSTALL_LIBDIR&#125; 可以看到报错的区域出现在make install 部分，报错信息提示是没有给出install的位置，接下来发现${CMAKE_INSTALL_LIBDIR}是空的。 解决方法:CMakeLists中加入include(GNUInstallDirs) 2 cannot find -lxxxx 这种情况最可能的原因是链接库连接错了，没有xxx.so 3. install后，cannot open xxx.so:No file or directory 首先检查是不是xxx.so没有生成，进入到lib目录 发现果然没有生成，这一部分属于算法部分的，所以检查cmakelist相应的部分，果然代码生成的不全 python1234567#原始： install(FILES $&#123;binary_dir&#125;/install/lib/libperception_fusion.so DESTINATION lib#改完： install(DIRECTORY $&#123;binary_dir&#125;/install/lib/ DESTINATION lib FILES_MATCHING PATTERN "*.so" 结果发现又出现同样的报错了，其他的动态库又找不到了，首先看下要生成的动态库 发现还有后缀是.so.xx 所以再改写一下cmake python123install(DIRECTORY $&#123;binary_dir&#125;/install/lib/ DESTINATION lib FILES_MATCHING PATTERN "*.so" Over!]]></content>
      <tags>
        <tag>CMake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杀掉指定进程名的进程]]></title>
    <url>%2F2021%2F01%2F30%2Fkill%2F</url>
    <content type="text"><![CDATA[场景是要杀掉服务器上的一个进程并且不知道进程号，所以我们现在本地查一下进程名，在服务器和本地进程名都是一样的 首先在本地查一下进程号： 查进程名： 命令： Code1ps -aux |grep -v grep|grep ID 看到进程名字是&quot;lidarperception_ros2mfr_adaptor&quot; 杀掉进程 Code1pkill -f &quot;lidarperception_ros2mfr_adaptor&quot;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下不同使用者使用不同版本gcc的方法]]></title>
    <url>%2F2021%2F01%2F11%2Fg%2F</url>
    <content type="text"><![CDATA[最近论文实验比对其他paper的代码时发现了报错，很明显问题出现在gcc版本的不一致。服务器的gcc版本是9.3，而paper三年前的版本肯定不是了，所以下载了4.8版本，然后下面是切换版本的方法： sudo apt-get install gcc-6 Code123456cd ~mkdir bincd binln -s /usr/bin/gcc-4.8 gccln -s /usr/bin/g++-4.8 g++PATH=~/bin:$PATH]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[protobuf]]></title>
    <url>%2F2020%2F12%2F30%2Fprotobuf%2F</url>
    <content type="text"><![CDATA[将lidar模块的protobuf升级到3.12后，遇到了这么个报错 结果花了三天的时间在这上面，最开始排查的方向错了导致无意义的时间花销，所以遇到问题首先要却定好大方向，在去深入。 先看一下出错区域的代码，这里是publish一个string消息 c++12345678910mmessage::std_mfrmsgs::MFRMessageString msg;msg.set_data(to_protobuf_string(prediction).c_str());mfr_publisher_map_[global_lidar_visualization_topic]-&gt;publish(msg);std::string to_protobuf_string(const LidarPrediction::Ptr &amp;prediction) &#123; proto::LidarPrediction data; ........ return data.SerializeAsString();&#125; 首先我理所当然的以为是升级接口的改变，也就是to_protobuf_string()这里的的改变，就去看了一下生成的消息接口，结果还真有一些我以为是新升级的接口，实际上不是，现在想想3.9-&gt;3.12的一个小升级不会有这种改变。。。然后重新用新的接口写了一下，实际对于proto消息内的repeated字段，有两种增加新内容的方法， c++12auto p = x-&gt;Add();auto p = x.add_xx(); 我只在接口的代码里看到了第二个就以为是更新了. 然后又跳入了第二个坑，以为是调用c_str后，传入const * char因为没有传入长度而出现截断，序列化后有许多的0感觉会这样，结果实际上并不会这个并没有理论依据，不能总是用以为做事， 最终的问题是在与当publish的时候又会进行一个序列化，两次都是才用的protobuf，连续两次序列化出的问题， protobuf会对string进行utf-8检查，然而如果根据报错提示换用bytes的话，这就要对publish底层的protbuf源码来操作，不现实，所以讲方向放到第一次序列化，我们换个结构不用string来存不就好了吗？用uint8[] 重新定义一个消息，结构就是uint8数组。 c++12345678910111213141516171819mmessage::std_mfrmsgs::MFRMessageUInt8MultiArray msg; size_t length = 0; uint8_t *buf = to_protobuf_array(prediction, length); for(int i = 0; i &lt; length; i++) &#123; msg.add_data(buf[i]); &#125; mfr_publisher_map_[global_lidar_visualization_topic]-&gt;publish(msg);uint8_t * to_protobuf_array(const LidarPrediction::Ptr &amp;prediction, size_t &amp;len) &#123; proto::LidarPrediction data; ....... uint32_t length = data.ByteSizeLong(); uint8_t * buf = new uint8_t[length]; data.SerializeToArray(buf,length); len = length; return buf;&#125; 但是如果对数组序列化的话，调用的是SerializeToArray(), 这里还需要传入大小，由于对于uint_8* 是无法获取数组的大小的(sizeof得到的指针的size), 所以我们需要吧这个信息写进消息里，随便测试了一下某个bag序列化后的size是4000000，感觉32位就够用了，所以我们把数组前四个一共32位拿来存序列化后的大小信息。 将表示size的32位数转化到unit8数组 c++123456void inttolitend(uint32_t x, uint8_t * &amp;lit_int) &#123; lit_int[0] = (uint8_t)(x &gt;&gt; 0); lit_int[1] = (uint8_t)(x &gt;&gt; 8); lit_int[2] = (uint8_t)(x &gt;&gt; 16); lit_int[3] = (uint8_t)(x &gt;&gt; 24);&#125; 转化回来 c++1uint32_t length = buf[0] | (buf[1] &lt;&lt; 8) | (buf[2] &lt;&lt; 16) | (buf[3] &lt;&lt; 24);]]></content>
      <tags>
        <tag>protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb来检查播bag测试的崩溃]]></title>
    <url>%2F2020%2F12%2F20%2Fgdb%2F</url>
    <content type="text"><![CDATA[本地播bag测试时，出现了崩溃，如下 首先我们先找到coredump文件，在Downloads/coredump目录下，然后我们根据时间找到对应的文件core.xxxx记住这个名字,发现是我负责的lidar模块的错误 进入到catkin_ws/devel/lib/lidar_perception目录,此目录下有个lidar_perception_mfr_node,此时我们通过gdb来看一下报错原因 Code1gdb lidar_perception_mfr_node ~/Downloads/coredump/core.xxx 然后输入bt看一下堆栈信息 可以发现问题是说有个地方的protobuf的版本不匹配。]]></content>
      <tags>
        <tag>调试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git操作指令]]></title>
    <url>%2F2020%2F12%2F05%2Fgit%2F</url>
    <content type="text"><![CDATA[git是什么？ Git 更像是把数据看作是对小型文件系统的一系列快照。 在 Git 中，每当你提交更新或保存项目状态时，它基本上就会对当时的全部文件创建一个快照并保存这个快照的索引。 为了效率，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。 Git 对待数据更像是一个 快照流。 获取 Git 仓库 Git 克隆的是该 Git 仓库服务器上的几乎所有数据，而不是仅仅复制完成你的工作所需要文件。 当你执行 git clone 命令的时候，默认配置下远程 Git 仓库中的每一个文件的每一个版本都将被拉取下来。事实上，如果你的服务器的磁盘坏掉了，你通常可以使用任何一个克隆下来的用户端来重建服务器上的仓库 （虽然可能会丢失某些服务器端的钩子（hook）设置，但是所有版本的数据仍在， 记录每次更新到仓库 你工作目录下的每一个文件都不外乎这两种状态：××已跟踪：×× 或 ××未跟踪×× 已跟踪：是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后， 它们的状态可能是未修改，已修改或已放入暂存区。简而言之，已跟踪的文件就是 Git 已经知道的文件。 为跟踪 为跟踪:工作目录中除已跟踪文件外的其它所有文件都属于未跟踪文件，它们既不存在于上次快照的记录中，也没有被放入暂存区。 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态，因为 Git 刚刚检出了它们， 而你尚未编辑过它们。 git操作 下拉仓库 Code1git clone xxx --recursive submodule更新： Code1git submodule update --init -- 创建分支 ###查看分支信息 Code1git branch -a 切换到 dev 分支 Code1git checkout dev 更新 dev 分支到最新 Code12git fetchgit rebase 创建自己的分支，分支名的命名规范是：[NAME]/[BRANCH_SUMMARY] Code1git checkout -b zhangsan/add_new_feature 将自己的分支推到远端 Code1git push origin zhangsan/add_new_feature 设置自己本地分支追踪的远程分支 Code1git branch -u origin/zhangsan/add_new_feature 提交的流程 首先先看当前的状态，通常是status命令，diff可以看具体修改了什么地方 Code1git status/git status -s/git diff 之后跟踪新文件或修改， 通常使用git add .来跟踪当前目录下的所有修改 Code1git add xxx/git add . 提交更新 Code12git commit -m &quot;xxx&quot;比如：git commit -m &quot;add_new_file&quot; 提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么，以及在本次提交中，有多少文件修订过，多少行添加和删改过。 推送到远端 git push origin “branch name” 远程库覆盖本地代码 git fetch --all git reset --hard origin/develop git pull 撤销本地操作 git checkout . 删除远程分支 git push origin --delete branch]]></content>
  </entry>
  <entry>
    <title><![CDATA[ros通信实现]]></title>
    <url>%2F2020%2F11%2F18%2Fros%2F</url>
    <content type="text"><![CDATA[ROS是基于topic发布和订阅来实现通信，底层是TCP来发送消息，具体原理本文不在详细介绍。本文将手动实现两个ros节点的通信。 首先进入ROS，并进入/catkin_ws/src目录 创建新的package Code1catkin_create_pkg basic_topic roscpp std_msgs #向功能包添加自定义消息文件(.msg) Code123roscd custom_msg_topicmkdir msg &amp;&amp; cd msggedit custom_msg.msg 在custom_msg.msg文件中输入如下的内容： Code1234string first_namestring last_nameuint8 agestring character 修改CMakeLists.txt文件的内容为： Code12345678910111213141516171819202122cmake_minimum_required(VERSION 2.8.3)project(custom_msg_topic)find_package(catkin REQUIRED COMPONENTS roscpp std_msgs message_generation)add_message_files( FILES custom_msg.msg)generate_messages( DEPENDENCIES std_msgs)catkin_package( LIBRARIES custom_msg_topic CATKIN_DEPENDS roscpp message_runtime)include_directories( $&#123;catkin_INCLUDE_DIRS&#125;) 回到功能包所在的工作空间，构建功能包: Code12cd ~/catkin_wscatkin_make 编译之后会在include文件夹下生成对应的custom_msg.h文件 可以来检测一下 Code12345ros@sunxin-ThinkPad-T480s.master&gt; rosmsg show custom_msg_topic/custom_msgstring first_namestring last_nameuint8 agestring character 生成了自定义的消息头文件之后，我们就可以利用自定义的消息格式来编写节点了. 建立publisher节点 一般包含如下要素: ROS节点初始化 创建节点句柄 穿件publisher 设置循环频率 Code12roscd custom_msg_topic/srcgedit custom_msg_publisher.cpp 并编辑cpp文件加入以下代码（代码具体讲解参考文下参考文献） c++123456789101112131415161718192021222324#include "ros/ros.h"#include "custom_msg_topic/custom_msg.h"#include &lt;sstream&gt;int main(int argc, char **argv)&#123; ros::init(argc, argv, "custom_msg_publisher"); ros::NodeHandle nh; ros::Publisher custom_msg_pub = nh.advertise&lt;custom_msg_topic::custom_msg&gt;("test", 100); ros::Rate loop_rate(10); while (ros::ok()) &#123; custom_msg_topic::custom_msg msg; std::stringstream ss; ss&lt;&lt;"Xiao Xin"; ss&gt;&gt;msg.last_name; ss&gt;&gt;msg.first_name; msg.age = 18; msg.character = "lovely"; custom_msg_pub.publish(msg); loop_rate.sleep(); &#125; return 0;&#125; #建立subsriber节点 一般包含如下要素: 回调函数 ROS节点初始化 创建节点句柄 穿件publisher 循环等待回调函数 Code12roscd custom_msg_topic/srcgedit custom_msg_subscriber.cpp c++123456789101112131415161718#include "ros/ros.h"#include "custom_msg_topic/custom_msg.h"void test_infoCallback(const custom_msg_topic::custom_msgConstPtr &amp;msg)&#123; ROS_INFO("I heard: [%s %s]", msg-&gt;last_name.c_str(), msg-&gt;first_name.c_str()); ROS_INFO("his age is: [%d]; and he is [%s]", msg-&gt;age, msg-&gt;character.c_str());&#125;int main(int argc, char **argv)&#123; ros::init(argc, argv, "custom_msg_subscriber"); ros::NodeHandle nh; ros::Subscriber sub = nh.subscribe("test", 1000, test_infoCallback); ros::spin(); return 0;&#125; 修改功能包的CMakeLists.txt文件 打开终端 Code12roscd custom_msg_topicgedit CMakeLists.txt Code123456789101112131415161718192021222324252627282930cmake_minimum_required(VERSION 2.8.3)project(custom_msg_topic)find_package(catkin REQUIRED COMPONENTS roscpp std_msgs message_generation)add_message_files( FILES custom_msg.msg)generate_messages( DEPENDENCIES std_msgs)catkin_package( LIBRARIES custom_msg_topic CATKIN_DEPENDS roscpp message_runtime)include_directories( $&#123;catkin_INCLUDE_DIRS&#125;)# 下面是需要添加的内容add_executable(custom_msg_publisher src/custom_msg_publisher.cpp)add_executable(custom_msg_subscriber src/custom_msg_subscriber.cpp)add_dependencies(custom_msg_publisher $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)add_dependencies(custom_msg_subscriber $&#123;$&#123;PROJECT_NAME&#125;_EXPORTED_TARGETS&#125; $&#123;catkin_EXPORTED_TARGETS&#125;)target_link_libraries(custom_msg_publisher $&#123;catkin_LIBRARIES&#125;)target_link_libraries(custom_msg_subscriber $&#123;catkin_LIBRARIES&#125;) 运行 然后再次编译一下 Code12cd ~/catkin_wscatkin_make 开始运行～ Code12roscorerosrun custom_msg_topic custom_msg_publisher 接着可以查看一些详情 Code12rosnode info rosrun custom_msg_topic custom_msg_subscriberrostopic hz test 参考文献： http://wiki.ros.org/ROS/Tutorials/WritingPublisherSubscriber(c++)]]></content>
      <categories>
        <category>ROS</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[排序专题]]></title>
    <url>%2F2020%2F11%2F05%2Fquick-sort%2F</url>
    <content type="text"><![CDATA[本专题我们将回顾经典的排序算法，这节先看 冒泡排序 每一次遍历会将一个元素“浮”到数列的末尾 快速排序 排序的基本思想是： 1．先从数列中取出一个数作为基准数。 2．分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。 3．再对左右区间重复第二步，直到各区间只有一个数。 代码模板 c++1234567891011121314void quick_sort(int q[], int l, int r)&#123; if (l &gt;= r) return int i = l - 1; int r = r + 1; int x = q[l + r &gt;&gt;1]; while (i &lt; j)&#123; do i++; while(q[i] &lt; x); do j--; while(q[j] &gt; x); if(i &lt; j) swap(q[i], q[j]); &#125; quick_sort(q, l, j); quick_sort(q, j + 1, r);&#125; while循环结束后，q[l…j] &lt;= x,q[j+1…r] &gt;= x 注:q[l…j] &lt;= x意为q[l],q[l+1]…q[j-1],q[j]的所有元素都&lt;= x 最小k个数 注意x不一定在位置j上 比如q=[4,7,2]，第一轮x为7，第一轮完事是[4,2,7]，j是1，x在位置2上 还有一个点，一定要多多留意两个指针l，r重合的情况，在有些题会对这个做文章，比如返回最小的k个数 leetcode面试题 17.14. 最小K个数 c++1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: vector&lt;int&gt; res; void quick_sort(vector&lt;int&gt;&amp; arr, int l, int r, int k) &#123; if (l &gt;= r) return; int i = l - 1, j = r + 1; int x = arr[l + r &gt;&gt; 1]; while (i &lt; j) &#123; do i++; while (arr[i] &lt; x); do j--; while (arr[j] &gt; x); if (i &lt; j) swap(arr[i], arr[j]); &#125; int n = j - l + 1; if (n &gt; k) quick_sort(arr, l, j, k); else if (n == k) &#123; for (int m = 0; m &lt; k; m++) &#123; res.push_back(arr[l + m]); &#125; &#125; else &#123; for (int m = 0; m &lt; n; m++) &#123; res.push_back(arr[l + m]); &#125; if (j + 1 == r) //注意这个情况 res.push_back(arr[r]); else quick_sort(arr, j + 1, r, k - n); &#125; &#125; vector&lt;int&gt; smallestK(vector&lt;int&gt;&amp; arr, int k) &#123; quick_sort(arr, 0, arr.size() - 1, k); return res; &#125;&#125;; 最开始我的写法发现有些情况最终的结果数组res元素小于k，也就是有些情况没有考虑到，其实就是当n &lt; k的时候，也就是后半段还要进行递归去找剩下n-k个，当就剩下一个的时候，也就是j + 1 == r，进入下层递归在开头(l &gt;= r)就退出了，所以这种情况要单独考虑的。 这道题还有很多解法，下面给出冒泡和堆得写法，冒泡会在最后一个用例超时 冒泡： c++12345678910111213141516class Solution &#123;public: vector&lt;int&gt; smallestK(vector&lt;int&gt;&amp; arr, int k) &#123; for(int i = 0; i &lt; k; i++)&#123; for(int i = arr.size() - 1; i &gt; 0; i--)&#123; if(arr[i] &lt; arr[i - 1]) swap(arr[i], arr[i - 1]); &#125; &#125; vector&lt;int&gt; res; for(int i = 0; i &lt; k; i++)&#123; res.push_back(arr[i]); &#125; return res; &#125;&#125;; 堆： 不正经版本： c++12345678class Solution &#123;public: vector&lt;int&gt; smallestK(vector&lt;int&gt;&amp; arr, int k) &#123; sort(arr.begin(),arr.end()); arr.resize(k); return arr; &#125;&#125;; 归并排序 对[l, r]这个区间的数，我们递归的先去排序[l, mid],[mid + 1, r]两个区间，然后对这两个排序好的区间进行合并： c++123456789101112131415161718192021void merge_sort(vector&lt;int&gt; &amp;vec, int l, int r) &#123; if (l &gt;= r) return; int mid = l + r &gt;&gt; 1; merge_sort(vec, l, mid - 1); merge_sort(vec, mid + 1, r); int i = l, j = mid + 1; vector&lt;int&gt; temp(r - l + 1); int k = 0; while(i &lt;= mid &amp;&amp; j &lt;= r) &#123; if (vec[i] &lt; vec[j]) &#123; temp[k++] = vec[i++]; &#125; else &#123; temp[k++] = vec[j++]; &#125; &#125; while (i &lt;= mid) temp[k++] = vec[i++]; while (j &lt;= r) temp[k++] = vec[j++]; for (int i = l, j = 0; i &lt;= r; i++, j++) &#123; vec[i] = temp[j]; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cbug]]></title>
    <url>%2F2020%2F10%2F30%2Fcbug%2F</url>
    <content type="text"><![CDATA[越界问题 对于二叉树要多多注意p-&gt;left, p-&gt;right 是否存在 数组当取下标的时候一定要提前判断好是否会越界，特别主要二维数组判断空时, 对纵向可能会用到q[0].size(), 这个要先判断q.size()]]></content>
  </entry>
  <entry>
    <title><![CDATA[字符串+栈]]></title>
    <url>%2F2020%2F10%2F19%2Fstring-stack%2F</url>
    <content type="text"><![CDATA[字符串解码 相信会有人疑惑为什么官方视频例子里，s = “3[a2[c]]” 存的是[[2, a]而不是[2,c]呢？请看下面解答： 看完此题很容易就联想到栈，因为涉及到优先级最能层的括号先计算，其实这道题类似于分配率。 第一步是如何设计栈，有一个是数字代表重复次数，一个字符串代表要重复的字符串，很容易联想到用两个栈来存，分别存数字和字符串，存储进入’[‘前的状态（这里存的数字代表[]运算完后内部的字符串需要重复的次数，字符代表进入’[‘前需要存的字符。 接下来是怎么存？首先先用一个int num存储当前遍历的数，string res存储当前遍历到的字符串，当遇到’[‘的时候代表我们要先计算’[‘后的内容，当前计算得部分需要先存起来，当遇到’]‘时，将当前的res重复num次与栈最上层的字符串拼接，也就是进入当前’[‘时的状态,直到遍历结束，每遇到一次’[‘一次入栈，一次’]'一次出栈正好对应。 c++1234567891011121314151617181920212223242526272829303132class Solution &#123;public: string decodeString(string s) &#123; stack&lt;int&gt; nums; stack&lt;string&gt; strs; int num = 0; string res; for(int i = 0; i &lt; s.size(); i++)&#123; if(s[i] &gt;= '0' &amp;&amp; s[i] &lt;= '9') num = num * 10 + s[i] - '0'; else if((s[i] &gt;= 'a' &amp;&amp; s[i] &lt;= 'z') ||(s[i] &gt;= 'A' &amp;&amp; s[i] &lt;= 'Z')) res = res + s[i]; else if(s[i] == '[')&#123; nums.push(num); strs.push(res); res = ""; num = 0; &#125; else&#123; int cur = nums.top(); nums.pop(); string cur_str ; for(int i = 0; i &lt; cur; i++)&#123; cur_str += res; &#125; res = strs.top() + cur_str; strs.pop(); &#125; &#125; return res; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>字符串</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective STL 笔记]]></title>
    <url>%2F2020%2F10%2F03%2Feffective-stl%2F</url>
    <content type="text"><![CDATA[慎重选择容器类型 确保容器中的对象拷贝正确而高效 当(通过如insert或push_back之类的操作)向容器中加入对象时，存入容器的是你所指定的对象的拷贝。当(通过如front或back之类的操作)从容器中取出一个对象时，你所得到的是容器中所保存的对象的拷贝。进去的是拷贝，出来的也是拷贝(copy in, copy out)。这就是STL的工作方式。 调用empty而不是检查size()是否为0 empty对所有的标准容器都是常数时间操作，而对一些list实现，size耗费线性时间。 慎重选择删除元素的方法 删除vector中值为x的元素 c++123std::vector&lt;int&gt; c1; c1.erase(std::remove(c1.begin(), c1.end(), 1963), c1.end()); // 当c1是vector, string或deque时，erase-remove习惯用法是删除特定值的元素的最好办法 //这句的意思是，取得"1963"的位置（位于结尾），然后删除"be"到原vector结尾的所有元素 对于list c++12std::list&lt;int&gt; c2; c2.remove(1963); // 当c2是list时，remove成员函数是删除特定值的元素的最好办法 当c是标准关联容器，使用任何名为remove的操作都是完全错误的。这样的容器没有名为remove的函数 对于关联容器 c++12std::set&lt;int&gt; c3; c3.erase(1963); // 当c3是标准关联容器时，erase成员函数是删除特定值元素的最好办法 如果要在循环中操作，总结如下： 如果容器是一个标准序列容器，则写一个循环来遍历容器中的元素，记住每次调用erase时，要用它的返回值更新迭代器； c++1234567std::ofstream logFile;for (std::vector&lt;int&gt;::iterator i = c1.begin(); i != c1.end();) &#123; if (badValue(*i)) &#123; logFile &lt;&lt; "Erasing " &lt;&lt; *i &lt;&lt; '\n'; i = c1.erase(i); // 把erase的返回值赋给i，使i的值保持有效 &#125; else ++i; 因为对于这类容器，调用erase会使被删除元素和他之后的所有迭代器失效，而erase的返回值正是我们所需要的，一旦erase完成，它的返回值是指向被删除元素的下一个元素的有效迭代器。 如果容器是一个标准关联容器，则写一个循环来遍历容器中的元素，记住当把迭代器传给erase时，要对迭代器做后缀递增。 c++12345678std::ofstream logFile; for (std::set&lt;int&gt;::iterator i = c3.begin(); i != c3.end();) &#123; if (badValue(*i)) &#123; logFile &lt;&lt; "Erasing " &lt;&lt; *i &lt;&lt; '\n'; // 写日志文件 c3.erase(i++); // 对坏值，把当前的i传给erase，递增i是副作用 &#125; else ++i; // 对好值，则简单第递增i &#125; 因为对于这类容器，调用erase会使被删除元素的所有迭代器失效，而对于关联容器，erase的返回值是void(c11也返回下一个位置的迭代器啦)。我们采用后缀递增的技术。我们要确保在调用erase之前，有一个迭代器指向容器中的下一个元素。我们采用了c3.erase(i)，这个过程可以分为三个部分(https://blog.csdn.net/yousss/article/details/80077758) 1、先把i的值赋值给一个临时变量做为传递给erase的参数变量 2、因为参数处理优先于函数调用，所以接下来执行了i++操作，也就是i现在已经指向了下一个地址。 3、再调用erase函数，释放掉第一步中保存的要删除的it的值的临时变量所指的位置。 使用reserve来避免不必要的重新分配 c++1234std::vector&lt;int&gt; v; v.reserve(1000); // 如果不使用reserve,下面的循环在进行过程中将导致2到10次重新分配;加上reserve，则在循环过程中,将不会再发生重新分配 for (int i = 1; i &lt;= 1000; ++i) v.push_back(i); 对于vector和string，增长过程是这样来实现的：每当需要更多空间时，就调用与realloc类似的操作。这一类似于realloc的操作分为四部分：(1).分配一块大小为当前容量的某个倍数的新内存。在大多数实现中，vector和string的容量每次以2的倍数增长，即，每当容器需要扩张时，它们的容量即加倍。 (2).把容器的所有元素从旧的内存拷贝到新的内存中。 (3).析构掉就内存中的对象。 (4).释放旧内存。 resize()函数（强迫容器改变到n个元素的状态）： -如果 n &lt; size 容器末尾的元素被析构 -如果 n &gt; size 通过默认构造函数创建的新元素将被添加到容器的末尾 -如果 n &gt; capacity 则在添加元素前，将重新分配 reserve函数（强迫容器把它的容量至少变为n）： 如果 n &lt; capacity 忽略操作 reserve成员函数能使你把重新分配的次数减少到最低限度，从而避免了重新分配和指针/迭代器/引用失效带来的开销。避免重新分配的关键在于，尽早地使用reserve，把容器的容量设为足够大的值，最好是在容器刚被构造出来之后就使用reserve。 大小(size)和容量(capacity)的关系使我们能够预知什么时候插入操作会导致vector或string执行重新分配动作，进而使我们有可能预知一个插入操作什么时候会使容器中的迭代器、指针和引用失效。 c++1234string sif(s.size() &lt; s.capacity())&#123; s.push_back(x);&#125; 通常有两种方式来使用reserve以避免不必要的重新分配。第一种方式是，若能确切知道或大致预计容器中最终会有多少元素，则此时可以使用reserve。第二种方式是，先预留足够大的空间(根据你的需要而定)，然后，当把所有数据都加入以后，再去除多余的容量。 注意string实现的多样性 (1).string的值可能会被引用计数，也可能不会。很多实现在默认情况下会使用引用计数，但它们通常提供了关闭默认选择的方法，往往是通过预处理宏来做到这一点。 (2).string对象大小的范围可以是一个char* 指针大小的1倍到7倍。 (3).创建一个新的字符串值可能需要零次、一次或两次动态分配内存。 (4).string对象可能共享，也可能不共享其大小和容量信息。 (5).string可能支持，也可能不支持针对单个对象的分配子。 (6).不同的实现对字符内存的最小分配单位有不同的策略。 了解如何把vector和string数据传给旧的API c++123456std::vector&lt;int&gt; v; if (!v.empty()) &#123; doSomething(&amp;v[0], v.size()); // doSomething(v.begin(), v.size()); // 错误的用法 doSomething(&amp;*v.begin(), v.size()); // 可以，但不易于理解 &#125; C++标准要求vector中的元素存储在连续的内存中，就像数组一样。string中的数据不一定存储在连续的内存中，而且string的内部表示不一定是以空字符结尾的。 使用”swap技巧”除去多余的容量 c++12345678910111213141516std::vector&lt;Contestant&gt; contestants; // ... // 让contestants变大，然后删除它的大部分元素 // vector&lt;Contestant&gt;(contestants)创建一个临时矢量，vector的拷贝构造函数只为所拷贝的元素分配所需要的内存 std::vector&lt;Contestant&gt;(contestants).swap(contestants); contestants.shrink_to_fit(); // C++11 std::string s; // ... // 让s变大，然后删除它的大部分字符 std::string(s).swap(s); s.shrink_to_fit(); // C++11 std::vector&lt;Contestant&gt;().swap(contestants); // 清除contestants并把它的容量变为最小 std::string().swap(s); // 清除s并把它的容量变为最小 避免使用vector 作为一个STL容器，vector只有两点不对。首先，它不是一个STL容器；其次，它并不存储bool。除此以外，一切正常。 理解相等(equality)和等价(equivalence)的区别 相等的概念是基于operator==的。等价关系是以”在已排序的区间中对象值的相对顺序”为基础的。标准关联容器是基于等价而不是相等。 标准关联容器总是保持排列顺序的，所以每个容器必须有一个比较函数(默认为less)来决定保持怎样的顺序。等价的定义正是通过该比较函数而确定的，因此，标准关联容器的使用者要为所使用的每个容器指定一个比较函数(用来决定如何排序)。如果该关联容器使用相等来决定两个对象是否有相同的值，那么每个关联容器除了用于排序的比较函数外，还需要另一个比较函数来决定两个值是否相等。(默认情况下，该比较函数应该是equal_to，但equal_to从来没有被用作STL的默认比较函数。当STL中需要相等判断时，一般的惯例是直接调用operator==)。 C++标准对于等价的值(对multiset)或键(对multimap)的相对顺序没有什么限制。 为包含指针的关联容器指定比较类型 每当你要创建包含指针的关联容器时，一定要记住，容器将会按照指针的值进行排序。绝大多数情况下，这不会是你所希望的，所以你几乎肯定要创建自己的函数子类作为该容器的比较类型(comparison type)。 比如： c++123456789vector&lt;string*&gt;ssp;ssp.insert(new std::string("Anteater")); ssp.insert(new std::string("Wombat")); ssp.insert(new std::string("Lemur")); ssp.insert(new std::string("Penguin"));for (set&lt;string*&gt;::const_iterator i = ssp.begin(); i != ssp.end(); ++i)&#123; count &lt;&lt; *i &lt;&lt; endl;&#125; 然而这个打印出来的不会是字符串，而是4个十六进制数—他们是指针的值。 即使我们改成 c++1count &lt;&lt; **i &lt;&lt; endl; 这个打印出来不是我们期待的首字母排序的那样,因为ssp会按指针的值排序。 为了解决这个问题，请记住 c++1set&lt;string*&gt; ssp; 是如下代码的缩写 c++1set&lt;string*, less&lt;string*&gt;, allpcator&lt;string*&gt; ssp; 分配子与当前问题无关，所以不考虑。 那么如何创建函数子类？ 最直观的是写一个比较函数，比如： c++12345bool stringPtrLess()(const std::string* ps1, const std::string* ps2) const &#123; return *ps1 &lt; *ps2; &#125;set&lt;string, stringPtrLess&gt; 但是这样无法通过编译，stringPtrLess不是一个类型，所以我们需要创建一个类，并在内部为它创建一个函数，如下就可以啦 c++12345678struct DereferenceLess &#123; template&lt;typename PtrType&gt; bool operator()(PtrType pT1, PtrType pT2) const &#123; return *pT1 &lt; *pT2; &#125;&#125;;std::set&lt;std::string*, DereferenceLess&gt; ssp; // 与std::set&lt;std::string*, StringPtrLess&gt; ssp;的行为相同 如果你有一个包含智能指针或迭代器的容器，那么你也要考虑为它指定一个比较类型。对指针的解决方案同样也适用于那些类似指针的对象。就像DereferenceLess适合作为包含T*的关联容器的比较类型一样，对于容器中包含了指向T对象的迭代器或智能指针的情形，DereferenceLess也同样可用作比较类型。 总是让比较函数在等值情况下返回false 切勿直接修改set或multiset中的键 对于map和multimap尤其简单，因为如果有程序试图改变这些容器中的键，它将不能通过编译。这是因为，对于一个map&lt;K, V&gt;或multimap&lt;K, V&gt;类型的对象，其中的元素类型是pair&lt;const K, V&gt;。因为键的类型是const K，所以它不能被修改。(如果利用const_cast，你或许可以修改它。) 考虑用排序的vector替代关联容器 对于许多应用，哈希容器可能提供常数时间的查找能力优于set、multiset、map和multimap的确定的对数时间查找能力。 比如我们需要一个容器来存储Widget对象，如果我们用关联容器，则每个节点不仅包含了一个Widget，而且还包含了几个指针：一个指向左儿子，另一个指向右儿子，通常还有一个指向它的父节点，至少3个指针。 在排序的vector中可能在标准关联容器中存储同样的数据耗费更少的内存，考虑到页面错误的因素，通过二分搜索法查找一个排序的vector可能比查找一个标准关联容器更快一些。 查找操作几乎从不跟插入和删除操作混在一起时，再考虑使用排序的vector而不是关联容器才是合理的。否则，使用排序的vector而不是标准关联容器几乎肯定是在浪费时间。 当效率至关重要时，请在map::operator[]与map::insert之间谨慎做出选择 map的operator[]函数与众不同。它与vector、deque和string的operator[]函数无关，与用于数组的内置operator[]也没有关系。相反，map::operator[]的设计目的是为了提供”添加和更新”(add or update)的功能。map::operator[]返回一个引用。 对效率的考虑使我们得出结论：当向映射表中添加元素时，要优先选用insert，而不是operator[]；而从效率和美学的观点考虑，结论是：当更新已经在映射表中的元素的值时，要优先选择operator[]。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DFS 困难问题合集]]></title>
    <url>%2F2020%2F09%2F19%2FDFS-hard%2F</url>
    <content type="text"><![CDATA[解数独 用col, row, block来分别表示每一列/行/块是否有数i，先对所以可填入的位置做一个登记，存入board容器，如果有一层dfs可以填满所以空位置就可以return ，valid这里也可以用来提前结束 c++123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;public: bool col[9][9]; bool row[9][9]; bool block[3][3][9]; bool valid; vector&lt;pair&lt;int,int&gt;&gt;spaces; void dfs(vector&lt;vector&lt;char&gt;&gt;&amp; board, int pos)&#123; if(pos == spaces.size())&#123; valid = true; return; &#125; int i = spaces[pos].first; int j = spaces[pos].second; for(int t = 1;t &lt;= 9; t++)&#123; if(!row[i][t - 1] &amp;&amp; !col[j][t - 1] &amp;&amp; !block[i/3][j/3][t-1] &amp;&amp; !valid)&#123; board[i][j] = t + '0'; row[i][t - 1] = col[j][t - 1] = block[i/3][j/3][t-1] = true; dfs(board , pos + 1); row[i][t - 1] = col[j][t - 1] = block[i/3][j/3][t-1] = false; &#125; &#125; &#125; void solveSudoku(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; memset(col, false, sizeof(col)); memset(col, false, sizeof(row)); memset(col, false, sizeof(block)); for(int i = 0; i &lt; 9; i++)&#123; for(int j = 0; j &lt; 9; j++)&#123; if(board[i][j] == '.')&#123; auto p = make_pair(i, j); spaces.push_back(p); &#125; else&#123; row[i][board[i][j] - '0' - 1] = true; col[j][board[i][j] - '0' - 1] = true; block[i/3][j/3][board[i][j] - '0' - 1] = true; &#125; &#125; &#125; dfs(board, 0); &#125;&#125;; 全排列 II 这道题是一道中等难度题，但这里也放到了困难，这道题对理解递归过程很好。 最简单的思想就是先排列出所有可能的组合，再进行去重，但这复杂度很高，很多递归分支是没有必要的。比如我们开始搜索到第i个位置，有两个重复的1，在这里选这两个1的效果是一样的就可以剪枝，所以对于重复的数我们只选择一次，这个通过先对数组排序再进行判断后一个和前面的相等就可以跳过即可. 我们还要标记一下使用过得元素防止重复使用 c++123456789101112131415161718192021222324252627282930class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt;res; void dfs(vector&lt;int&gt;&amp; cur, vector&lt;int&gt;&amp; nums, vector&lt;int&gt;&amp; used)&#123; if(cur.size() == nums.size())&#123; res.push_back(cur); return; &#125; for(int i = 0; i &lt; nums.size(); i++)&#123; if(i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; used[i - 1] == 0)&#123; continue; &#125; if(used[i] == 0)&#123; used[i] = 1; cur.push_back(nums[i]); dfs(cur, nums, used); cur.pop_back(); used[i] = 0; &#125; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; permuteUnique(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); sort(nums.begin(), nums.end()); vector&lt;int&gt; used(n); vector&lt;int&gt;cur; dfs(cur, nums, used); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>DFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树专题]]></title>
    <url>%2F2020%2F07%2F29%2Fbinary-tree%2F</url>
    <content type="text"><![CDATA[二叉树的最近公共祖先 c++1234567891011121314151617class Solution &#123;public: TreeNode* ans; bool dfs(TreeNode* root, TreeNode* p, TreeNode* q) &#123; if (root == nullptr) return false; bool lson = dfs(root-&gt;left, p, q); bool rson = dfs(root-&gt;right, p, q); if ((lson &amp;&amp; rson) || ((root-&gt;val == p-&gt;val || root-&gt;val == q-&gt;val) &amp;&amp; (lson || rson))) &#123; ans = root; &#125; return lson || rson || (root-&gt;val == p-&gt;val || root-&gt;val == q-&gt;val); &#125; TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; dfs(root, p, q); return ans; &#125;&#125;; 二叉树展开为链表 将左子树插入到右子树的地方 将原来的右子树接到左子树的最右边节点 考虑新的右子树的根节点，一直重复上边的过程，直到新的右子树为 null 记得吧左子树置空 c++12345678910111213141516171819class Solution &#123;public: void flatten(TreeNode* root) &#123; TreeNode* pre=root; while(root!=nullptr)&#123; pre=root-&gt;left; if(root-&gt;left!=nullptr)&#123; while(pre-&gt;right!=nullptr)&#123; pre=pre-&gt;right; &#125; pre-&gt;right=root-&gt;right; root-&gt;right=root-&gt;left; root-&gt;left=nullptr; &#125; root=root-&gt;right; &#125; &#125;&#125;; 二叉搜索树中的众数 第一种方法就是遍历一遍吧每个数出现的次数记录一下，然后换到vector来排序一下 c++1234567891011121314151617181920212223242526272829class Solution &#123;private:void searchBST(TreeNode* cur, unordered_map&lt;int, int&gt;&amp; map) &#123; // 前序遍历 if (cur == NULL) return ; map[cur-&gt;val]++; // 统计元素频率 searchBST(cur-&gt;left, map); searchBST(cur-&gt;right, map); return ;&#125;bool static cmp (const pair&lt;int, int&gt;&amp; a, const pair&lt;int, int&gt;&amp; b) &#123; return a.second &gt; b.second;&#125;public: vector&lt;int&gt; findMode(TreeNode* root) &#123; unordered_map&lt;int, int&gt; map; vector&lt;int&gt; result; if (root == NULL) return result; searchBST(root, map); vector&lt;pair&lt;int, int&gt;&gt; vec(map.begin(), map.end()); sort(vec.begin(), vec.end(), cmp); // 给频率排个序 result.push_back(vec[0].first); for (int i = 1; i &lt; vec.size(); i++) &#123; if (vec[i].second == vec[0].second) result.push_back(vec[i].first); else break; &#125; return result; &#125;&#125;; 上面的代码可以优化，省掉闯创建vec和对vec排序的过程（上面这个主要是为了展示怎么对pair写排序），就是存储map的时候，同时记录最大值max，然后遍历map找到所有value为max的key就好了 再进一步优化空间就是采用递归充分利用二叉搜索树的性质， c++12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: vector&lt;int&gt;res; int imax = 0,count = 0; TreeNode* pre; void dfs(TreeNode* cur)&#123; if(cur == NULL)return; dfs(cur-&gt;left); if(pre == NULL)&#123; count = 1; &#125; else if (pre-&gt;val == cur-&gt;val)&#123; count++; &#125; else&#123; count = 1; &#125; if(count == imax) res.push_back(cur-&gt;val); if(count &gt; imax)&#123; res.clear(); res.push_back(cur-&gt;val); imax = count; &#125; pre = cur; dfs(cur-&gt;right); &#125; vector&lt;int&gt; findMode(TreeNode* root) &#123; if(root == NULL)return res; dfs(root); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[job]]></title>
    <url>%2F2020%2F07%2F29%2Fjob%2F</url>
    <content type="text"><![CDATA[该文章已加密, 请输入密码查看。 d452e1b2bbce516a27def17d8229324e9452e4b87683ab2335e8251e24339004b966b544b9097106e62172582551777d5cf68845372200a54931701dc26aeb49054e57d2b96e26d6bf8d1e03ac0258074406f1f075ad48019186c1906e977563a3b0e7f20764bf37e77a9c2ee468783ebcd4f7a56070bf81e7d43394518c760bd83155855db6d04f13cb0100fdb5515a369f2ef2973579e03a0e079ca007bf70b3f290869db3a54cd4ad18a27b415abae9455ef9786fc2e471875a09d1dc701fc0559ae926364a972cc594f357938f1a1240f813a0fa6178ef81525f55689c8e8922294e06eaabc5a57f4bb7e477401b38aecd024e2af7feb36e9a7033cf78cc12c7e5766b4cbee66ce7060039e96a905896ca9821bb31cf5f26148d805fc4809826e5fb749ac08b722cc2a2472650921f1738faf8c99ecb77376a3a2ca3a7e7b92238b54a99f4f17147edebe4e4f1e6ac3380a21e7f330e19a06ec0c7eab3172525cfd37050487098a636feba56b9f2c13175495b4a7872732f307affd67bb1e90245b71b0c5ba4f65dcf42fd37e20e7783a5999caf4ef1eff54a0dcc7d526b50abc794426e64244d699b9b6bebadd19f91c7ca61ce04d4306e087e706b3ad93d7e617130f7819489ce6e5521fc4c0cc029b83baf3a2b4d1d80b3f503dc92745ad0f07ef77d689beb93d9bc6a3dcaab184e5b8452d0ad5996bede031f81fc4b95ff15e7144f3c2d90fc4f89d0be3b6ec2e0769622686ca74b88515db9e55081717152f9e34b54b1f44c683fe58c4d508d62a9ab2069269cdd407fa8b7728bccb537e7f61cb11ae3a6c7d080a7ef745c4aed2587ca07266787d31e2d519adc24bd1705a4b33b2c3d75a58d1a675e29ae151f3d33e333ccbaddb0726808662a0e6666169ac4715006f06f5604414f442c7523c0d4571c13db5b1a485fdbee2045db6d72d2b0214f3b3c24412e17d00d4b95401fe36747140c4ee43fc8e69c103c9f5f6e5ad0e2a7c271d34614e4411cad5a35b6b61fda815782677c556394c015fe943873521334df0eeb2253cc950d37cfc31bbe3e7947484cc7f9054d6b8f4e171ef1fc80d17805323c7d9bbe7c15ced658a9cb8e5ce83760f332c16b481ccb93a145260ae9ca04cc6985206bd96f2f3adfc86c0facb2a87a023242ba6664bc4b282366ac16b1e647b0aee3eb30739c680da7771bbf82a9ec82544059e7c54de7e46f870c69ab972fcc755c3ee66eceef79fbb92b66308526dd05180b29bb3c485a24aac8a77edf08d1c490f6e8beb756615ab1ac4862705aa3037ebf4553c0dd03d28575726dbc509463b18f420374183815542fb70f4ad2b76318810ec286d33326ed2515cdf209f673a023a0bd2b08be44ea8875e6fb201fe7b5e2dcb6643e2ef4dc00f3c8c77da779b830d87de338a9b7a1ee5aaa045e022ad49bd7252ca75bf2c4f228abcf89ff5c602e0224acc6b31ec2ab9413df42a1456c1ce92952fd5225f0cfc62ad8ddf96b74e861e332542743f84cd071268c62009f8fc8882a02e9d77370916f5c3ff9b0445d197ab3426f458088342d66e9c4a40439f222526dc3f00050b9d3f1ddc735e343e74481f2697ef60c290ba87f784e19dee85f47abdd7b7be3d0f2694f2e481ffe6ce614df247cce6a23b323d6254262f472aeccecaec891f8a7f1e5e3003b245fc6e0b3d1d1a08209f2177b0cd2fae72de48d27b6d7a0bcae68cee9dfa6ed855db9ac7f7fa352eebb3a48310aa3f4292cdbe2270e2dd3422b30e72b4b2337d0a34f444bd4c29bf1f984b78c79204c31ad3bcc9224bf65b54120cfdbf6db052c85024a75e05e72ebb2c18c977c83aec888a827f29ee97ff5eda1cbeee99b3dcde36f2dd0696721ebffd0915a74e657a636f80d9de068e318e8bdb6c7cb99db910e565b401592b04eba508aea5587d93df58011edf7e79ebef87f0b8bdda50e79f8a2691b1c7305e339b4c594825a83b163ee3fdd50b6011a6c8fdb3299ecf892947e88587b760dd3653d6c2c6aaf8c5dd3028ddb23b1581fe437126be49d0b90c7086e2fe766568b73a3f74a2aff0df6cd44918016b7c9f3ed2de1834c49cb5fc563ff386d805cd38a813f8fa7b5e6084abdf4390daf85d5056c531335f5d72645ae10554fd71ce369590ecc3fc669582adbc3d31e84fc36b880780c469b1167265d933fa612b69bda7907c877c8b904f183ac4bd1101a866df8dc169cb55e0c3ce08a8c2ce1289b6ad659dac407ade822096333d6c19f3aa59e6f6e68ea756d28e4423fd1e42a23ffae6a28fcea5f7c6458d9f2327e7ea23d0a6181e733ad2bb6c6023cc8fff538f96b92dea463b7b5ae8bafe042f01372a823910561ce3543830969c8dc72af8be3f9ac8546be1711edc57608e6e59fbfc7b153cb85fe1443a57bbeb32f1ddd39ed78aee102ef4e2e7d15c0c424a195c035034ef9cfbcb378f976235892fd34e21c9f9d0f6e3db108cfdea6359501ba0f8dd605e7b4c2afcbe30e1c06b6d0fbe254a4adb5bf7c7c3e54d30019bdf7839928dbd52404063077b935e307818b34f9801306aaf657b43de366eae11310f67e04f2da57178f646558975198fe5ce59e5a29386b415439e094d25d77cf28c4a8d264d0f269810cb90825d56e406c585d38a07cbbbbc73cf067bbef3dcc6726965baab232f593205678da588802016e3b6bc0122b7714399a7489812c592b8308d5eaf5ab0338f06db92ab81389fb7548ffe87924ed513e1ea553ddf04df88273ba51a4d4122203e47d6b86e8776f38aea77dfbd1445f481c5ccbbea03f4a41d90f422acc40612ad200f63211f7e9496f59317f708905a59872dc36ca84b928d8f1818dfd12a63480a05820b91688c6348956eb3c58806025906c9c8d9b286b0e58c820996d2abebba171fc07096abebe2106a3f48aee0720beda8244b30c96efc63cb744377876adfd7e91cd208fc75d096286e16ef0168f484f08b1781ebd1eb78e9ddf99f0b978ca00710129fb8381b7330162525a333881fd8643cd3aa981ff639cedf51e76edc38e571f1cb8cad41395b0e9c697f496d08c052633d56a6ce6fa3d793fa47955a08d09286028c94176735b53c216b0a5804c0db797dc899834264eb6a32aa8f6c9fc43883b6d1dfe91bc1eca9a120a93a541ac4a3f83fc00e1389ff136ba060cbf18835a4674ab18c936262440fd87b929572378188c3cd0560719d1d726fc5537f8bb77646e085188f7d77ea84b054d3196788acc8d60a6119302cd3525c81aadd07f523ffc66b996c092d14944cf1b07017c38b3403a3e4fd06b813a7b022124771f53734429f2e6b2cf397d2313ed7eaeeda227ed3398c43f041cb3f4a368ac6c45c00b2661d427ee65acd6ae18f99f759066e46872f0eb917f765250d217a8c957b6bc1b52bf35f1d5e408491657a8e1beb465ac574d07cb3936d08f1aed527a5afe75392de17679b87b63422e505bb36a3c9ec56bc4c5ca91fefee5869e05840d0d7447d8d171bfa0aa0800b963778d51b0d8e842214e09b16006e3d5b45c9b5b226de7f8024ceabd0358107da067e5316bf29f81e4803d3515da13d0aae7466855b140f5870b7ec0275cf74a4cbe8d46f6711361417dd00de21abaf6782c45206683d2070740824dcca884e51938a2f8a4ed7c8819ef262d76d7e2c7afad0f3f9a9187830be41750cae326c0edc42de7ca3fab6c9338278d89318ea0b94be119966dfa6dc976f35d888e47e817d73d0c8651dc9dd6ea2e35d73e032b007e11001b01d5dd9a45311aed48987bcf41ca6f4455d8be2eab6642c6ab5dad855c14c0367860e18b20dad49e44220f9daf3b0414f13c66f11f7a2796ef3edcf22c1f6b1ebe4226d116f370d2fc276c144b3259c8a8ab81d9502bcfad7943578db5b04e03e3d79337d1b13e9206d2abecdebf8225c5535179de86c0b936be3ef97e8445722a8234bb19cb203295855d64551b4892ee415bd3bf3b3d2d75d85f2a7a253b7b17ee1d4d6d5422c1e2dd483cfec87c32e8693bb22217695fdf71bc4e53bee10f23e326ad8fe182fc4a8e928432773f05e9945b9ace17cb251a10632a1c2f7dbf7c41a06280544a4e80e4f1804b0a4948bb3aa873243a1bd62af434bf8ffda7585f880791bd2943766d8bb54b09cd4b936edb1f484ccd73f97c81b05f5ba132cd028f53a1f40cc0c70a38da515c25cc55da2c64ca1a9e73229fccc241a1fc97023b84bf5a71f8aadca53d6ee8f10610df515a424f4fe37c2b350be079c9886bdeb37575d10309762ce045d6a5d70e5ac8eefd6a7a522a0f167c826b7f3bdfab96354fd27d1e20f02bcb76b8877c3b5aa3cbc19f7baaa2e8cd863ae0e12289249eb6297f383cae26643ac7c44146c2b3b91f87e971085f6bdd5f28d6002283a205cd5680bce322a03ef42ff73bf2a94519ab23d1978802b8785d760cfb4db3e78673a3b21a9f97a0017c6b2f8ab63166c05e1e69ca24480b3b917b5f020478dc07d7bd0280b991a6143a1e57928d64599c9619a521f268021a50c1bc576a8eb99cde54a2c7ff583ee04a2a8c482ed2af55a69f02e3dfbfbadfaa1f9b747ad265da66697a816da0c33ef134ca60f3aaeb532899a421b5765e6c197331244523292a7210e65be95fc092286bfa176e65700261bd510dce82b3ef1b4697362f7b1abc9daf335d4f25e4fb87d5e0b808861fc64a6d0284a4fe2c310fac57944e05551410c404b47c71224951471246e689e7955b2b414a28c8b38656b4bd13dea964302fdc4e38cd57b4c6e57ac8af3b164524013eb1294539819dd4502c96db4a85805f05608bdcff78460324ad0d8e71af2fdeccf7082b9b9124b142cf43debe124a08176d09a755342f107c3661c7a7222aaa481ac53e5f20fe6fd444e6686ea4a8f6a1946ab40dd7d77517815b000ff7cb127248409c3a5486b69d8ddc787490811b199ffe3eb539585863cd8255b73ebf3e495cc247a26ed01133ee8a53ecbe52a8253e28db8c043796bdbbdb9abe49d079e1bfc63ad9a5fef89a11a848bedd3651f2f05ce45bf43ced901987da04bc32d79572c542563a790c974efb93e04a4a25228f3c2767234d7d974afdc8a33c7f87d61871c4a6c8c822162a7cc53a693b805fdaf884db5d0b0de35b4166cd46ad19c9f4b8263870a85199eecaa158109f4adc41a43c5879a06b163dfd95244fc59c2ba5b303f9487e9f6ea502ad996a3c38fc4e1ee0551e07c3a6b32ad88b5cb7bc64ca0d763680876fc7643bacea7cb851427f53ab34844e5ebcc035c7e8c8ff8a17d72279b0455b9249ce2bbb65844b5311395c2efbacd12fa1fa0c1ce99bb9c4b2c86fcb0c9a81866af81c90ba98088c4ab5385cedcb81278b3687606b5360c556b3f4786642aaf2245f24b77dab5a21f1da9f63ca04cfe9ed951b2ee6e457e76dd08e491d2ff4cd423258f1ae7f3a3d0bf3f7c0273edf5372eb9da57dd4729b6cec2de9dd90111af3132669dda8f2f8904a9723283f2b48b009fc37acdf8eb69bca18363d3b7d05132cb63e7fc95f3cff4b83b26c7564bd28941e22f9ac2ea740903a42126dce33cb185cb3f70347f5be18f03ac841a906ff207fd6620124514c334ef1355e09b6c3bdac79a60bb90c90d6dbb66d6af356a1873329602388f6df1ec024ad2f6335ddf9243af5fa4294fbef92eadd6fd46fefa1ca458c95a32083ead369881e8a26445721efc6a2b28dc74ba5195bcc7511833ec2e285bd162f9048be85e54eaf5852f36a77925465abcda0073451c917f2661aa89390c59abb6a58c3fc7ebf9450926e064ffaaec29848c969df429e68a0f9fe976bfc6c86fe5e2f9f01a141313fd59f9a9f847981f9673b27aee1904d1d46731e1f0d4114fa2c1f210ba693e1be9b60dcc5891a2d87eb345b2488ba1d18d0de54123832f788f12b6c42b9930d4c7897bedbdd988a03fddb97c1a66152634210d08207fa97df6586d2d46d48cd84381f37c6d7021cc10e76fea4ef34e9e5df38a2db30b6d9c25fdc66987078a384bda7f95575dd6e677dba5c37ee09bde5e1f0da88f28449aeb3bb879db8a4d42f97b4ebe825b067221d8185c0b1ed215e05d28acb684f5599ae192b252ab52d0d083fca9f0d8ae8f525b11e244e6f51635f20bc5f6722dfb71eb11ead80e21fa37030aa350fa9750729ce6339853290f0545b20f752b53b90e2dd4e20b01bb487b154c11b0d6502a51c8376bcf4242637a257dc6bdc42d4121c383d343bb4edb9f4637f9cf92354105dbe92d12d8e357343237d45dcd3e542fdd3bbeb99990156ca15f4b509f80b90291207b18d6d9f59ef9bf0fc367af665595258fe2fe321bce0e1b71598148cb0618720fea3c605d66df9a0a1bfec1aed2eb0e2e67b7bfc3d6266bf30c85c7dc6a436f06a4cbe15f839ac311134d632e10c1c5964e81681e5ecccbf27a402dcce51d7dd67137fc3e85f99ea274f40f4d9c974a6f7e4c067654da101444a51526bdc6a9ddf2d8281c6781b4d2f6c1d66e61171f7ac67237023df0dd12f2b3d88fe9b13fa39d02e3d69904b8797c82223b105c7cef49fdc418d8f30a729e06b003b5603277f9b14d9f9c8e8782817dbac2eeb408a5388d45ec0ed9616749871919884ed5c9e741392baecf65f22c4b51bea93543895f66a029786dc7e6cb3f4b10b7a23b16399940a42ec838f2120297d0be54ba80f4c0b56f340d37ba808fb7c01ee36a5c6c8808077f21c1ae9e5f0070e51f4b9cb4c5a8b65b902f0245001e3f986608638f25ac00301462121a816ca6d12a479f62963b5c13748ca1fe672eb185b2862d7800efe60317743eac436983d5649f46eb477f3f205e1811e88ede30031a37ecf5f8316afad0cac008c393675f0607cd341754292dc0469704b9528d720b8a5f1b5d2021f0e8ea65d74d9b26970ca8dc4d966a05f610d01d592fd717d81255b371d944dbb9a02d31a048521525848bb89fcc20075ca7d3ce0e2b55070c16ef1c38809d0af1f1b030d852d9d41ddf80ef2a6d02da7a6b121404d0c50fe7d77cb0850ecf2656f7bae65a52ea5e9b37dbba77dd7bd4345522b599f172977e1b8bddf5a7d0c177de0d90a515ccb58e37de3a43efd5fd9ef59d595fbbde33d9bdbcea3598d9cc5206fa94c1428bc0929397995c1a3b9fa0ad8c34ed0724f1ef21faae18da309e78d2f5e4ea8edea0023d17752bdcf821d64bb5fff1408174585ae53bfc8dbf058d5332f88a0c7413206f2824a8025f705cd0f2b79bf23cb66b2e7a92a677fe9a5c4d578cfaf1738ec17871fdfeaea4377f6df4956151b30ad34b80465f4794376eba0898a4996d59c9ccdf7b2e55f84db6e4c1a9edf99a2113c4e66381f9a93a14d4c4edb1ba1197db3d00905dacc60483fefdf72611c232aac98fa8a2bf94f3a0b2340e77163b70fd66b63c9a285b128456e9fd08fa2a2b872530961340c12267ca9da91326847a822a1c47c9cbe70f5437135128b72a085b7817027220cc4c73a64b2fdee173519fb6faab395021e1e74d30ece5aa72f6b945fbdd1acff00ea005e526125bdadc37df6e8ba307700812805a20400c1bd8326eec9a153de2826a096155e9690553c0658575ecb3bfc5d9b05ee7e3b190a1955c6749644c667019cc3690deb15ec015bdc8218a36e726de6d13b127327c9fe080d8ae999a7168a661ac262e43803370942d88d163ee9869ddf8de07eb8be000c97110d1b9ac03191ff5af13c72cbaa5a9f9ff9698544c712e20661488f029189d9f334bc23c3f3bbfac349393ee7bcf2ec004643ca87067cb1906323640d5b07f12dcba525f78d09f9be3d18a735da27b0fe89ca673f1554cb867b5320449bd2953808ebdfadacab9b3846ea3f3929ab4e84872ae213eb203095b4bc1b05f7891df93a4fc8d34abad3970977690b3aa7c4f1ec553cfa8da96db63c07e92d2cdeddacd75d1141d8cf67f30aeb77210d805fd17f842d3a8e5da52eb1da39180013e0d35088f6df83d5795e04ca14503e666d807b9330d75e2381855d86c4c10d51c9e73191a7b5680c00be3e18aeadd90f856d4c157ac2a1c644ba1285ed57a6a05b6a1a5c2deed2db24d4d9e6d598bdb9c1f845d39f185dd481a396c771dfa699f93a285144874b8e779e80c7dde68151dc3c9f6d4f8b0291277982fe515f38aa3538cc75e168f276d32d7e654e7df7c1707ba5f91df234348b330c64d41d4095acb4513ddefeb3cc745aa373ae85cca635be8a89a4a57bf1f8c028f57a693a2eca3c33ed918dc4fc3859f4a1926cede4e5dfd6b8f0a4cda3e0fc8aa059c80c39d92192c1e7a679ecca7ab92442167bb911eb57f78f4c08b9786f94dd3464284566f31ccbfb75d1dde74580401f124329e9a5269504fe5443dafc5b9ddb5774a4cb1d442c7efacb860cd64d4953d2ee3425162915f9159c1309b3c7828d82055864e8937a8191ae340e11c33851db43560bcbc992c98e51869dbc363facf1947ec43cf042c30c7dc49872d8612772f4d81fa881a9a593b55864e664805c758fda97af5c4442d6aed41edbe7555e731424d4bf06503e6b57b9404a84fe46be79cdf77bfd420f5e928f85fdcab80badf6627d754fdcb0236697d3b5f44d08be363a9a4d63654abcf43300f513087b6e60b04c6a0ce942bbe6cd716a2a6d291ba09d55cdcf9e77d8ef0dd64132c3ec7b933ec39b41df2211363586639455f43e4fb76172903a413a349baf70ba00a816425e5d40af8c52d2f9ee36228d24254c0b525dfc3217439f6f8d25a5c4ff5afd0dc1b412fee58e015974b4e300f78a38c278b43689b6656e0fbb0a59e87db93032ba02aab5fab7325f8925b918f6b9b0b39950a05b230ae80cdd1e3abb382fae880d4cf649fb2e96a909a55891a8ac5bddad58c8df140b842592998650ec4c39f30aab1155cf46de239b4b33c091d4eb4e33854539274127dcac56546a071ddaffa05f37a39f6d07e2d6094612dd133a8503979c7df1f6833e937a8f39f96e8c4532eed85db54ef962d332a7719dcca3d74347425eec8c329371191fca9d93e92fb4931022920be71732b6b75f2fe3f9ded68c2a8cbe3f50b7cf052ef37ab1ea1e5ef01dc230a128513c60e413b96af7a45b78b666ff9bebd47033e9f8f72b7349bc60ba80215a99e7868a288c3351e68fb7d43e88c4e8d99364f12a7a2d2f391fc6787f7fa7b2957b0b3fadb0c4e874cc7979b25d1e3f1d03ffa24b6c154b53f65b7a718493ea615e3c308d3e5e80bb6404b3359f7a844b233a2d0d68d5dd5b52c1b10c02809a94f00bd1292e08df44f2cfd8d635de455381208f30fe4db4efd484928345064616a433becf790c5612df48d3b1ba511599e84fda866f5401d447943ed6a36c4152c5a51dfba6e76bde11f101ce3e14d73f5f3633ff61c5c7e35ecd19c4309cd28019557f6a576d97c42b1dfa4130a01cf11a46f64fd681ad1924122606caca9ca2eb45ce534398aad46ff23dd4ce6faa27e5d883dff51b78d4d30933946e670bd405cbca7d9dbd49d8523acc1b76ba1a18ba0667e72b6945672386edb0534b163727d7671071e5aa30b1c90078ef31a7516c2e6b2ef00e8d803a5d4b15319b1d2be1eae820af1e193c91d0422900be702d045ba841b8657d9d6e79e2a7fa4b4d26f6569299c9388e16391e6bd865797798a8fb77693445e7e9e9a9fa7185cc44b20d0d6422645e7a10f40117901564600ac6b94b0dc85ddec309acd47c50bdb54c3a8b931bd4c9dc040224ed4745c259b3bd9ec4ac90d961a8d9499f7a21980f476a66f27a7856910f8b7204041d332594066adabb34c040c4870db5d696e52082518dc42da7bfdd74263a2a8b2423e51456e519b3bbc2827dae337d4e4650a63f23291b2772dc92cec992b69a8cdd736cbd2dff8ed0ab70215c5259e7dee4a5fccb3e0dbe52f39f88f30348137289a86316a9dffb7211a6c87ff6240f6132a1bc3c92be0f6ac62ba4f38642ac8e4cab12ac18bc01afe47b67cb35627008e703217a9fcd338a83d10e19b45fe3f49e43243cd2b43c7891c98fbdf0249ede6c44f4d6679775f6708b63cf9b66121eca895b347d9efa33a1995126114d3ce7062e72322946197ed6c8302942c57c35f3cae94664fd9835bf4f13d120963a3a974928daae0f1b5d21db64020ff6669e723fba66b81b35a0f2fe57602be0535f3beece9c48abc823e3759574ffa0509e7864a3acf7f3662921b2f962850bcc51c6522e245c77e8257219f452cbda768c94437717e10ad7ccec0e17236c800e86990427fd8ac823040b5b5ec73a6a0186662c7cdc43567b1e25053abff30210ecffc97563c06659055eb1f0d096dfe265e6fa9d31f8ce666423af89f6fccc0c4bb77deeed2a2b45f86b21432c8868b65a7cf91c0ddabd168ee969cb0d06126930b85e94005ce22c6cf69d49929f02bab23d3a766fb0bf5c97e9672b1609ca377a2d79d4963f63f02a294905e6b1c4c6045e6a98862104428c1647e3c965b898bacba1b044234bbd263f093e83c2a4987b5f73c57cc6111720b38c91a366f3b777a670a3c0af4f25ccf3a0345fc20d761d1d99db62d3913d2b8fc46a39232b31d8a58d7de6fc4072c8b0f0ba562f8e862847f48bfdac48168187ac171abdf723615c01ddd60f9b57524f7d15486b0c54e3812ae28329486129c41a3ef445775be6f9715a8ab0da840ce28d60aff8143295b3dcecff6b771017a156f0308ac0fca273b01c9db42f3f6ed9a90b3329736e27b84fad5bbc2aafc495c3ac2ea795cd4bec0283a38c20270b64c252dda9b5e33961c64d19a73c23a25d14c72bfa07c91943bb2b750f5567f92e49f01c15fc1bf740d7f6bb034f053d1a64c31e137aa1d514b180d1d45c7ec3b08ccd315b63b211ac3102749cad24bc78eec9c669739441336c02b63303ce8191b451402414814d45dede0416e17c58082d278908eb23670fac281c9ce4dbe2321326adce347ad177d5315dc5a0e1e758dc4a4944b206a69dfce7ad0f1a736be4dda3e354dcc54cea70ab989a3e1aaebeda3140897ee9cea0d10c3e93e08447faa42133bdb00a4d4d7e1cb17f362d3106a76e449df30b52709f07ac5942c68ed2056f082b7599806e4eef7cada6c5272616b4ab6bd65f929ec88cdcaddcfc32b9cdb8893c093f8eb63a92a5a90a4b2b9ef8252333371fa4f76c0a177d15bf69ee325772096a34ffdabe60dfd75af767402a51383ec9ab0a3c38f0db54e1293ae067f750b9b291c05153d4bc1e9c4a05f634a0d2f58e0cc64617e5d3fd48af5f7222bd6bc00af2a918e9c0b1d74464a5cf0c232868f768c098705fc358c06b1870df47956b6dab7dbb25963d8590d819a52bafc841f50695b16ba0f43d0af40023528ddb8dadd69c17458981b056ecbbb34245b60014bc67a2ab32ece812a542a98603d8c14e42d945b3af71987e66b953d0e46c01a9251b68b8ed733825686f89af2b504f4e5f7a0ad05c38265913fedc04976c01f2a1311ef9221c355cf0ec510fac1733a6ba8b5f606b7a01f802bf8f0fdd7687084d82893aacfb4d79beb7abafd11213b94eddea49eabbd5d0778c56e0d5b657631dba9c59879c4975bdee844e2fb2b9e035a6f1868000088ac8c88c3600dae41f707370e070497e3e6173f7860bdf3c61946c606375c143b62969b9df769889db0ad7c44f9007e5bfd1e24b4f7a7db4f0f2b7f37c45ccac27518e0c410c00ac8fb5001ddd38522be9a3473d96ac3a977b5884bc59af46c3a5c5c8a20902c5ec5f797e4697aa9ae89c53e773cfeb0b26affe9f5eff44fb875294dcb25a7b98960601c935e1cd1434bc5c160398a6fc65fe119f94eead08b60114214428ccaee39b19701c9d94cdf9e95a8a88d99018c50e4c097b18ce7946c1dcdd9de82c1a207b3b0cd615c969422d46553e267d7c9c8590d97b2b4cb778c9dfe7a4e4d53402078ec071a2c4bb379cb4d6a22680f553a379a84f0bb2867d3144985d3ec65b80209013f20a255326cacfba20e769fcc8950f0c1adf6058f1578604a23b1ec15c1a5a389fb320630ba268cfeedcdfbae58653b88eaf4601999f040b48894af84f3b951441ef6920e577294fce7a4d398abeb6948cc53b0c6cd983d6c9b1ac2615a2129fe33eff9bfdefa2cbb8976e55460c06d89623855900ccba459b7d41310cf2b53c227017ef9e138d8683216d96421199da72cb8281a7355964531719805ead32967a8cdaf83bad799924c9400d312196e24c9980d545a8d0a4545564aca5d92073fa44fdbfae656474020bec9c0228a7ee5e340fa3b05d1ac709c453dde3f8f8d01c7a9d6732e7d9e89692740b425f927fcb25ee8bfc877278b8793aea53228ac548eb8e37980e247e35d337d399b8a10283c7bb3ecc633efeb9c8de7e47013d70008a583b4f03c3ab32bdd5e8c6b1608a05b486ad7f59e64c3ea358d1b64b69e5c532570b69cb09c98f34d581cbbd2e9e71079a3e6b9651534a2bd88b96594a71eb83df430dcaa57fa0f939bb590bbab40f5841ae966abcd1bb48f4a680c0afd6332cfb900007611f5c019b3cf451911f7f09b708a4de04e1a11ef19db8b18fca19c25c587053cbd80db89b7be5acfde365eb6fcf0e9135befae39d03f06a9a37121a323d187e4371875f5fdcc81fb8f6e85757feff2062d59e31b9ddb1d72e25c53ebe2db7bc465ff431fd4cc509aee2d476c2a1d0c5331be09c7f641d6bf0d209282d4b7ae9c575a524ec62b14cf9db92539826bcb8e15f027117940aa5c48f554df9029513c39c09cf9eb9e6527e08e987a0a55d830ac9c2839b88cac22337e8847611403afc84444bc980f8942f0d447684770c5dc31e52a8be454417b11ff1b19779241f26075ae3148cbaffcaa99bcf701b4d44b45f3c32b08dd770d3eeb09aa333bc4920f1d0ee7eb3075b56f19ceffe28aebd30db7cd05329a1c0fe64b8ee5277fbb711d1f19e38556b50a188e8517312cb46a6cffc19ebc0ab44f5936b582d85c09edaba23fc7c9cefddd5c3be198178255b9e717bf4691f1f29fbcc36b05e881c649e0b62c197ce5db3b3d4549345094def473dfcc7cce4c16bf09873b0f81f6a0d103c81a360502d2b27fb91c728635db0b48ae538c872dbe3f0dfb42181ab84021bf620caff4ab721d19a7aebc22c9a264535aec87225e338ca691864fac901a6216ec46c4bdabeb5be691dcd034ffe12b42a0683f144abb1fb7fcef1063436df1bddd5857bcd733a9b090334471c372c2fc31b2e5b06f6a727b9c2a1ddf31d68be99df81492c4e11a68884928aa8ce8cebbb6d7fce0c14345b50e2cfcd7f25111153fe2b51a68580a77dac8911e87ed171f1a020eb12ab5dc0d396ac430111a396b9109108fa2b2d8e72efabf9404e7331556415f24bc41905b260c1d2c2c657925c64568bbfe880ff0be6819ad8e85d82258d17cbb54ba18a400035a76a25aa2efa58c409e65428d90a97b81df1d6cfb387bc17efffba235e5d37a164538b758f7e922acb6e4893f82e08303a992426a22968b7f23b2d67d094788854b29f7f52ba6e8f2135f5b36dbf30bdafd156ae9796b93c93a54e2ac09493a38e46c43fbdfd3a5985e604dc0b131feb3d02100f4f07ab3e1aa41bb17dc2d4ee9759f6bf31f1caad77f769868b39180d092ae394edbc5a82a7b55358e5366fc3d8de2bbb3a3391677ce4cb16d56d48a470ce4a205c7d00ee5872621375fbae8af3357d088c7946684130718f22b1cc8f8595863f3ba44e720f26f364cd63d54951ee0a7b5d40c9da617ff2da88bb27922a9cc5e354621240d4207c9fa685336e4a80bf68914249dedbb8b99170f54d9d2952901ca5131d7b4c113e80239b01e41991379bad0b9f579d492c408375f04a1885a1602779a058e99bb121f9223ad675c3429e0ef2a758944f3fb3ba9cd0017f363036315fb4ed75bc8a7d8e630ff8c394e6fb8fbc38583e38216ba261df27caa2b912347c18d84f14469a33f2b4eef6584718c8078d729404e719cef6c1fc24d90dc586dc268a9da7118b3c993ca91ae21f5390e11fbdf5cecd55d7d0ed80a20f47848968e62e9fedb386af6fb134f28840b68d0f4e8c6ac5c874a115771aab6422de83526fd1e1908ae644c69f3a0169e07ac88bf11d939b0ba7b03b12c1063c83e8e7437874c525ef36fc207b298c1ce59ce4f36682c7c59c4ead4ece02278283d249941a6ddf8505105eda35f020dc6398516a136f7b03296eb49ec75f8eb0fcea4b2de19fc2f9ee179eaf64af6a3a8cf438dae246afaf7b1bac5a893b1a0a781ba2bf150b390bc363a5fe6c616a7b3846dfb60087992c3d491fa8c264e8a05d17ee3061489893bac043e595a3a2eef7ef6c71af20f886d43ec5dc134d50befb07c864cd864c9bb2ca1852d67c46d0d355cd0f102667114d5f6a0d6ac5c0780c7c600cb3229253ce157a1ff9eef5f08847dd51a6d540581a2a9b14017d65467042d8d10c39a809b95ac07d1abbd32b6c2975c46ac3168c069391f12c587975ee12b4b952894031a823c81c8ec4a3323a83211f16ae2630e3eed0099f9c09428c989ba2b350e91daeb09e7df281dc49ca488512bf1a5c59cf1f61395d07c371c4467a7a0aace48cc4c7f8e303d5a413593b57a3c6bcd8e54c3eee90f8d64dbce3db2a61dc4b26755d8a7aafd8a3e5961e3ba6b4376ebe1f006446ca822e92e8cf682e1ba086d4a506e01ee851ed6529c1253e861496b16e44f7fce82100fff65d5314e6d71f6355849a3c216cb72e41d5db7bfb6dc340d2e159bf357f11549b3005513bb1777e4440a1c3ab2ab53b781ba0af347b66a01b20ffac2fac379d0cf5dcbdeb355963dffb133216610d94b1d742eec2c5a22165b8feff8f05214a2f2b9773c4f632c7ec3379a74da3ea2ef30c1f77fccb44ad602b9cc83e9d2336a42042586159fb724cd4075d23d915ff057249e75f84cadbfffb892389b4e1c2f48d19544c40d2f2bfb090d2596fec12214e93cf78c675565f9229d5eaf03351efef570a421706df9353cd3918e134321426f64fe23dc08669990ad42a404f39d717315bd18d25c71cacc1e98f90c2b1bd1f7c08908018d7bf605397fd2d5c923d51452784cb70a3b2d3faa1dbd273c5f0e56638fc04799af90729e21a03ed9e56bffa920d35744dc8ab8c56cb81ae6ce952dc29a27627ab3f8e129bf078154d6e2c8cfe0d8a62e6f968b39058d0a327add4bfa49b573c3e358a1b2b87c50e556fd57cd407240bdb00143f82085c3e3c2c0e33612b67fb0cd0380135b5ed2704d4b688025657347a79a58a75354d8f536da7dfbc7fd6f9e62a9a5cdf976a63a398afb9b9a2dfc9758631081b2225b294a3c3b70ad778bc5703e9229e180537c4ae91ccb4fbaf148679ed8a2442c0dd2fb6690f31110010bfad566ec0f1e54fb816afc128a65789a571595c39a28a4217c482fa0fc7f9d4ec54c1781ad944b86427d6171c510325360bf0b769933e3487f62d3a399241b3b24825f059205a12e77a4ab81d3465e89bd8090d72eec18c9f867454a60018713a7523c1f767d8bb6bfa2ac7645c56851ec26bc896f8be75cd83c9141fb6c5d1b80dc4843142a86c01d428f563d0a5a2ea9cac0c59d05c06477e1aac45c0f5db0d6e5bf1c82c83c710f4bf4f2f3683e88c904b24387794beef080809787084d77b163b0e78effa2270b3ea6185f0d3f7e97e7cef20d27b421ad11039d1a8851070c4793cf23cc3b4f2fc5279d2345fced198e2166696bbdaa995401d11b4765b679e72172a9ccb31462de8e3976a99bb5fecbff43399310d481da65cf200b9d3303ff515e6e202e5b508ac996f0d9ec9ca45569c707a9f85ed12a83f6c0db4bb43bdb998d767acfec64f79b77fd37c67953d48f0fd760f26e6f2cb66e428a32377c9a038ba78476e1dd23cf2ef0f745d5bfadd0c7a604c7fad4abfc87a2c8488484e8c8c244de2239e71a4128c3aa8e1b001f6e198ff7a54687c4f7b76f00d210249ccd0b32187701e477fb329880f9a7fe8eb9d13ff9e28e51d9c2c9df3103c82c71b1cc3324ee0e0032d2eed9aeb40989057f52a8cc115d3fb00032ae7cca9aeb6582bd91870e45403ab9e31ed66a414943ba7d38e6c01fc73f7686c69da3afbb185bdb2b688c4a6c8e5e9cc08d811dcde62d42b10faba8e8880f582efd59d51b649d233e6c13f9dc0d3ce4b15e0a3237abdfc4d2143881f3a2ccb308303dfa909f0528b1a96d8c15138b09d5978775896d5e3827e4e18c082eb85971864daf441c0459c56953b58033448cf01ca3ba1d6ac67653a5ae09cadce63daeef2cf152d622a0f380c6a0685550434bf0f4b8ed780269429874893102a3cb9c48726fc52cf9da09b4e4cd97ab49f2fa1412020952f3f6e7462cb796c292daeb23cda0f25e73109d5575302ce565ff113ec5bdb497f41bcc6f1bc6f9bfece0158be65a514ae822a6799c763a61943f1a3175498ad49eff154a52fbc2396d66d7ca0770048e2a5fd2d10b18cb0e9ebfb72daef4f9a38e1d57f2ea0b66aa53df1c53b64af900cc8da6780c04b1ecb69f537ce2b3f347f247bb13168e113597becd6404f4570ed477c4e201e4f631c71ddeb4a98d4b4ae0634d9bff8a193c463483f0229adb1cabc8b61f2c09fa03bf12e564f17407128f57f42094d663e6e5c03fef5e5a3e6351459ebfe5e98fd162f91cd016e715f70483d9ae43bbe2c39c394ef393de95bb7559719ce7c3e08ba0c529a2d580a23c505d49ef8f7e21012cab7d58ea50753733f85bfdb4f912d0ba0a0a1a23d91abbb4a47d19f9fcfb20bba3ce51e5aa10b7884b284895e1d15bc760479bb3eca81821eb8de785516b6be12e5a70aae453c71efbf6b2e124a5b5431a31b2b0657c194269e4b572153226c5e24f3774623190f8ed8828a0eaf3b96119815409d1a7eebc91d65f584b93b6cd64032d5318b1b289af75486d50be4bec0d0a3a3918deb3df0bf72acb7690a2bfee5db66fa941077d5a07b948247ca38961ee9ead5c519b5f144de2527466027a99f5d406725ba5d58f6f09cee16ec287ec79699e608f909dec10e0798f8b7b5e8892871c7cf7eea83015f2b02c17c3e7a9442871ac226c25964b8f338235951e328dd998b8ff3193defafe722e4920cf203b64214c567eba313cae5c7801b66eccd905dfe8ba5fa408ce80bc776b9dd72c3adc6f52cc5d93330da7439e0d9a26ec1374206380b0382394019ea4dbd6d66feab12e78299f851813315164d2dd00d316565e0f42512bda52e5399098b2aac293e36a3c4d7c6c1c016e3573cb97d5df68ade9ec5c2eb3f4d4432fdb2a3490fea6c843dbf13c435ae3cf81002534ca12b3eefc3c959b56ee66484ec3f5f8a00d3b07560b40de0b5eee32cdd25e06e0f955c8348fca46ecc4afb4212554056fd5c6a069c8af4d61b2bb261f409a0e29e0ea9239314ebe3cfd7a239463931f37bc011419fddf9ead32fba3cc7002b8067143bb594d2a9655ba412a2bb23ccdd531ad94c36bfbb0c58dbbbe20b1d6b00e14531cfb0f21ea37aa153d0caa923af25436b9c0f36b9cd8471d58cc4316c43713863fa8e62bc4fa88bb8ab82a904d2c61deb84dd3042d5c82d45d413d101b94cd1625a6dec75f12a8defc547e6bbcc558af06ef42b88a6c17ca452fdcf67f688930129a3923513462681392c568b18e3c82dc2a50808b973965a8a9e66e99c191d15d34ae802f3dcabbe05974faad8887d9dfb1ad603d8d77c3c43dbf2ddfeb381649bb1367eed6752c2375e4bd597432b0f5e7e2231d67f2b8996a9ffe24476dba12549b1568a8aaf3ca0c4973b77596d941d3e27fc47e4d163503ba8ab7098860ad24f2c5e0878144c2f242a58614332a4b6d656fbfb08c39bc6a7a2cc7dc497ad4a2f8a850ab16e7067a218a3734e17952669aad855d18fce5acbd83ab0050f1d9aa2109376c26d78e32310db911dcc30a48eb7faee2e7e2e29e0ab21cf6e8b5a2cb5e922582d127826d5d9fe3b97b34710adacb233b9f6d8b64825afdaa1e728352dc10c4fa8e2ad066db4bd355cb0730bbb87721ddeb3a8173345b2141d65d404e4332fc6bca5e623ec6d5bd5404fa42a086c2627c1254289180d3a1de6602349bc786c2d245748858913712aa1f0343b7ede805060a7cfb77c247a1d82957127d84c12651ba0fed4945fb82ae41a790fdbb0ddbf4d76fa11ff58c1bf6ad889ba7a1c8085357d25bda65148b627fd50523ca6d701a4728ce01b418636689b98ece555d2cc55b06f363d6c4af440007e28c2262b6347868fc4a43130ce1127c56ffa62e2410f488362c5724a4c05b91a6c5de0308ee41cf1e22a45c5db470292da893dfcd35fad1a9c9ac42c0efef8032e4c7fa04d32215c40a7b8546e5fc91db144e6c8ee673775b98e3d84411ef0bde8508897cebb6aed5900bd7d8b33e9a66da39d361a4e2e7af3f9519ffd7191765596016384efbeca2c873ca7557e1d1da1a8343548fbacc3966512d6a0b079ed13c47e622ff48d26294c2a0cd6e92902fdb408600194b26c87bbc55e138aaaa26212bce026ff4e993d3fe324ce15720a3561e0cb4f6d5239fb64e650a995577e828f0c8081bd4636a868cacf6590aab0d261fc43230a2be58c620d38010a866ff49ff1cb50b016cae6058a5d0d35e3c8db2bd4a2f39560f970624f39507b407c0d38143130f919924857fa111fd23b9ab0bf88a299b18efa30d8ffa6d24dc24b745fc008036c4b288ed15e48762f438a1f2e67e45be679e34b172a653ec32b1787feb154c5e32e470fe438d96b0c1c6997c952ffcebc52486c98d3685dee26dd44dffd7a315577ba20c0e0d131681f20922fee9257646e7ce377bd783fcd7444eac7fe271aca18a2ddf3e7943584f0f21f251d217f8cff2d7b5d8fe6f101f6efdd832fecc7e621a2124852b27fa41a143723d67127513491084fbac116ee13fe904861a6261e22ed19dd5f0d562401c1b054b3e8c11be488cb37e5da4bdd5105a804c86e12e05b017564e8866bb98afb4c8d2ac55a74d7bc9874ea674e58458224bfa34fe54a149d78250789f6576b2c123d73e2ed3ac4878c2418523863049262ac072330b7a6c7ec82b45708c5d01ea7905dd7b0cf14254fc0208f907db926ecea3a589f1415d5569c0f3b8a3d1030260abd4fbcf680cbc852178868b6757b56f4bd833475641a0ef92e6ee97a49d239585875e9bdb1b2865822b0b20e961c4796b1af8f82c634b01e5e0f73a0e00bc3e99491e6d1a5ca54084cec712223b593e733538ce0b1254df71e2a569b6a7f614811ae9a7221ac696ce5f167c67fd80c379094fe424d3952225add8c53f585db15782cd30139ff1f7954dd8fb01b221505c6b540e3e5b9a7c5a730630ee0297532dafcfb67dec95a8607a74f838da9a72b741eff14ae74f8954f362c3173bf5849014b372ae57789abf277bc296627bb563b1db97820e59b55e4f34dce4dc43238de91967fc2114973c010b38f0e12b64569c9e18e77485c9ccbc4ce0b32ec591d12e08db9708012ba2438eebfdea32e0d21f2c0f575888be041d5c8b29fcccd0a6d3a1e43ad93862cec06a040feb518b99660c2870609359df052cb416752028918ab693c2ffbf52f12c4d90e014cd3292c303bc4ef8ca4f8facf1e63965dd0d621ebcae3afa274c4e963310c461704e1a18203be7375ff15305c205852ec2f37cbefe2c5a488a9cb653b0fd56828a29281f5b20e4cc84d30dcf183fdc2d6aa5afb05192741fb7318f319ffdc4697a6f39b543413bd2ba19a42e513526df35f61f613b48cc7f227c2ff390c5f70fcc2388cd17807462180b4afbf60eec366afde07f70a2e3387ff0e24a101fa7bf3e912c4f84963ff59c8e2066dad54418f107b961b5aa944522977ddd932ce9f927f959331ab91ebe13ae8e6cf7544cad93cd7820bc4898403f9b483967a4eccfaa0d54226968a0ecfc874ea70ec6363f1b961712c53767bdffd49f4e892e4a7efd67ecd83c9c2e64054318012e421aebbfc75a00331a5384375d0ff1e50ac11cdcb161deb0ef6154d8c492e7be2dc22969fcbcf61b08d266bd205833b41d3d79d9a4895cc8742702f1cb6994da88a103b8887d78ac1eb462bf6e15f69f91f9666be1649ea11e828d2d1d20e4457a0ebdbd8f35ff5abc95fed2acd506c86760d2503094d5d760ddc4b3f11f8ea4d5719cd541f4089cc423dc1209a148baec840727ac5a1322c57c0d452bb413d20d065d5bf5acd4eb3751a22b5fd54809295c493c0e8326feac93675b66b9611d0d8f1fcc8956107bcb7763d3b98b8b058d52179d6d397dfbed4adf6979934745f645d89341b904f3cce33e0fcd889c4fedae06dbdf54b8487774f45742ad4c92a380354715422d61885b8a4f4d401aed1c58fde7f19d4dca9291a9bb37aa5eb5aac38c265bf6a502fb51a1cccf0a2090b5e5d12f9a8a75cc39a8f493fd16e2d09278cf618b87a150a2032c014c26c9243338d2ee7a33eed78566c5e67a154335535b03ec9277b7fa49cc5c625ed6094d7392d5f3e3bdf157318158497fdc86d3a0f66efe837c187f19bb372c98fad603097818b94b59f9f0d926364b1c8d27e8781242be50f11838244e512f3a5c5b88164881168ea264762e6e42088c0c42a204a5c7b2391af512cbedd72a666bc4c7bcee7d2d4d4bb230575287ebbbb25128a3a2ec55e1f157893f2377e5e35ad6640d574c69bc40d0cad0a02ec7f9a2d2e1d59ed442bf89582246ea9120169ba9f6bb0c8cd2a7a21b097972575329106e7c23f60c44e724177888ff8b5257ddccebff00fa6d309be65402f04f05fe833c2b3e62d63d5861c5ba56a0e98d42d37ef0cdc3efb847c3004a5e13850dd5a47b34fd465365aa10edf9662ec97f0827dbec800b5322747813de8d7b273b0b65b6096c74de9ca33bf0977074b7fa8d897c3a1b5cd895d6d0918b40b864d32b9b48b427914a26a27f1332b40eb57099cc288611d6722f9b00cda2c33e98a07146e40360723c94f4bc205dfd7a5b658d8cb6029b93103137d9c374a751b55d9b7961ed754a4004ce914cdc7e4bbfd08f5ec218230ef9d684984e8dee389d60418d6e04ffb4f4edc34fd99ca18a5b9a7a585603331c1e3dcb1671fb08bbe999cd521fe60df0fe86cd3cc1128c9648127b80b011a65d35b6cfc4109652a37580196afa89145149199ed52f651f0d82f6a56e6156e5ec82ecabfffa5d7ddb1824850f16ae052331dfc5ff1f11497580332c36602b7f34b93e0eaeef40c8da434dac9cca6ef0eb7ebe2d871dc6f9d6c8f239c01220aba7cb610b01fed6ca8814cea30f7b9a48ee7dd55a98e6da0658b0c18d0f9da5c672e5dd5100611ffbce12e63f02b34d64cd40c5437fe3c7a7dff63efc0171027ff2bd44d7205db89f626a5dc0cc65dc3ac25d19ee8a69485410b17516c4392cf458afd8111f880f43420abc7fcf64ded4e6c8e14a2ccdce0de3393ebef5c3d262bc3fe5d6228b7bcd03408f695b7ddb0b1adf3b6ab38ce61e43874e43b66b70961b1b7962edf7f516687c070025b2d3d4c71d2bce9e8598596119a46024a95f4a4a9c38be2804091a7abd8887568c8c9cf0b1736e837b1df1b9f1ccefa201227043b0e055abbbdf1f6f6b3080c1c767abc3e2b99109b887631e3f00c96e8cc19df758ec5a677c5994f69ff62959212a95642f79c32ca8ddcc82724486da0651269e92b8efb5493ed9e59267393d0539967ce214def2e9dbcf2ce57551666c4ac9f89d9194201226374cf4d05978b18ecf99c1c4d5935aebd1923731fc839bcf18695f2204d5a461ecaf12b4465c8066e9341da9a82a2d2df7d381bf56de82a8109b8d30c26f347b59bcedf54a1e633207e054eae6316e1da250b411707f324db9c7a04bf84f4356ee230951c1527e2ce3e0ebd0d210c0e42f7a63f29707c1ed45978b8424e03d9c2c9e7f520983dd65f9bb0dac70ca943c20ed376ef0460cc8af3c748aba944c6f9bcf06d80faf4a7756ce991acb4aecb4a2c41a3cead3d3c64764f358c96a6ebc15dd400841c5f798ac15b065f3790ed61667a13405d27ac723d1f5909c09bf96c9378e81afc6e852ce5eecd8feeab64b3515324fce3445c75cdccf5d96230613735c1846b06f3a04bfb7b028a69e25755144c08a7593527e28b8c224e23ff23b968e2e0a3a322b2519072dbc0601eff5b10ea89fee800485e31633dfc593d2fa1c772133de5cea0449e0bb54e764ada2f9ce6371cabfba7931bc3adeb861fa8f4d1296e0e57df2d99d851de389d2a7e9cacbc0a5c3ffbe26592bfd353f49a4ed739a9d6a9a17f6441f0919589641a94650ebc22a17ffa896e2c7988eb1ed9246684bb364341c0bd5f6a06c9ed5c903f9b1cbf52ac5ac0d50c656038212ecbe8f1b7cfa05726158f46b86df3f7be79008d01a931b26591c8840dd03f8358b244e6a8aa9d2b065d99114ccdc01a1f850f79a45dcd88279a22670633bf0bb0d91d898c2e181c02e446bd4ee327b32cc4dc085749ae80fadcd2202f063627964b3f54bdea8d4be124b2c2a0ed86af2d2974669f1cf613d59bdb540287e182a47b377ed68d58a22b0d9eca2a52d469a5966b2fb4f945af305402f49554236603e1c0111f5c22d11478b02dc20411299c0d3eba89822d255878ede0071bf9b29bad7c18b168fada5d95951bfc8f2f82ce977088d5dd0661fb3cbd8378442b5c6d00110ef31fe6d8171bee4600c2a5e8175821ca6c21f46fc536c277d07c4b006a162b74d6b9af3ac9fa50bfaed4b93a7feaaca67910c569ff84e6b564ee81f64a89fe891d5d86de94cdcb565feae76d4f92508fbb6dff9bbc0d6dfe1203bae401a306f8f370571f29da8b5b7275d2620065ea045c35858b7e50f94e34c83cde39a262504cafb3c9055ec9d048a2c20e4c0d8663a5e4a56860df9a1fe6360be19e0d84bf539d77e87ce304cbcd4db35bf5f1c1a5f44885190fb6839edff733419d7e9587aa2440165af5c83a21937d273b8de3458ca04630d27daf48d5f67d6b60f46221548365706d07867c6ef0645d1897622887a5e2806d27e24fbb8b44985e0181169aa3dd5ea0162f560e0ef64663acefae735cff5797de15505f8dc12a53aeb58bd25fba7e04a5b5b9770d61a3c48fdeb1baecf713245b2551d9c15df7f8b6ab8baf7d6a320c50c34cfc4a433ded48a7758acf7b533b605678d554b5710fd800223557c75d1eb1b2c188c263bbb0b376cb0ef3a456153129350bfbec6763565fc0b47fbf545b619c40c49a494ef8643ae995826d6d1802c65508eb61878d90b7b33a88063b4b74b5f4752ae7e564ad5880d49504a0b4756b2ae9b99b9a5eda041f7173b635a33b80482b649499ea0fe680c4065499d62f922151f811e0330bc829afb4c1169cbc947b1ffe888290d1e517ba3ed1001ac228ca8f0d81dddf6a24c10f1b139b865f84d2a88e97d1f849bc70a3c4d59283ca2ba96ad44c7a0c49841736668ea9aeafc4441384ba795cfad844655b61537a469eb3ccbc4283e3cf080f852bdcf0d6c6f83103b6fd6e5e02e66eddc27c44f1f0a1b621ae6cbde3a3758dd3785c7323774b9bb706858e6ea9b21bc597b9a5525542f643d40f934330c3655d1c34185f538f994520689837e8bb8ccebfbd0482ce2578777d66b6f41270a90fc8d720d294f3c0ac639c31038db1279c72447e45c42851b64ed218c5ebf4cb8a2cfc64ff24ad4c3372d45f2921e0ccff0906b4eee97f9e5e8e59b2d59e45456d6adcb76da550d1583494410a9dae84f4dd9e38a3479fe7f5dd00cd232612b5f82b4c04c3c139d48059afac5e3f2617b1511a6fb1faff9ed97fdd5ca75ab4a2b7f932bdd674b42fb2d3b0cd4000a8d7b037932402a29cbe31aa0d59ea06643e8b502fd29826d87584d0c8f617f74ebcaeba86c98c50eb59653bacb849e3feeea52d15f3db8793fa6aa3adf31a66552eb549d72dc3a782dbc819b4ba517274f1c6d366a0c4dbba6cd5c9c8667b66a914b6a8d74b2b057cb6f739ef4ed126918dfa752a1f6985c69824562f7179575af1991c8ee46b9beca25afa2d3b168c3b9d056f418531346200486148d94375a767b10ba242e7d2e06ab0248899788fb729810be9f3c962ebca2cb2815d22c826715a7d5995b6c98619e6605893d2b5a617290773419eca13b91a6f63a208d6687ffa5b4abb85ed7d573aadf9193a24148b299ed6f86f6ffb37becbe90148166f843feab4f1e0111011266a998fc92407103b5e54be044abb30c3d83889d4cc65229f4eaae0e7379cb5ee5a864e9e52ecfc97a86cbf56c53db238e5ca6f2b05e555632506cb7c359e0575b7a85708bf1da880a4d6f067aa976a331f4a7da33d579e225c4ae4880ed55166b04c0e87c9d43cdaafb69e225be820dc05d9e18f793cfceaf0ca700cb5750068b72a4367fd109eefb1f87c4cfe82016669e2a0dd8dfaac54462382ea0b332067546868f97025c7dc32c20ae18aea541ec708df76690d51920e6b279d7c15115f6793031dba82b5c02fcc595e59640cde01bd6b538233ab77279bbf775761e4b76532d817d8764fedb71cff97f3924bc03123ea4b12a4bfe05962f06d126df5aee897988cc655cd63497069349e0ac2cc2a3afc21f374af3de7913c5b6d913f1a1bfc3d7c33cc48c193e600576340617271fb343ef09f6693d6d25e3b27dc053332325f56dcb2953e0d40aaf4cd4c4b961d87164b78c304fade70630f74413a913e1f7e1be6a5d1f1de31015a467e7676d0413c481460668e0d3a3333db42556bcaa7443c93f7101633eaaa4f4eafc1ed868dc138204924c8627ee2d547db1e5fb020ee43b5e9363d5ceb8afd60706c05ce6f771877d3bf2431866346408070f680dc012c1890fadabda15fc51a0bf7e10924f7d3003a6d3cffd9793733814cfc26550988e54f6a99c41843dd3c01efdfe5172daa865bc61e7a8cc0379fb6fa6f0850a662b31b9ade72541e76a0408b7fb32f1dded640b1c1e661ead73627cfc079a22051846764463b6d9b5cfec2d55fbf9d69e8ee132b170fc38923f8c3c4314f3d143402109329c524d046506ec135c776aab44da9e8ab461fb4c1826f9d931a7c858b7d7fb9b6890bf54199e70c8516aafdb9c7c01f1e1cdbc7d528467985609e6f05885d29883bc0590db659c59f51c443d4a25abf2cfb815fd87f9394c09914fa70607c35e49b01da9eb7f804049227fa8107c4b75a0cd9096b8c5a258af624d52ba851d90b69d1faeee35d5d94c32b3cb6a028bb69028b49b1f24a03072cf723e81cce0401335169552912c4c9a84ad98be22799655ab2a161b67d76dbbf046f3e5fafcb122a5cc5e86ff55de911ed08700232c2e26437517a3bbef02d7bf5cc295f76f7545f2b2efe68e31f3f76fcd7f74ced1de56d2e252cb0d371403b0b8225ce770b11d257ffde4871f12e1d34488f56358a7d34d9978f74b1412d20b1fce207de6632becc7267867946b16541af4c6c9f135029b8ba516ddc5c348fef618ec8383eeed9f91ac44219e1486fd55236fa3bbca0fdce13ad16c094ec37e3fc180294c44f3011f94bcd8cf5376f9cbc7e001b182fd40376e254b50271e8135622b8177c9c0983d700cd3fe6ed21ff9fcbdf0ce855da0e9f212290bfe132c9287d2e77c44dfcaf00a9532a41a066836533c20166953a63665f2d12e302053f46bd171e6a4df42393b890d4d14f0e4fe34cf6cda726198de88f2817a44faede8c29d8ef93ccdd94904b8518d64ca69d9c991aa750d34686a79b97ee696556a6f8b4386dd24466743f3c36a5eab20ae4c28ae43a9f7e20747fb6584d67c341c9be93764ec7e3ce3418efe08bcea8709edeed284d68a95a90c9e206055a03619f763521e3a38ff710dc1280dbaf6f1a8b6058cdc7402bbf3f2502007da5468e157d801e590817d85b5f4524c14103e9888c3aa5c1a4fe753ab4bd58740f6931dfd83cb88bbd362fd9855db97a4699f7071ae496fda17e6648059ffcb9b188021f024bedf4b4737b3a12b1b8760c7c464c2623ab17cf0c0539cd08e75e6a58a0ee8ec8f8dfbf2f7b97ead5ce17ea8ae3f99269f57932a111263760db6f3adb12afb3de0e545a6c4dadd722ca2f9c26f098f9c87fd110c51eb275330312a8bebbdf4847ebdde148022d3cbeffe04867fbb1c0bf345ab1737b3b3b21531644071b87e45b9ee5cfc95dc6893a12c070a410fc00579cfbc2a6bfaa4a0cc8e87eb975b7ec3d578520842c8b7b119cb24a1baa442b1d57d225125e374b173dda682110d66d33a024c5febd9dd387b40da27e47f8e66ea8fc97e85b08f6b5ee15ad5836faa8b7a16fd06b4093c93cf6f08c7769f9581bf6bf32ae9d8d3b1725e10c410c0465896581e34461c3294ef71371d2cadc43b5355316a11325864667ec5f8b4db8bf2e9f41cc91be6dcc3cd2b9a4bc5f004078f4755b579ee289c75eb5f734109b6d34f0800b4e123926b30da3c0b3f3b0af35b3d7fd1b0b3254c79d5098e385c178968a0070d2d7e33b275cf4d85bf4325fbcf45e8e5da0c8645e2621892ed7e720472b9a86d919644e4f5ee9d3c694d5b15137a4ee364da0b4332b449a827065e36d496eaea5b0d9bd1b455e2938054a224f28103f8b92f4f042ec7a01a7ab68b781923c73f835e1ff302b81634aa0c4323648ad68723ae3fecbf6b84a2c092976f5bfabb7447072fba68b3f6fdd9780a6df8c1512651af9a0388d29131f67ff7cd957d16ad985871652ee1bf63b7aa3016d716074093f529d609fae7ee8656819876d1db65677c27dfe239295649f698027cc6a83ac50e33d3c26ecef5ab01dd95d1224b14a56d0078f96c7484a4987282f1093e938eb0c996eb1729295ead45a4aaa3624b27f69e249b8f9ac44f47f9fc167c1d442bf2fc6198159a9e304ca9208e2bb259dd588ec41034496e2cf0aeb67652a5a68b5d29a719dd3735d6f2da10d2111fdb9ec45805d411494beb28bc95c0d45374c2b0ab695a99d20f73e2551c72f04ae8fe5ef989214a8f115bc7f178abd39ae8553e4ddf4e2674f3c9344db0fc2375fadf6425df0b57920d2682407721efc9d01e2c74fa1421642e76e92c5886b542cd57d44da678aa8a59d3b021e0d0bd07e11f0e6d6b042152099ca48e28a50a19b374415b89aebfea56c0d4a991004ce9cb3cb8615067537401f2f612f5b6c5e97a68f83be540deda478eb0005331efa3fd90fe8f84574d674ecf48a235ff83e932cdd7559c92c5c77ca2b768dfe8565fbc6829f13cc93a613b3f15d080f3471ca43ed720c404fc82cc240534532c19011fe15da057cc686953fbf7962ddb057717b6aa3ad9788037c90e0d3a35ed6a5e5dbff16adbb590f259f7576e509a87b1bc4f488da9fd6b8ad53839059032b1006176fcfb84610538475f336c9c843ec7ecc9433ab6ec2b868a7b583923d9851ac01a3f6233f481cbb23b461914c6e706aea05394d4cc4ac025dc81874098c7bab84fa844ba4c17c5c1c99507a4b5bb24633373cb70490cb69b957ee1b5c65488abced2538cb73fd5b02292a34a9ffb36acaade790ef5080f5040542b6ba61872ae294aa1d9b99d9ef3c6a218d8660470d2e86e510798a76bde792bba6ffce200acf837e9fe1785cee40731df7bd9ad030182dcbd55791a1ac4e297abe012e51f183968d9809bc31f2814dc20a1d717a75e8744faa272dd7d4d57bb17e35d2ac155118c574f00b0ce8613f73aae76f43425ed8e2a18589a718affc5c7625ae6d8057f22d3f699abd7ab3619fb3d34d71a8626377262905ec6f86c40dff6ec5402179b50a26e38bc0609980ecc945e50dd3edb9e8faeee54f2f7e902287bb7e3a35ff59731a35b34615891cc716d800b01eb6a9b4420bae9bdbde88ff46ab536af6ff2e3fc6f7d2c77c5dc6d73dd018494f280894615555e2bde7cf98e4a2d6ed87f574bb6af4de8dedb8d4853ecc71c816267e987000ef468e61e4b2f50ba4bf484b74074886310b33101f2badd7db4ba56b2b95d9cb53b7397286068f941f5c5d961f28ee2530e712bee537c15de6c775f110962b273528a1e44d0aede4f7c3ec218a6b9ea20334f8e9d2c415149f8ddb5964721154b9a6e649ec58302f511030ab7d95b24f0669b6f09d3921332521d3075f2db18d9a99e2f719e31eff863d98a45aedb2a7cb693a915137d1696e8ab3a9da20678eef3f623e8edd5aa6c490b1c8c590473252681eb0e8008f8571f4592ae14b6842edda544c9f073e40b56556eaad1795423334bdd206707a795dff4b4c776078423ebca318c65f45fe6006316a4079fc5f9ad38849b4c01e018334adcc3f319d1357670a0272ca0f181c53acf5d8c1e1cdb8518e131321595a95e64b3a8ce0d132821f5d09be94cb4242672418eb6270874a362013d1f5753a930c75637a81ca23cc6c6d2c1ad5b4e101602b2fecb735b2fdf69a5d1302a9f92bde3e858a9e6890f793d72d66e806fab25408e6766b1f2e9a1b8715ced14fc49cbfa1a67ed94cb431e8fa61b9871ab219dc0069b20c5f2249b1572e1ccde08d15e5855961b3bf92b5a506fd6661135214b0f7caa5f766ac06b43d926ba17f19ff4e39b7447120a65fd23ab42242772d55b3d6ec7a65e10fb356c0590cbae6a49407752cdfd21a7584ccf433d54bd19b18dfeeaca8d02656cd178d3798e3c4cd119830b1bc9cf4b7bb1085c432f10ea5d790ddfc67db38f086a299057a43e0a6591c85e04271acc1bb9c4f09fc922b8498ba5b7f69d15f678445d824da798f2797c00028c496c836804bc3d84522fd3af1a43915b519742738b1c1be43d8f20fb455f3ffd86147bf1d5c07e844d03c08901bd3abde6691effbf5338c13dd166564f2a7aaf4afd04555792be919874cce1e4b01fc111be49af88e2b18a614b88acc80f94c8dc7ede6be06d99fc1c489497c98edc5038041191007f60d1a5508c5b77272767d53cd0096018d2a8ccbbd032680fd95930428c24f2e9bd73d9894562a8b9b2aa97069fc9ea28f5cd1596f0349cf131827a45a71abfa91d7814f936c07e7863d95ea4350e068b33020189befed7520a613e48fc1531e093b9c1c06a96492f05b1c50e9590dca716247a05a5ba2cb45507e7ae6f4c0b7a912cbe4b0b5c66d2c1c115245e0df4a34522aaaa7d619f31d3448c4dc8d7051c6e7c29bd4aaf04eb685a284d9815b1d1e0f1a24b26b0dbe4412685793d9c9f8be7098f602997edcb951eec6d1fdcec7d82e8642afed6ceaf8266925fb90dac8e62c17ca0b490947b23f1fd286f43fcaccf7ed97b0975d55071f514e91cfedc74dc444666c9bc64c785b2305fc02bef9ac29de6817b9e8d04a4dcaa575cb02340e5b2cdb232c2660638596fac65d35423eb2e37a5004754c54a888b7f34cda322f95ce6527b26d77037edab5bf08e31d1a1085cdce1bc11689a0b77d300e434a31565227a62c23086fb095aa0884092ac76a381439ebb80568c1d96ddd7fce7c0b7781ebe451d3bd2fe8b19a8157ffc8636b242823fa3c43af549c3bf83bb9a4db82ca92683f25096527eb6b5bc41fae4a9673168d4f17d58b8935adefca432ad62b87cc566e82ae66e830d889881b1b462fc9a289109c775d226a8fd8f163b2ff3a351bb891d2a19b09bbc852c4de2b52bc7fd68d8f9594466c4054136e2c99e636be57c7c91fdc3b3ae29794c35df0f77e59fcfe58d7c6e2960872a2e9039ceca6c8faed0bc4f3cd5c48dc88cf37ffa9ac1eedb88fcd7b799b1e5b9c35427cdfbd4a521624311b45ce51add6f21d861c981c9d36225107fc10f70a88dcc0e2d1461a5e31c0d1722a6692c8394343bec0afc5149e38df180f9d858a3e666956154291635b929a73d5d901ad493bc6e184ce24693924c4eb475a005f2eb0045550055d90c4119f7f7b2b9fda3731aafddf472015cd959d68f3f7c2ba88fbdb7e2adeb502639327a45a36a2b001a45d5fbdf431cfaf5bb220e998ed6a7b36c429dc3be46a987e4b66c35e6588ab1fc539bfd972ddc80cde5ff1c49c75976841828b792e30d1d172251ce8ed131003ba133532d431a3dc8d09d5ba0b3d98f2cb0ac2db5769b9019e754941ceca7959387ac13f591c83769b4ea52cbf4ea2e48727ade9a1d322da4e96b6f9d3405a88faea1df9eaf986b9d92c6fa48b92718411f4bc1da471c619a2c37d4a99eb440e366b3384e7b0119c4637c68cf87c6ad755123e73d751f5875c4551ef2f2965d7f2a61ccd1ceb471fcb5a306870505574d3d36c3407864fe5d1d25d1beb33207c22ec61294b7cf214d17c3d06ad1d12ca7e803838749030e938e2f41ae26d2b3a71fb5a709660ce4d917deccd1339ae19d9ef3ca98aa29959c0221ee82ea78aef550cdac058f8b79804ccc9502dec541908204034b0f7067a2a724fc36d695440d3a83cca2757b859b84bf13623d8e0907c484f72e17d55e82d42f301aa336d7b61a7ca56033fc6ac03ad71a89487e749791cc7a6f8aacad3d9b9caf77ac5289c409f8be338bb670b3e63c0af84467d2f736f51940ae1e0a25ee4f7c94ce5d775c102ecc8e9fb6a869af23065e5c0722b417eac90b77f36b6c5bece235f2387fceb9e6d36138a859e8f39d062986d05f6c1d92af148f142281bb60f1b9c584a30312167aa3949232969445f45b63267e6f7347d9cfbc91ba38e1080d9a3401f3898d632d2c001a229a00e12c04744d51f50bdddda5f55dfea3cf91cc0ef54be81ae4bfe78342ab2ab39ade610ca08050970d61dbe3d0ec133c3aaab7c314cb65ccc87ec2bb5452acfe34a801e194934d616da12f672d0143d54bf96a1db50d53c0d3e1250d0f3a20b11247b8c0081d7f23b7eca79be6ea564e67416166f6adaa33b32505a09c54694b993dece1755c833a471b09617ea9e6edbb6c0235e6fb642052c66ce63b41d024b1426a054963193a7b43a10c0ca3ca76f5ba6bf588451423e843b9072543ff27ff168b88a30c1ae1e5dba4455427566efa5e6057b031b1e820569f65a378275dc0c7b1be55ed06ceef30e2679450ccc1acd8fc9bf5347ff3b81a785982255dc9379252f551f80ef7451e16b6a9a1fd25803ac8e0d7811c213d04086ed9bdba32d0e014bee8265eece99f1a568f45b541194cb25d161cff54df0db56f30e1c35e7129695b54642584b7424c385b61bbf98da4673f23912d3f709771f2c6168c231220227559916fc106efd06f1acf425e1a3b9cbabb9db84d9ca784e9a6ca7899edca6fbb79010cc2bc498b9a160168680a1e916ea91bd6b7690ab0875b7f1ed3f8ca5a9575c332baa975e52efadbb2d035edd74727fa1318cf28ad18170c3961a7ebf66e0c86025413d67f5843484eaababb73bc224b97055aed1bb2d1c1cbed59c5e382164cb6670eb35a133d0d48d23575f31d57974bdf02d0d5731dbdbc2118a990bf5e0165a4c54ab6f11d8e971c0992b3a4965c316e19a938f7cf6a068f6db23bcd3fd10ebbedea4594759243625385481b9900dda7e04ca31fe22db714a05de494ab9eb2774314975b9bc40257db3bc5ad1e1cf6c53aef33e383d2bd28733cb3875d8d3dc94a1cc3923d1b93e910e8b3d9d7ddff19447038e567fb4ef698bc370e0d00afe4a54d6b939e6088f6359f597983e8a07c942e2a0243c59a156b952f5351bcedbf910ffc4da440287f3b4f61754205c9b193fdee41795a29432ab15d14188a592519416161b676065c03c33a941dd4a093ad6a2b1d0b09b108efa4fec3f46c260277d56ed5aca1dc80875b7827ededb6485deff230e0313aa580f1e10868bc08ef50af7b17e09d77872936f06f49b88622690a637a3407ec10e7b3f1a09bd8863bf8e57a2064422ea8b891edfe05e131b6711dc682651bb1b90ea540c993697b20f066e63b0d2b5488329609931f6415b244456727bb24d5be25270bdebaee75aebb8ce82360c37d4a537c106c01bdb84354b484efa3e5233ab0f6b02656472f85a8b7eae8581881a8ead6078f061ee0073daccd1c9e910fa99725b1a51088469f968b41b60eabdeeb6d1e66b91c4a5dfb8554449ec4dc62d3192ec82ad69b1d50b4cc3ecd5e7e32165c2a1f6a037c681a88ac94bce5995e80a2503f07f254dd8423121c540bd55c1de280a2095b0f1b8e1fd79e744ff6282b808cd8cf7f74218e910742222e510977bea88d3ae5b4fe575e004dcd65aaef199ce5f9b4fc6053c76d938a44825d94ca389e38d05ef0d8e903614712ae696a7481e308a36006a9f608585e9791f3a5a5d5c7938c64cd2bbc99ebb0095f9fa4eac1921bf242a359ca20f9354fb8318c9c82d160bc06494a7c5a9d44dc289cc2dca6695a05ddaf9f71d069246a9b543d3969beac260a87b5ea751286f485d2eec1fc499dca75817abae64fa2d3d97cf49129289f87eccc8db135a8cee3f672931968c12553fe6b14a2d535b866a9acf7d331d89f0e4f0ba486fdcaa72d69328ec88a89d893cd31e11e17cea9ea634a3ce539121fcfbab4188178dc2335d2ba7f9c3dc82244dd715f80bba3643973e1eb10e9e491692a225d986ea01710b348cfc4906e002b363aadc2b738e85a8d559892329297babb323f516f5d2bcac15febc141098314f6ccbc9144926258dee156ad290565d2380533c03e124cacfc22c5aa1a7169caccf11084396b203873e8e37503e530079c9f3f180a671f6d3908fc51a1f2b1c2db1ebecb4dd779364e0685f7f75a13107eed1eca309ba956200cae32ecabe944db9b7bc2773a159f0db7351df205bf5d9d0273d03d500a16112380afbfea4d9db864bc59f7fe0b6cd1264887a12ade34d74f41a80694094fd464d869e01b5cd9dde626f951b6047b4a7e19a971a4ea8b355254b4fa3f89f03beb4dec94958b83fa6817db96b561caaed1f40686985964b9114c53cfef36f3a15f51d0be4d831bad07baebda0c2c3b75835ba74d2520e1c66a1788dde49ffdf2f9b9e0d3272a530cd71af65c002641cc4f4c2f5872466c4f985f7027779921edda87e90a9cac200de1c1350493426374cb36f0187c2b5f5a652ac0c5ab7f59fe2110a222db8d54bdb2e9569e3d16301f627c9fbf8e7e384821f2c3a19eae8e861568f0b222699c6b8fb33f028b549640de3d093e900621fe9554afe97676b6b62b1ad2f9d5184fd254b3a8343834750f37e699b87c6e287093b6378eade39165a671a6735e12276985ea1268eec58e1503e30ba5051b9f2f991aeafc91ad8e6fc32294ece34bcb4b6e432c1541fa1fe1c1aad39326876ec187ac044c5180bbfd6c48e45b090d8475a7e78ea4f3e95b1ac26e0ad25c0367f72d80f0162d7049ebac04c75d656c06298d1938dfc559c05da5610e101ba5f74d1268773c24ce92d03aaf1743169efe55a29541d15f7f51a9b3ea0e548b7873380114d766a980c3e969a3973083d9b45c48b55306d7c715be9d2c8c934eea43f80543bfbb466c7e46381dc37062e158a1f3edd6f7e7afa53aaa58f75ed7c93965641f2be3661eddc1d04dd11582e38861a5567c88550152e75f09cd173c42ebdb619419ac3a9aa1a454422804d4972574dc7dc3c955ff07cbd45a72812c45cafc18b392a23a71b401240fe4d8eee2d28f136149b7eafbbec3ed1906367f6e754b67b6d2989f08bed72c88e6f77cdcd5442423c0c3f6a66ddf887df2bfee446e43863439ef0d6dc3b3b9e5596640fdddb83a32cea4c1854347d96bd35c9f093cd3934d3f1eb8df2739002442120b00945f206fe5edea85b8bf2f7350cf125056e7031252c69c578108e6d3374fcefd8e56e63dda77ab8139317c72502f7841918c3bf02665bb498bedaa2c424850276ce80120061904f46d989e47ad4a80f2a2b79e5be236101f3570a2b2a4c782bde2b5d7525abb1c174d94aaa78f6e816372c13a65445171f23dc2a83792464ff6f2a88eef2f7ef7131a7e930b57bcd58633bf1adf9de391602e4c497ac57b640d84e1d98e6995dc97e664356a2648a41a57372b5848288d5dad92656d3ec9660c26a9f99e20e39d26e34b0a638ef3741c16360ae6d10f3bbffac68664d345a207c01e074996025aa6ae154ae8738007f8140afa6fa2403e4e8f13afc68c4e87078f2fdf0f5d3bf08019b7c83d97b83531720e2727394893b325235b05f28781a13b778e6f092842793d1482030cea0e3fbf76ad0ba4c6755f6d4c7dff8521b39e64ec6507ba016c60ef709d9720ae73dd8dcdc002b7e8c3a9690043544374af3262731e5c123ffe97ea7600c2c01ed6457ad73292a8a00b13bd362dc6611d2ec70ff39407f712d5ea5bf70342d155df894674a75a414f796698b940a74ab4f400c092a08670ba0fada84be9519e2090b1b08a92431e0ece1dd8ee5c8c6516b197cd9685c4136742dcc5b334641cccb18479d753976810576ed908591fa18a2d850275155c77667deba4b1d66b30999644c90784595aa92648283214440cf2d8b9633a233658b70ed5a9983dc1e48e07491c6b9d71897f6c8c86c926fa0ab30294404e3464e3eefabfa7a01a85e6e5ce7a5e9a164399fb448121e54a0c4e9a14ffe95731c87722291357ef9231dcf32dd0a6577d37c5b387b3d38b2a31cf43f5a1dd8de84bcbba6f85222b001addd7710b2b1849562677d9e9cf1ddd49ccc7a0a47b47533472f73460ba8244b52b16b863b521962485c3f81f72cb3a91136c16f98a67152f2a695be52a0af898c3268ac55418a5322fda735a278ad13f03d291f61415aa02a9e22aea9cdb14ab3f1d9cc95399e9ca0d3db1b48a8a83df4f99c58c379a3024f315072174c9b7572b959add4f89f1d5e8e622c256f8b940667e7820d09f3b739b7b534a4069403b2508154be8e7aa82d1462c0cfe93c95835d2faee941aa98a3e39d34b318d558994923e65f7a2db54bfc65ad6ae2ba3703be7f74d11d32d811a4fda23ddd11f6a8c89b1c3163607beb36f8fe0efd053cc66db1a9a10d8f6004ad7369c87a091ac8bd89a4f3433f2d848346feaaa9b44e4ae6065da477e3d5741893fe6705baaf2d3c85893841af9eb225411f3c95980424d616edf7bea66130ba1259512a0296df946f9c854b083975e9dd90b13fa07a43dfd02628b5a29ebb23be574c4472b46ba89083481d1f3e86453dbbffa57c67e3dbe9e0c5d3e0dba2954559286ccca7fe4dfea6d1f26797f27b8f12b504fa23ec4385cf8ddecf91eac4508e0af71607289facd95358a8b077eb9e9cc8147e606d76e9e9b359e1ac88da085436f3b5b73d97898c7be74926030e789dc0905fecbcfa60bf66c2391538be6111a602ad88c5b33cc5d95fd23cd7c335bfaa4ec773cf187ff70b41228dbd729e9088bdbc8c7284fd7669c946523c9eba793b5fa673653a0c235adc1d5b08aad54aa51f4ecca3cc637330c3bfc0757846e3bef4e6fe9555eca06af5b28c42cf960de8dd71774bccfbf69fe8ea5f63831c77a20545c5f35e51e6036191c8740187c9114a50aac7d7416b5d4f69ece126d4cebe85b0aad7d6a038f7fb9c30df7d7c579615860d5e98aa9361b040cd203855a175117e2d3bc3f7f3544701bb6622ae112db5a1342ddbfb416715d8bbf41ec0537f7f3ab3e6694ae13c4e7c6cab5e6c522dc56e2562ec70e45375384f53e26029274a753a33c210c86c62a460371027d7d9a66b3edcc68e80e1bda79c1cd1d9e72b4781182301e950864cde56d28e146b533452155a42]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[指针专题]]></title>
    <url>%2F2020%2F07%2F22%2Fdouble-pointer%2F</url>
    <content type="text"><![CDATA[三数之和 首先固定一个数，然后另外两个数用两个指针去探索记录和为0的组合。 对于前后一样的数可以跳过 c++12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; int target; vector&lt;vector&lt;int&gt;&gt; ans; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size(); i++) &#123; target= nums[i]; if (target &gt; 0) break; if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; int l = i + 1, r = nums.size() - 1; while (l &lt; r) &#123; if (nums[l] + nums[r] + target &lt; 0) ++l; else if (nums[l] + nums[r] + target &gt; 0) --r; else &#123; ans.push_back(&#123;target, nums[l], nums[r]&#125;); ++l, --r; while (l &lt; r &amp;&amp; nums[l] == nums[l - 1]) ++l; while (l &lt; r &amp;&amp; nums[r] == nums[r + 1]) --r; &#125; &#125; &#125; return ans; &#125;&#125;; 二、滑动窗口 3. 无重复字符的最长子串 滑动窗口的本质也是双指针,两个指针分别代表某个子串的两端，用ss这个字典来表示某个字符最新出现的位置，当右指针遍历到一个新字符，就检查一下这个元素最新的位置c，这个新串的起始位置就是c+1，每一个窗口就比较一下获得最大值。 c++1234567891011121314151617181920class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; map&lt;char, int&gt;ss; int max_len = 0; int left = 0; for (int j = 0; j &lt; s.size(); j++) &#123; if (ss.find(s[j]) != ss.end()) &#123; left = max(left, ss[s[j]] + 1); &#125; int cur_len = j - left + 1; if (max_len &lt; cur_len) max_len = cur_len; if (ss.find(s[j]) != ss.end()) ss.erase(s[j]); ss[s[j]] = j; &#125; return max_len; &#125;&#125;;]]></content>
      <tags>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树状数组(binary indexed tree)]]></title>
    <url>%2F2020%2F07%2F18%2Fbinary-indexed-tree%2F</url>
    <content type="text"><![CDATA[lowbit()运算 非负整数n在二进制下最低位1以及后面的0构成的值 比如lowbit(44)=101100=100=4 求法：对原数按位取反再加一，得到的新数再与原数相与。 比如101100 求反 →\rightarrow→ 010011 再加1 →\rightarrow→ 010100(就是负的原数) 再与101100(44) →\rightarrow→ 100 lowbit(n)=n&amp;(-n) c++1234567891011121314151617181920212223242526272829303132class Solution &#123;public: map&lt;int,vector&lt;int&gt;&gt;g; vector&lt;int&gt; countSubTrees(int n, vector&lt;vector&lt;int&gt;&gt;&amp; edges, string labels) &#123; vector&lt;int&gt;ans(n); vector&lt;int&gt;visit(n); for(int i=0;i&lt;edges.size();i++)&#123; if(edges[i][1]==0) g[edges[i][1]].push_back(edges[i][0]); else if(visit[edges[i][1]]==1) g[edges[i][1]].push_back(edges[i][0]); else g[edges[i][0]].push_back(edges[i][1]); visit[edges[i][0]]=visit[edges[i][1]]=1; &#125; for(int i=0;i&lt;n;i++)&#123; int res=0; dfs(i,i,res,labels); ans[i]=res+1; &#125; return ans; &#125; void dfs(int v,int t,int &amp;res,string labels)&#123; if(labels[v]==labels[t]&amp;&amp;v!=t) res++; for(int j=0;j&lt;g[t].size();j++)&#123; dfs(v,g[t][j],res,labels); &#125; return; &#125;&#125;;]]></content>
      <tags>
        <tag>树状数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NP-hard问题总结(reduce to MC problem)]]></title>
    <url>%2F2020%2F06%2F21%2Fpaper2%2F</url>
    <content type="text"><![CDATA[在这里对图论相关的np-hard问题做个总结 Triangle minimization in large networks 本文从两个方向来最小化图中三角形数量，一个是删除点、一个是删除边 以删除边为例，有两个算法思路 基于度的删除(每次删除度最大的边(a,b),这条边的度就是min(d(a),d(b))min(d(a),d(b))min(d(a),d(b))) 基于三角形的删除，每次删除边所在的三角形数量最多的边 优化 Lazy evaluation： 采用优先队列，再第i轮迭代时，若当前边的在上轮得到的三角形数量值小于当前的最大三角形数量，就不需要计算了 K-core Minimization for all given k Preventing Unraveling in Social Networks: The Anchored kkk-Core Problem k=2k=2k=2:有多项式时间精确解法： 一、RemoveCore(G) 移除图中2-core节点之间的边(也可以想象是把2-core中的点浓缩(contract)成一个点，命名为rrr)，将图转化为森林，这个森林的树有两种类型一种有2-core节点叫RRR，一种是没有2-core节点的叫SSS。 这样就分成了两种情况： 对于RRR,选取离rrr最远的点v1v_{1}v1​ 对于SSS,选取最远路径的两个端点 比较这两种更好的收益做下一步的选择 k≥3k\geq 3k≥3 证明: 构建:假设S1,s2...S_{1},s_{2}...S1​,s2​...是集合，e1,e2...e_{1},e_{2}...e1​,e2​...是覆盖的元素，我们这样建立图，首先顶点集合 {v1,v2...}\left \{v_{1},v_{2}...\right \}{v1​,v2​...}对应S1,s2...S_{1},s_{2}...S1​,s2​...，HHH是一个随意的大图，除了顶点hhh度为k−1k-1k−1,其他点都是kkk，然后按照集合覆盖的连接方式连接对应的vvv和hhh,这样选择了一个vvv，和vvv相连的图 HHH中的顶点都可以保留了。 K-Core Maximization: An Edge Addition Approach 总体思想是每次选取followers最多的侯选边，改进的算法并没有对followers有本质的提高，只是对侯选边精简和中间结果保留优化了时间空间复杂度。]]></content>
      <tags>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图论经典问题]]></title>
    <url>%2F2020%2F06%2F17%2Fgragh-th%2F</url>
    <content type="text"><![CDATA[本章节回顾一下图论里经典的算法 DFS与BFS DFS --stack–O(h)(根据树的高度)–不具最短路–恢复现场（恢复到之前的状态）–剪枝（可行性剪枝、最优性剪枝） BFS --queue–O(2h2^{h}2h)(宽度)–最短路 DFS：经典题目：排练数字、N-皇后 最短路径 难点在于建图 dijksra c++123451. dist[1]=0,dist[other]=0x3f3f3f,S(目前已确定点的集合)2. for i in n $t leftarrow S中不存在，距离S最近的点$ $S \leftarrow S \bigcup t$ 用t更新到其他点的距离 完整代码： c++123456789101112131415161718192021222324252627282930313233343536373839#include&lt;iostream&gt;#include&lt;cstring&gt;#include &lt;algorithm&gt;using namespace std;const int N=510;int m,n;int dist[N];int g[N][N];bool st[N];int dijkstra()&#123; memset(dist,0x3f,sizeof(dist)); dist[1]=0; for(int i=0;i&lt;n-1;i++)&#123; int t=-1; for(int j=1;j&lt;=n;j++)&#123; if(!st[j]&amp;&amp;(t==-1||dist[j]&lt;dist[t]) t=j; &#125; for(int j =1;j&lt;=n;j++)&#123; dist[j]=min(dist[j],dist[t]+g[t][j]); &#125; st[t]=true; &#125; if (dist[n] == 0x3f3f3f3f) return -1; return dist[n];&#125;int main()&#123; memset(g,0x3f,sizeof(g)); scanf("%d%d",&amp;n,&amp;m); while(m--)&#123; int a,b,c; scanf("%d%d%d",&amp;a,&amp;b,&amp;c); if(a==b)continue; else g[a][b]=min(g[a][b],c); &#125; print("%d\n",dijkstra(); return 0;&#125; 最小生成树 哈密顿图 设G=&lt;V,E&gt;为一图(无向的或有向的).G中经过每个顶点一次且仅一次的通路称作哈密顿通路；G中经过每 个顶点一次且仅一次的回路称作哈密顿回路；若G中存在哈密顿回路，则称G为哈密顿图。 任何一个哈密顿图可以看作是一个基本回路再加上连接回路上顶点对的其他若干边 从一个基本回路上删除k个顶点，最多形成k个连通分支 向一个图种 斯坦纳树（steiner tree)]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[近似算法]]></title>
    <url>%2F2020%2F06%2F15%2Fapp%2F</url>
    <content type="text"><![CDATA[近似算法要求 时间：多项式时间 近似比： 常数 假设P!=NP,NP-hard组合优化问题可以按近似性分为三类： 完全可近似的，对于任意小$\varepsilon d,存在(1+d,存在(1+d,存在(1+\varepsilon $)的近似算法，比如背包问题 可近似的，存在具有常数比的近似算法，例如最小顶点覆盖，多级问题 不可近似的 不存在具有常数比的近似算法，比如货郎问题 最小顶点覆盖 Steiner tree]]></content>
      <tags>
        <tag>近似算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划困难问题合集]]></title>
    <url>%2F2020%2F06%2F14%2Fdp-hard%2F</url>
    <content type="text"><![CDATA[dp可以用来解决有限集合的最值问题(max,min,count…) dp问题分为两个部分 状态表示 状态计算 初始化和边界符合定义就可以 两个子序列的最大点积(190周赛) dp[i][j]的含义是到nums1[i]和nums2[j]为止的子序列的最大点积。 1.选择nums1[i]和nums2[j] 不选择前面的 dp[i][j]=nums1[i] ×\times× nums2[j] 也选择前面的 dp[i][j]=max(dp[i][j],nums1[i]×\times×nums2[j]+dp[i-1][j-1]) 因为dp[i][j]是截止到nums1[i]和nums2[j]中的最大点积，所以只需要dp[i-1][j-1]就可以了 事实上从这里可以看出想法一就是想法二的情况之一 2.选择nums1[i],不选择nums2[j] 这种情况很容易想到就用dp[i][j-1]来表示，但实际上dp[i][j-1]并不只表示这种情况，因为dp[i][j-1]表示的是到i和j-1为止的最大点击，nums[i]不一定就选，但是这个并不影响最终结果，因为我们是求最大值，当这个状态表示的集合多的时候，不会漏掉最大值的。 dp[i][j]=max(dp[i][j],dp[i][j-1]) 3.不选择nums1[i],选择nums2[j] 等价于dp[i-1][j] dp[i][j]=max(dp[i][j],dp[i-1][j]) 4.nums1[i]，nums2[i]都不选。 这种情况包括在第二三种情况了 这样会保证两个序列长度相等吗? 会的，因为每次我们选取的操作–nums1[i]×\times×nums2[j]+dp[i-1][j-1]，都是同时选取每一个序列的一个元素. 时间复杂度O(mn)O(mn)O(mn) c++123456789101112131415class Solution &#123;public: int maxDotProduct(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; int n=nums1.size(); int m=nums2.size(); vector&lt;vector&lt;int&gt;&gt;dp(n+1,vector&lt;int&gt;(m+1,-0x3f3f3f)); for(int i=1;i&lt;n+1;i++) for(int j=1;j&lt;m+1;j++)&#123; dp[i][j]=max(dp[i-1][j],dp[i][j-1]); dp[i][j]=max(dp[i-1][j-1]+nums1[i-1]*nums2[j-1],dp[i][j]); dp[i][j]=max(nums1[i-1]*nums2[j-1],dp[i][j]); &#125; return dp[n][m]; &#125;&#125;; 最长公共子序列 c++1234567891011121314151617class Solution &#123;public: int longestCommonSubsequence(string text1, string text2) &#123; int p = text1.size(); int q = text2.size(); vector&lt;vector&lt;int&gt;&gt; dp(p+1,vector&lt;int&gt;(q+1,0)); for(int i=1;i&lt;p+1;i++) for(int j = 1;j&lt;q+1;j++) &#123; if(text1[i-1]==text2[j-1]) dp[i][j]=dp[i-1][j-1]+1; else dp[i][j]=max(dp[i-1][j],dp[i][j-1]); &#125; return dp[p][q]; &#125;&#125;; 这道题到不算dp，也是用dp的一点思想来递归。 在第一层可以摆出6个ABA类型的和6个ABC类型的涂法。对于下面每一层，每一个ABA涂法可以拼接2个ABC涂法和3个ABA涂法，每一个ABC涂法可以拼接2个ABC涂法和2个ABA涂法。这样迭代可以算出第N层有几种ABA涂法和ABC涂法，相加就是答案。 c++1234567891011121314class Solution &#123;public: int numOfWays(int n) &#123; long long aba = 6, abc = 6; const int m = pow(10,9) + 7; for(int i=1;i&lt;n;i++)&#123; int ABA,ABC; ABA=(abc*2+aba*3)%m; ABC=(abc*2+aba*2)%m; abc=ABC,aba=ABA; &#125; return (abc+aba)%m; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客美化专题]]></title>
    <url>%2F2020%2F05%2F27%2Fblog-bea%2F</url>
    <content type="text"><![CDATA[加入爱心页面 首先新建一个html的page Code1hexo new page &quot;html&quot; 修改主题的config，加入下面 将下载好的love文件夹放到\blog\source\html 修改config，跳过渲染，因为已经是html文件了，渲染是吧md文件到html： 之后的细节按照自己的需要修改爱心文件即可]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>博客美化专题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bug]]></title>
    <url>%2F2020%2F05%2F24%2Fbug%2F</url>
    <content type="text"><![CDATA[该文章已加密, 请输入密码查看。 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]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[seq2seq]]></title>
    <url>%2F2020%2F05%2F20%2Fseq2%2F</url>
    <content type="text"><![CDATA[本文将介绍seq2seq模型以及机器翻译的内容,需要明白RNN模型 RNN介绍的文章看这里：https://blog.csdn.net/zhaojc1995/article/details/80572098 为什么需要RNN? 时序数据：语音、天气、股票、文本 ht=f(whh⋅hh−1+wxh⋅xt+b1)h_{t}=f\left(w_{h h} \cdot h_{h-1}+w_{x h} \cdot x_{t}+b_{1}\right)ht​=f(whh​⋅hh−1​+wxh​⋅xt​+b1​) y^t=g(why⋅ht+b2)\hat{y}_{t}=g\left(w_{h y} \cdot h_{t}+b_{2}\right)y^​t​=g(why​⋅ht​+b2​) R’n’n seq2seq seq2seq(sequence to sequence)故名思意就是一种能够根据给定的序列，通过特定的方法生成另一个序列的方法，属于encoder-decoder结构的一种，这里看看常见的encoder-decoder结构，基本思想就是利用两个RNN，一个RNN作为encoder，另一个RNN作为decoder。encoder负责将输入序列压缩成指定长度的向量，这个向量就可以看成是这个序列的语义，这个过程称为编码，如下图，获取语义向量最简单的方式就是直接将最后一个输入的隐状态作为语义向量C。也可以对最后一个隐含状态做一个变换得到语义向量，还可以将输入序列的所有隐含状态做一个变换得到语义变量。 而decoder则负责根据语义向量生成指定的序列，这个过程也称为解码，如下图，最简单的方式是将encoder得到的语义变量作为初始状态输入到decoder的RNN中，得到输出序列。可以看到上一时刻的输出会作为当前时刻的输入，而且其中语义向量C只作为初始状态参与运算，后面的运算都与语义向量C无关。 seq2seq应用在机器翻译、对话机器人等领域，后续会补充一些项目实战，下面先介绍一下基础思路 seq2seq训练 训练数据为&lt;中文，英文&gt;，然后我们将每个minibatch中语句的长度补成相同（与最大长度相同），不同的minibatch不要求相同长度，这样方便进行向量化矩阵化(matrix)操作， infereence/Decoding 如果我们已经训练好了模型参数，怎么生成语句序列呢呢？ 通过模型softmax，我们可以得到每个单词的概率分布，然后每次选取概率最大的作为生成词(greedy)，但如果我们只考虑每个单词(unigram)，即使生成的语句单词相同，但是如果顺序不同就会不通顺，即没有好的语法结构，所以可以用bgram。 如何改进只能考虑局部最优解的局限性呢？下面有两个改进想法，exhaustic search,beam search exhaustic search 就是每次都考虑所有单词的情况，而不是只选择概率最高的单词，这样肯定可以找到全局最优解，但是这样就会复杂度很高，为O(∣v∣T)O(\left | v\right |^{T})O(∣v∣T) beam search exhaustic search复杂度太高，我们考虑使用beam search，这种方法是既考虑了贪心算法的改进也对复杂度降低，如果我们设三种方法的最优解是ToT_{o}To​,TeT_{e}Te​,TbT_{b}Tb​,那么To⊂Te⊂TbT_{o} \subset T_{e} \subset T_{b}To​⊂Te​⊂Tb​ beam search的想法是每次只考虑最好的k个单词，接下来是对第一次最好的k个单词继续考虑第二个生成单词也是取概率最高的前k个,但如果这样继续下去又是指数级增长了，所以是取对目前的序列（目前也就是长度为2）的概率和(其实是概率的乘积，但因为取了log)最高的k个序列，最后直到序列预测到end时停止，这样考虑也是有局限的，因为可能有的序列到很短就停止了，这样他的值就很大，最优解会优先选他，所以这块我们对每个序列除以长度。 每一步最多考虑k2k^{2}k2个可能性，这个算法的复杂度为O(k2T)O(k^{2}T)O(k2T) 代码实现 这里附上pytorch官方的实现：https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html transformer 我们知道同一个单词可能在不同的语境中可能有不同的意思也就是需要不同的向量表达，这个表达依赖于上下文的意思，其他单词也影响着这个单词的意思， 为什么需要self-attention？ lstm的不足： long-term dependency 只能串行 transformer： 两两个都能考虑到]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>seq2seq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[attention(注意力机制解析)]]></title>
    <url>%2F2020%2F05%2F20%2Fattention%2F</url>
    <content type="text"><![CDATA[本文我们将讲解注意力机制在视觉和自然语言以及图挖掘领域的使用。 PyTorch：https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning mutimodal learning 即将多个模型连接起来，每个模型完成相应的任务，一起完成比如看图说话、提取摘要等任务。 attention(注意力机制) 将注意力放到重要的地方，比较符合人类的思考，可以应用在文本、图像、自注意力(self-attention) 看图说话 先把图片提取出一个向量作为桥梁，我们取模型中倒数第二个向量v，wih是一个转移矩阵,输入到RNN中来生成语句序列 但这模型有些问题， 识别不出来某些物体 我们把图片等价于一个向量，通过这个向量来生成，其实有时候我们只需要关注图片中的一直猫，不需要理解整张图片 图像识别的注意力机制 这里feature矩阵每个格子都是一个d维的向量，a1也是一个3×3的矩阵，每个格代表这个区域的权重，当我们生成第一个单词我们要将注意力放在概率最高的区域，然后将这个两个矩阵的信息进行汇集到向量ZZZ，较于之前的seq2seq模型，我们这里就多了一个ZZZ 我们将z1z1z1输入到rnn模型，这里的first word就是start ，通过h1输出第一个单词和第二个单词的注意力，然后再生成z2z2z2,这里的y2y2y2就是的d1d1d1 https://blog.csdn.net/shenxiaolu1984/article/details/51493673#fn:1 attention in seq2seq seq2seq的不足： 梯度问题 首先我们的语义编码c，我们的目的是希望这个向量能包括所有输入的单词信息，但是因为LSTM梯度消失的问题，c可能只能捕获离他较近的几个单词的信息，前面的单词可能就考虑不到了(怎么改进？给前面的单词分配一个权重——–attention) 应用角度 现在的模型，我们生成下一个单词是依赖于上一个单词(pre)以及语义编码c,即v←(pre,c)v \leftarrow (pre,c)v←(pre,c)，然而往往我们在翻译的时候只会关注句子的一部分，并且这种模式太过于依赖语义编码c，如果c的效果不理想，那么最后的decoder也会不理想，这也是bottleneck problem。还有一个原因，c向量的维度已经固定，对不同长度的输入句子，都用一个固定维度的向量表达难免不足 seq2seq的attention 下面这幅图讲解了大致流程，首先看encoder部分这里的隐含向量g是什么，举个例子，按照图的描述，www就是transformation,f是激活函数，g2=f(Wxh⋅embeding(weather)+Whh⋅g1)g_{2}=f(W_{xh} \cdot embeding(weather)+W_{hh}\cdot g_{1})g2​=f(Wxh​⋅embeding(weather)+Whh​⋅g1​)。 我们要使用注意力，就要给每个词一个attention score，最简单的就是hhh和ggg的内积，当然也可以设置别的函数，比如gT⋅M⋅hg^{T} \cdot M \cdot hgT⋅M⋅h,这里的M就是要学习的一个参数矩阵。 我们以内积的方法为例，通过计算每个gT⋅hg^{T} \cdot hgT⋅h我们得到了每个单词的一个权重，然后通过归一化(可以是简单的通分，也可以是softmax)。 现在我们如何生成单词呢？首先先通过attention scroe,来生成新的context vector c1c_{1}c1​,用c1c_{1}c1​来生成翻译单词(之前我们用的是ccc),c1c_{1}c1​按图中的例子就是c1=0.6⋅g1+0.2⋅g2+0.1⋅g3+0.1⋅g4c_{1}=0.6\cdot g_{1}+0.2\cdot g_{2}+0.1\cdot g_{3}+0.1\cdot g_{4}c1​=0.6⋅g1​+0.2⋅g2​+0.1⋅g3​+0.1⋅g4​，然后我们将c1c_{1}c1​和h1h_{1}h1​拼接起来，来得到输出的单词y1y_{1}y1​,y1=softmax(Why⋅(c1∣h1+b)y_{1}=softmax(W_{hy} \cdot (c_{1}|h_{1}+b)y1​=softmax(Why​⋅(c1​∣h1​+b)(y1y_{1}y1​就是v维度的,选取概率最大的单词作为预测词),之后类似，y1y_{1}y1​作为第二个预测单词的输入 attention的优点： 解决了梯度问题 可解释性(深度学习缺乏理论支持，大多参数的选择都是随机调，所以可解释学习也是当前的一个方向）. 没有attention，我们无法可视化，无法看到模型的不足点去修改，有了attention我们可以针对性的解决，比如拿一句话今天天气很好，我们的模型把今天翻译成了yesterday，那么我们可以看一下今天的attention score，如果很高说明方向是对的，可能是样本数据的问题，如果权重小也就是其他词的权重大了，那么这个模型就是有问题了 attention的不足： attention in seq2seq的不足： 我们这种思路是给每个单词一个权重，我们更希望每个单词是独立的，然而RNN的特性，当前单词又会汇集之前的单词信息，这也是一个矛盾点， 想法一：g2-g1?来去除冗余信息？当然这是不对的，因为向量的表达相当于是空间中的一个位置，向量的差值没有什么含义，有方向的，方向是不能减的。 self-attention]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>attention</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法优化]]></title>
    <url>%2F2020%2F05%2F15%2Foptimize%2F</url>
    <content type="text"><![CDATA[本系列将探讨算法的优化。 时间复杂度对算法的选择 时间优化 思维的改进 LCP08.剧情触发时间 最开始的想法同时考虑三个属性，每到新的一天就遍历requirements数组，看能否有剧情出发，果不其然超时了，最后两个样例没通过 之后进行改进。 首先如果只考虑一种属性，显然我们只需要计算每一天的属性情况，最后对于所有的requirements 都在属性列表中进行二分查找（现在只有一种属性了)，就能知道他是在哪一天完成的了。 但这道题实际上，每一种属性的满足是互相独立的。 简单来说，对于一个剧情要求 (C, R, H) 来说，假设 C 要求是在第 x 天满足的，R要求是在第 y 天满足的，H 要求是在第 z 天满足的。那么该剧情的满足时间为： t=max(x,y,z) 原始代码： c++12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;int&gt; getTriggerTime(vector&lt;vector&lt;int&gt;&gt;&amp; increase, vector&lt;vector&lt;int&gt;&gt;&amp; requirements) &#123; int res[3]=&#123;0&#125;; int day=increase.size(); vector&lt;int&gt;end(requirements.size(),-1); for(int i=0;i&lt;day;i++)&#123; for(int j=0;j&lt;3;j++)&#123; res[j]+=increase[i][j]; &#125; for(int m=0;m&lt;requirements.size();m++)&#123; if(end[m]!=-1)continue; int count=0; int count1=0; for(int n=0;n&lt;3;n++)&#123; if(res[n]&gt;=requirements[m][n]) count++; if(requirements[m][n]==0) count1++; &#125; if(count1==3)&#123; end[m]=0; continue; &#125; if(count==3) end[m]=i+1; &#125; &#125; return end; &#125;&#125;; 改进代码： c++123456789101112131415161718192021222324252627282930313233class Solution &#123;public: vector&lt;int&gt; getTriggerTime(vector&lt;vector&lt;int&gt;&gt;&amp; increase, vector&lt;vector&lt;int&gt;&gt;&amp; requirements) &#123; //将三个属性分开，并初始化为0 vector&lt;int&gt; C(increase.size() + 1, 0);//初始化 vector&lt;int&gt; R(increase.size() + 1, 0); vector&lt;int&gt; H(increase.size() + 1, 0); for (int i = 0; i &lt; increase.size(); ++i)//算和 &#123; C[i + 1] = C[i] + increase[i][0]; R[i + 1] = R[i] + increase[i][1]; H[i + 1] = H[i] + increase[i][2]; &#125; vector&lt;int&gt; ret;//返回值 int maxlen = C.size();//若lower_bound中没找到则返回last，此时求的差是数组长度 for (int i = 0; i &lt; requirements.size(); i++) &#123; //lower_bound 返回大于等于查找元素的位置 int lbc = lower_bound(C.begin(), C.end(), requirements[i][0]) - C.begin(); int lbr = lower_bound(R.begin(), R.end(), requirements[i][1]) - R.begin(); int lbh = lower_bound(H.begin(), H.end(), requirements[i][2]) - H.begin(); if (lbc == maxlen || lbr == maxlen || lbh == maxlen)//没触发 &#123; ret.emplace_back(-1); &#125; else &#123; ret.emplace_back(max(max(lbc, lbr), lbh)); &#125; &#125; return ret; &#125;&#125;; 代码简洁优化 检查单词是否为句中其他单词的前缀 使用字符串流 c++1234567891011121314``````c++class Solution &#123;public: int isPrefixOfWord(string sentence, string searchWord) &#123; stringstream ssin(sentence); string word; for(int i =1;ssin&gt;&gt;word;i++)&#123; if(word.substr(0,searchWord.size())==searchWord) return i; &#125; return -1; &#125;&#125;; 判断是否包括元音字母？ 最原始思路 c++123456789int de(char c)&#123; if(c=='a')return 1; if(c=='e')return 1; if(c=='i')return 1; if(c=='o')return 1; if(c=='u')return 1; return 0; &#125;de(c) 哈希表: c++123unordered_set&lt;char&gt;S(&#123;'a','e','i','o','u'&#125;);S.count(c);//0就是不包含，1就是包含 参考资料： https://www.acwing.com/blog/content/32/]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode多函数编程]]></title>
    <url>%2F2020%2F05%2F15%2Ffunction%2F</url>
    <content type="text"><![CDATA[设计地铁系统 这道题主要思考点在于容器设计，in容器来记录编号id的人的（上车站点和上车时间）–pair，然后不需要额外用out来记录下车，直接在checkout函数里计算一下id的人上下车时间差做好记录，最后直接求mean就可以啦 c++1234567891011121314151617181920212223242526272829class UndergroundSystem &#123;public: using pii = pair&lt;string, int&gt;; unordered_map&lt;int, pii&gt; in; map&lt;pair&lt;string,string&gt;, int&gt; a, b; UndergroundSystem() &#123; in.clear(); a.clear(); b.clear(); &#125; void checkIn(int id, string stationName, int t) &#123; in[id] = &#123;stationName, t&#125;; &#125; void checkOut(int id, string stationName, int t) &#123; auto [ss, tt] = in[id]; int time = t-tt; a[&#123;ss,stationName&#125;] ++; b[&#123;ss,stationName&#125;] += time; &#125; double getAverageTime(string s, string t) &#123; return (double)b[&#123;s,t&#125;]/a[&#123;s,t&#125;]; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>多函数编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Binary Search]]></title>
    <url>%2F2020%2F05%2F09%2FBinary-Search%2F</url>
    <content type="text"><![CDATA[二分搜索核心思想：把待搜索区间分为有目标元素的区间和不包含目标元素的区间，排除掉不包含目标元素的区间的区间，剩下就是有目标元素的区间。]]></content>
  </entry>
  <entry>
    <title><![CDATA[bert]]></title>
    <url>%2F2020%2F05%2F08%2Fbert%2F</url>
    <content type="text"><![CDATA[pretrain embedding word2vec 不能表示单词在不同场景下不同意思，希望能得到上下文相关的表示法 learn contextualized embedding language model/lstm+unsupervised data 自编码；回归任务]]></content>
  </entry>
  <entry>
    <title><![CDATA[华为云口罩配送大赛经验分享]]></title>
    <url>%2F2020%2F05%2F08%2Fhuawei%2F</url>
    <content type="text"><![CDATA[比赛链接：https://competition.huaweicloud.com/information/1000037176/introduction 赛题分析： 地图大小为12×12，需求点固定为5个，配送目标是将所有需求点的需求进行满足，配送过程中会随机生成捐赠小区 纯命令行交互，使用标准I/O作为命令（S/R/G）和移动方向(E/W/S/N)的传递途径 在1000张地图上测试 思路 我没有做太多的思考，思路也很容易理解，首先先到的就是greedy策略，每次都选择当前最好的选择，当然这只能考虑到局部最优，但最后结果还不错，能排进前二十。 每次配送的时候都优先选择离当前最近的需求点配送，取货的时候给每个捐赠小区一个ranking，就按照捐赠数量/距离来做，试了一下距离的平方结果不如绝对值。 配送有几种情况需要考虑： 车上口罩为0，那么肯定要去取货，那么就按ranking来选择 车上口罩为100，那么肯定要去送货，就选择最近的，因为最远的周边可能后续会生成捐赠小区 接下的两种情况最难考虑，就是送完一个小区或者刚取完一些车上还剩，那么是去接着送别的小区，还是取货呢？我的想法就是也写一个ranking比较，送货和取货的价值比较，但要考虑一些特殊情况，如果此时的货够最近的需求小区a那么就去送，如果此时的货加上离aranking最高的取货点足够那么就直接去取货点取货，当然这考虑非常不够，很需要改进,可以学习依一下别的选手的思路。 代码分析 下面对我的代码进行讲解，用python写的. load:当前装载量 target：目标地 R(字典)：对应坐标的货量，需求点就是负值，捐赠和仓库就是正值，坐标要用元组，不是列表 主函数 需求小区仓库初始化 python12345678910111213if __name__ == '__main__': new_string=input() s_list=new_string.split() S=(int(s_list[1]),int(s_list[2])) R=&#123;&#125; R[(int(s_list[1]),int(s_list[2]))]=100 for i in range(0,5): new_string=input() r_list=new_string.split() R[(int(r_list[1]),int(r_list[2]))]=int(r_list[3]) p=list(S) load=0 #初始化装载量为0 target=S 选择（每次到达小区或者捐赠点就行下一步的选择) 这里我加入了一个配送时如果有顺路的捐赠小区，那就去取一下 python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950while True: P=tuple(p) if P == S: load = 100 target = choose_na_target(p) elif P in R.keys(): sum=load+R[P] if R[P] &lt; 0: if sum&lt;0: load=0 R[P]=sum if R[closest(p)] &gt;= -R[P]: target = closest(p) else: target= choose_target(p) #车空就去送取货 else: del R[P] if len(R)==0: break if min(R.values())&gt;0: break load=sum target1 = choose_na_target(p) target2 = choose_target(p) target3 = choose_target(target1) if load &gt;= -R[target1]: target = target1 elif load + R[target3] &gt;= -R[target1]: target = target3 else: target = com_value(p ,target1,target2) else: if sum &gt; 100: load=100 R[P]=sum-100 target = choose_na_target(p) else: del R[P] load=sum target1 = choose_na_target(p) target2 = choose_target(p) if load &gt;= -R[target1]: target = target1 else: target = com_value(p ,target1,target2) for k in R.keys(): #顺路就去取 if R[k] &gt; 0: if(k[0]&gt;=target[0] and k[0]&lt;=p[0]) or (k[0]&lt;=target[0] and k[0]&gt;=p[0]): if(k[1]&gt;=target[1] and k[1]&lt;=p[1]) or (k[1]&lt;=target[1] and k[1]&gt;=p[1]): target = k 读取命令行输入 python12345678910111213141516171819new_string=input() if new_string=='G': #读取到行动的命令，向target移动 p,next_step=step(p,target) print(next_step) else: r_list=new_string.split() if p[0] == int(r_list[1]) and p[1] == int(r_list[2]): #空投贴脸hhh if load + int(r_list[3]) &lt;= 100: load = load + int(r_list[3]) else: R[(int(r_list[1]),int(r_list[2]))]=int(r_list[3])-100+load load = 100 else: R[(int(r_list[1]),int(r_list[2]))]=int(r_list[3]) #更新一下选择 if R[target] &gt; 0: #注意R里没有S target = choose_target(p) else: cur_target = (int(r_list[1]),int(r_list[2])) target = com_value(p ,target,cur_target) 移动函数 python1234567891011121314def step(pos,to): if pos[0]&lt;to[0]: pos[0]=pos[0]+1 return pos,'S' elif pos[0]&gt;to[0]: pos[0]=pos[0]-1 return pos,'N' else: if pos[1]&lt;to[1]: pos[1]=pos[1]+1 return pos,'E' else: pos[1]=pos[1]-1 return pos,'W' 选择捐赠小区和需求小区 python12345678910111213141516171819202122232425262728293031323334def choose_na_target(pos): na_distance=0 global load for k in R.keys(): if R[k] &lt; 0: if k[0]==pos[0] and k[1]==pos[1]: continue cur_dis2 = 1/ (abs(pos[0]-k[0])+abs(pos[1]-k[1])+1) if cur_dis2 &gt; na_distance: na_distance = cur_dis2 tar = k return tar```pythondef choose_target(pos): po_distance=0 global load distance = (100-load)/ (abs(pos[0]-S[0])+abs(pos[1]-S[1])+1) for k in R.keys(): if R[k] &gt; 0: if k[0]==pos[0] and k[1]==pos[1]: continue if R[k] + load &gt; 100: cur_dis1 = (100-load)/ (abs(pos[0]-k[0])+abs(pos[1]-k[1])+1) else: cur_dis1 = R[k] / (abs(pos[0] - k[0]) + abs(pos[1] - k[1])+1) if cur_dis1 &gt; po_distance: po_distance = cur_dis1 tar =k if po_distance&gt; distance: return tar else: return S 捐赠小区和需求小区的比较ranking python12345678910111213141516def com_value(pos,target1,target2): global target if load &lt; -R[target1]: cur_value1 = load else: cur_value1 = -R[target1] value1 = cur_value1 / (abs(pos[0]-target1[0])+abs(pos[1]-target1[1])+1) if load +R[target2] &gt; 100: cur_value2 = 100 -load else: cur_value2 = R[target2] value2 = cur_value2 / (abs(pos[0]-target2[0])+abs(pos[1]-target2[1])+1) if value1 &gt;value2: return target1 else: return target2]]></content>
      <tags>
        <tag>比赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[transformer]]></title>
    <url>%2F2020%2F05%2F01%2Ftransformer%2F</url>
    <content type="text"><![CDATA[seq2seq主要有下面两个不足： long—term dependency 会出现梯度消失或者爆炸 只能串行 时序的模型，后面的运算必须依赖于前面的运算 我们知道同一个单词可能在不同的语境中可能有不同的意思也就是需要不同的向量表达，这个表达依赖于上下文的意思，其他单词也影响着这个单词的意思， transformer就改进了这块的不足。 transformer的优点 RNN会将它已经处理过的前面的所有单词/向量的表示与它正在处理的当前单词/向量结合起来。而自注意力机制会将所有相关单词的理解融入到我们正在处理的单词中。 Encoder encoder 主要有两部分部分，一个self-attention另一个就是全连接网络，self-attention进行不同单词之间信息的交互，具体下面来讲，而全连接网络就是对每个单词进行的转换，也就是乘上一个矩阵再加上偏置，然后再加上激活函数。 所以encoder主要再self-attention 首先输入就是每个单词的embedding，比如可以是glove训练出来的，然后有三个参数矩阵，Wo,Wk,WvW^{o},W^{k},W^{v}Wo,Wk,Wv,这是共享的参数矩阵，然后输入向量分别与三个矩阵相乘，得到三个向量，q1,k1,v1q1,k1,v1q1,k1,v1,这里的向量是一个比原始embedding向量更加低维的表达q1⋅k1,q1⋅k2,q1⋅k3...q1 \cdot k1,q1 \cdot k2,q1 \cdot k3...q1⋅k1,q1⋅k2,q1⋅k3...,这就是两个单词的attention，比如其中两个值是112、96，如果我们直接用和的归一化112112+96\frac{112}{112+96}112+96112​,96112+96\frac{96}{112+96}112+9696​则这两个值会比较接近，梯度更稳定，如果直接送到softmax，e112e112+e96\frac{e^{112}}{e^{112}+e^{96}}e112+e96e112​,e96e112+e96\frac{e^{96}}{e^{112}+e^{96}}e112+e96e96​,这两个值就会分别接近0和1了，没有区分度，所以这里我们对他除以一个d\sqrt{d}d​,ddd就是qq q的维度（论文里是8，也就是64维度的求根值）再进行softmax，然后对每个atteention值(这些值也可以当作是一个score向量)分别与对应的viv_{i}vi​相乘得到z1z1z1,z1z1z1,具体可见下图， 这就相当于考虑了整个句子了，这个整体就是一层的encoder block. positional encoding 主要为了体现距离位置的信息，encoding向量之间点积越大代表距离越近 矩阵化操作 首先是矩阵化求q,k,vq,k,vq,k,v看下面图很容易理解 每个attention我们是通过q1⋅k1,q1⋅k2,q1⋅k3...q1 \cdot k1,q1 \cdot k2,q1 \cdot k3...q1⋅k1,q1⋅k2,q1⋅k3...，我们就可以个把k1,k2..k1,k2..k1,k2..堆积起来到一个矩阵和q1q1q1进行相乘得到attention向量 可以再进一步矩阵化，我们把q1,q2...q1,q2...q1,q2...也堆积起来到一个矩阵qqq 然后得到了attention score矩阵，每一个值都是两两个单词得到的attention值，除以d\sqrt{d}d​，再对每一列求softmax。 下面是对第一个单词的score向量分别与v1,v2,v3...v1,v2,v3...v1,v2,v3...相乘得到z1z1z1(图里是b1b1b1),这里把vvv堆积起来，最终得到整个self-attention layer输出O矩阵 总结起来就是： multi-head attention Multi-Head Attention相当于hhh个不同的self-attention的集成（ensemble）,然后将所有头得到的特征矩阵ZiZ_iZi​拼接起来,经过一层全连接后得到输出最终的ZZZ. 优缺点 优点： 每一层计算复杂度比较低 比较利于并行计算 模型可解释性比较高 缺点： 有些RNN可以轻易解决的问题transformer没做到，比如复制string，或者推理时遇到的sequence长度比训练时更长(因为碰到了没见过的position embedding) RNN图灵完备，而transformer不是 疑惑 attention考虑到了所有两两单词，无论是邻居还是远在天涯，但这样没有考虑单词的顺序了？ 原始文章：加上位置向量，这不是学出来的参数，是人工加上的 transformer和lstm可以说是一个并列的模型，也就是一定意义上可以相互替代 原论文：https://arxiv.org/abs/1706.03762 参考文献：https://jalammar.github.io/illustrated-transformer/ 翻译：https://blog.csdn.net/longxinchen_ml/article/details/86533005 参考视频: 台大李宏毅老师-深度学习HLP]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[换新电脑hexo博客的迁移]]></title>
    <url>%2F2020%2F04%2F29%2Fblog-trsf%2F</url>
    <content type="text"><![CDATA[一、拷贝原始电脑blog文件夹到新电脑 二、安装git、node.js 三、安装 hexo 在 cmd 下输入下面指令安装 hexo Codeinstall hexo-cli -g```1234567## 四、在blog文件夹下执行git bash，输入以下命令```npm installnpm install hexo-deployer-git --save // 文章部署到 git 的模块（下面为选择安装）npm install hexo-generator-feed --save // 建立 RSS 订阅npm install hexo-generator-sitemap --save // 建立站点地图 五、创建ssh （1）打开git bash，在用户主目录下运行：ssh-keygen -t rsa -C “你的邮箱” 把其中的邮件地址换成自己的邮件地址，然后一路回车 （2）最后完成后，会在用户主目录下生成.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH key密钥对，id_rsa是私钥，千万不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 （3）登陆GitHub，打开「Settings」-&gt;「SSH and GPG keys」，然后点击「new SSH key」，填上任意Title，在Key文本框里粘贴公钥id_rsa.pub文件的内容（千万不要粘贴成私钥了！），最后点击「Add SSH Key」，你就应该看到已经添加的Key。 注意：不要在git版本库中运行ssh，然后又将它提交，这样就把密码泄露出去了。 六、部署可能出现的问题 git上传包提交时出现：Please tell me who you are. 解决方法：执行 git config --global user.email &quot;你的邮箱 git config --global user.name “gihub用户名” 之后就可以正常使用啦]]></content>
      <categories>
        <category>博客维护</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F29%2Fknn%2F</url>
    <content type="text"><![CDATA[title: knn应用（癌症判断） date: 2020-02-03 15:54:50 categories: 机器学习 tags: [KNN,应用，参数] cover: /img/me.jpg KNN简介 KNN算法的思想总结一下：就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为： 1）计算测试数据与各个训练数据之间的距离； 2）按照距离的递增关系进行排序； 3）选取距离最小的K个点； 4）确定前K个点所在类别的出现频率； 5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。 距离矩阵和k都是超参数 参数与超参数 参数(parameters)/模型参数 由模型通过学习得到的变量，比如权重和偏置 超参数(hyperparameters)/算法参数 根据经验进行设定，影响到权重和偏置的大小，比如迭代次数、隐藏层的层数、每层神经元的个数、学习速率等 实战 属性信息： Sample code number: id number Clump Thickness: 1 - 10 Uniformity of Cell Size: 1 - 10 Uniformity of Cell Shape: 1 - 10 Marginal Adhesion: 1 - 10 Single Epithelial Cell Size: 1 - 10 Bare Nuclei: 1 - 10 Bland Chromatin: 1 - 10 Normal Nucleoli: 1 - 10 Mitoses: 1 - 10 Class: (2 for benign, 4 for malignant)（2为良性，4为恶性） 为数据添加label，在第一行加入id,clump_thickness,uniform_cell_size, uniform_cell_shape,marginal_adhesion, single_epi_cell_size,bare_nuclei,bland_chromation, normal_nucleoli,mitoses,class 数据样式： clumb_thickness unif_cell_size unif_cell_shape marg_adhesion single_epith_cell_size bare_nuclei bland_chrom norm_nucleoli mitoses class 0 5 1 1 1 2 1 3 1 1 2 1 5 4 4 5 7 10 3 2 1 2 2 3 1 1 1 2 2 3 1 1 2 3 6 8 8 1 3 4 3 7 1 2 4 4 1 1 3 2 1 3 1 1 2 python12345678910111213141516171819202122232425262728293031import numpy as npfrom sklearn import preprocessing ,model_selection,neighborsfrom sklearn.linear_model import LinearRegressionimport pandas as pddf = pd.read_csv('breast-cancer-wisconsin.txt')#encoding='utf-8',header=None,sep = '\t'df.replace('?',-99999, inplace=True)#print([column for column in df])df.drop(['id'], 1, inplace=True) #df.drop returns a new dataframe with our chosen column(s) dropped.#df=df.iloc[:,1:]#.iloc使用全是以0开头的行号和列号，不能直接用其它索引哦。而.loc使用的实际设置的索引和列名。 这就是.loc和.iloc的区别。在实际运用中，我还发现一点区别，.iloc只能选取数据表里实际有的行和列，而.loc可以选取没有的行和列，赋值后就可以添加新行或者列。X = np.array(df.drop(['class'],1))y = np.array(df['class'])X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)#print([column for column in df])#clf = LinearRegression(n_jobs=-1)#SVM.svr() kernel='poly'clf = neighbors.KNeighborsClassifier()clf.fit(X_train,y_train)accuracy = clf.score(X_test,y_test)print(accuracy)print(df.head())#example_measures = np.array([4,2,1,1,1,2,3,2,1]) #一个sample#example_measures = example_measures.reshape(1, -1) #Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sampleexample_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,1,1,2,3,2,1]])#测试用例example_measures = example_measures.reshape(len(example_measures), -1)prediction = clf.predict(example_measures)print(prediction) accuracy:0.9714285714285714 预测结果：prediction[2 2] 两个都为良性]]></content>
  </entry>
  <entry>
    <title><![CDATA[并行矩阵求逆]]></title>
    <url>%2F2020%2F04%2F25%2Fparallow%2F</url>
    <content type="text"><![CDATA[引言 parallel parallel表示其后语句将被多个线程并行执行，“#pragma omp parallel”后面的语句（或者，语句块）被称为parallel region。 多个线程的执行顺序是不能保证的。 for 我们一般是对一个计算量庞大的任务进行划分，让多个线程分别执行计算任务的某一部分，从而达到缩短计算时间的目的。这里的关键是，每个线程执行的计算互不相同（操作的数据不同或者计算任务本身不同），多个线程协作完成所有计算。 OpenMP for指示将C++ for循环的多次迭代划分给多个线程（划分指，每个线程执行的迭代互不重复，所有线程的迭代并起来正好是C++ for循环的所有迭代），这里C++ for循环需要一些限制从而能在执行C++ for之前确定循环次数，例如C++ for中不应含有break等。 测试下电脑是几核的(几线程) c++123456789101112131415161718#include&lt;omp.h&gt; #include&lt;iostream&gt; int main() &#123; std::cout &lt;&lt; "parallel begin:\n"; #pragma omp parallel &#123; std::cout &lt;&lt; omp_get_thread_num(); &#125; std::cout &lt;&lt; "\n parallel end.\n"; std::cin.get(); return 0; &#125; 参考文献：https://blog.csdn.net/laobai1015/article/details/79020128 问题分析 矩阵求逆大致有三个方法，待定系数法、伴随矩阵求逆矩阵，初等变换求逆矩阵。而待定系数法和伴随矩阵对维数大很难计算了，而初等变化法有着清晰的过程，比较容易用编程语言表达，并且遍历矩阵去操作归一化清零等过程可以很容易实现并行化，不同线程的操作是针对不同行和列也不会产生冲突导致错误。 实现方案： 使用高斯消元法，用二维vector来存储矩阵，方便实现矩阵维度的变化以及遍历，将可并行化的循环加上#pragma omp parallel for实现并行化。 代码思路 运行加速比和正确性验证 代码基于c++和openmp编写，需要代码邮件call我~]]></content>
      <categories>
        <category>并行计算</category>
      </categories>
      <tags>
        <tag>openmp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pachong]]></title>
    <url>%2F2020%2F04%2F21%2Fpachong%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[pytorch]]></title>
    <url>%2F2020%2F04%2F16%2Fpytorch%2F</url>
    <content type="text"><![CDATA[深度学习有许多应用，这些应用往往包括以某种形式获取数据（例如图像或文本），并以另一种形式生成数据（例如标签，数字或更多文本）。从这个角度来看，深度学习包括构建一个将数据从一种表示转换为另一种表示的系统。 从一种数据形式到另一种数据形式的转换通常是由深度神经网络分层次学习的，这意味着我们可以将层次之间转换得到的数据视为一系列中间表示（intermediate representation）。以图像识别为例，浅层的表示可以是特征（例如边缘检测）或纹理（例如毛发），较深层次的表征可以捕获更复杂的结构（例如耳朵、鼻子或眼睛）。 张量（tensor） 对于来自数学、物理学或工程学的人来说，张量一词是与空间、参考系以及它们之间的转换的概念是捆绑在一起的。对于其他人来说，张量是指将向量（vector）和矩阵（matrix）推广到任意维度，。与张量相同概念的另一个名称是多维数组（multidimensional array）。张量的维数与用来索引张量中某个标量值的索引数一致。 张量的优点 Python列表或数字元组（tuple）是在内存中单独分配的Python对象的集合，如图2.3左侧所示。然而，PyTorch张量或NumPy数组（通常）是连续内存块上的视图（view），这些内存块存有未封装（unboxed）的C数值类型，在本例中，如图2.3右侧所示，就是32位的浮点数（4字节），而不是Python对象。因此，包含100万个浮点数的一维张量需要400万个连续字节存储空间，再加上存放元数据（尺寸、数据类型等）的少量开销。 比如可以用zeros或ones来初始化张量，同时用元组指定大小 python12points = torch.zeros(3, 2)points 输出： python123tensor([[0., 0.], [0., 0.], [0., 0.]]) 函数名后面带下划线_ 的函数会修改Tensor本身，例如，x.add_(y)和x.t_()会改变 x，但x.add(y)和x.t()返回一个新的Tensor， 而x不变。 Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字典树]]></title>
    <url>%2F2020%2F03%2F28%2Ftrie%2F</url>
    <content type="text"><![CDATA[单词的压缩编码 解法一： 原始思路：将所有是其他单词后缀的单词删掉，剩下的求长度和就可以了 python1234567class Solution(object): def minimumLengthEncoding(self, words): res=set(words) for word in words: for k in range(1,len(word)): res.discard(word[k:]) return sum(len(word) + 1 for word in res)]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[kmeans]]></title>
    <url>%2F2020%2F03%2F25%2Fkmeans%2F</url>
    <content type="text"><![CDATA[简介 k-means algorithm算法是一个聚类算法，把n的对象根据他们的属性分为k个分割，k &lt; n。假设对象属性来自于空间向量，并且目标是使各个群组内部的均方误差总和最小。通过迭代的方式将样本分到K个簇。 基本方法 选取K个点做为初始聚集的簇心（也可选择非样本点）; 分别计算每个样本点到 K个簇核心的距离（这里的距离一般取欧氏距离或余弦距离），找到离该点最近的簇核心，将它归属到对应的簇； 所有点都归属到簇之后， M个点就分为了 K个簇。之后重新计算每个簇的重心（平均距离中心），将其定为新的“簇核心”； 反复迭代 2 - 3 步骤，直到达到某个中止条件 sklearn实现 python1234567891011121314151617181920212223242526import matplotlib.pyplot as pltfrom sklearn.datasets import make_blobsfrom sklearn.cluster import KMeans#产生数据k=4X,Y = make_blobs(n_samples=100, n_features=2, centers=k)#构建模型km = KMeans(n_clusters=k, init='k-means++', max_iter=300)km.fit(X)# 获取簇心centroids = km.cluster_centers_# 获取归集后的样本所属簇对应值y_kmean = km.predict(X)print(y_kmean)# 呈现未归集前的数据plt.scatter(X[:, 0], X[:, 1], s=50)plt.yticks(())plt.show()plt.scatter(X[:, 0], X[:, 1], c=y_kmean, s=50, cmap='viridis')plt.scatter(centroids[:, 0], centroids[:, 1], c='black', s=100, alpha=0.5)plt.show() 手工实现 python12345678910111213141516171819202122232425262728293031323334353637383940414243444546import numpy as npfrom sklearn.datasets import make_blobsfrom math import sqrtimport randomimport matplotlib.pyplot as pltfrom scipy import spatial#产生数据k=4X,Y = make_blobs(n_samples=100, n_features=2, centers=k)def calcuDistance(vec1, vec2): # 步骤1：定义欧式距离的公式 # 计算两个向量之间的欧式距离：根号下[(x_1-x_2)^2+(y_1-y_2)^2+...+(x_n-y_n)^2] # ver1 - ver2：表示两个向量的对应元素相减 return np.sqrt(np.sum(np.square(vec1 - vec2))) #注意这里的减号def k_means(data,k,Y): m, n = data.shape # m：样本数量，n：每个样本的属性值个数 cores = data[np.random.choice(np.arange(m), k, replace=False)] # 从m个数据样本中不重复地随机选择k个样本作为质心 print(cores) while True: # 迭代计算 #d = np.square(np.repeat(data, k, axis=0).reshape(m, k, n) - cores) #distance = np.sqrt(np.sum(d, axis=2)) # ndarray(m, k)，每个样本距离k个质心的距离，共有m行 distance = spatial.distance.cdist(data, cores,metric='euclidean') index_min = np.argmin(distance, axis=1) # 每个样本距离最近的质心索引序号 if (index_min == Y).all(): # 如果样本聚类没有改变 return Y, cores # 则返回聚类结果和质心数据 Y[:] = index_min # 重新分类 for i in range(k): # 遍历质心集 items = Y==i # 找出对应当前质心的子样本集 ，对应的items为[True,false......] cores[i] = np.mean(data[items], axis=0) # 以子样本集的均值作为当前质心的位置 result,cores=k_means(X,k,Y)plt.scatter(X[:, 0], X[:, 1], s=50)plt.yticks(())plt.show()print(Y)plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap='viridis')plt.scatter(cores[:, 0], cores[:, 1], c='black', s=100, alpha=0.5)plt.show() k-means的改进 k-means改进的一个路线就是尽可能加快收敛速度，这个方向有几个思路： 1.质心初始化：选择初始质心之间有一些策略比如尽量远离，有助于反应数据的分布，加快收敛。 2.改进k-means的迭代过程，有几个方向，一个改进复杂度，比如数据的访问用KD树来索引，一个是改进目标函数（原始目标函数就是使同一类的离质心距离最小），有一个思路是时刻更新质心，比如移动一个样本到最近的类别，就立刻更新相应的两个类质心，这样改变了每轮都要对所有样本更新label的繁琐过程。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>K-means</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es]]></title>
    <url>%2F2020%2F03%2F23%2Fes%2F</url>
    <content type="text"><![CDATA[开启外网访问的方法：对elasticsearch.yml文件修改下面参数 transport.host: localhost network.host: 192.168.3.5]]></content>
  </entry>
  <entry>
    <title><![CDATA[链表一]]></title>
    <url>%2F2020%2F03%2F20%2Flist%2F</url>
    <content type="text"><![CDATA[知识点： 缺点： 无法高效获取长度 无法根据偏移快速访问元素 反转链表 方法一就是双指针来进行反转，注意要额外申请一个指针指向r指针，要不转完后面的内容就没了 c++1234567891011ListNode* reverseList(ListNode* head) &#123; ListNode* l = NULL; ListNode* r = head; while(r != NULL)&#123; ListNode* cur = r-&gt;next; r-&gt;next = l; l = r; r = cur; &#125; return l; &#125; 方法二递归 递归的设计要从两个方面入手，一个是返回什么，一个是得到上次的返回值当前层应该做怎么 这道题是应该返回链表的头结点，也就是原表的尾结点，做什么就是翻转了 翻转可以通过两步完成，假设当前操作的是phead，则通过 c++1head-&gt;next-&gt;next = head; 即可将p后面的节点指向p，然后我们要删除当前p指向后面的next指针 c++1head-&gt;next = NULL; 注意函数的返回值是p而不是next，我开始犯了这个错误，首先要明确最终返回的信息，我们不需要下个节点的信息（上面两步只用到了head），我们需要的p指向原来的尾结点并不断返回这个，在每层的函数完成翻转 下图就是回溯的过程，p始终指向尾结点 c++123456789ListNode* reverseList(ListNode* head) &#123; if (head == NULL || head-&gt;next == NULL) &#123; return head; &#125; ListNode* p = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; head-&gt;next = NULL; return p; &#125; 环形链表 方法一：哈希表存储 遍历每个节点存起来，如果再次遍历已存节点就是环了· c++12345678910111213class Solution &#123;public: bool hasCycle(ListNode *head) &#123; map&lt;ListNode *,int&gt;visit; while(head != NULL)&#123; if(visit[head] == 1) return true; visit[head] = 1; head = head -&gt; next; &#125; return false; &#125;&#125;; 方法二：快慢指针 c++12345678910111213class Solution &#123;public: bool hasCycle(ListNode *head) &#123; ListNode *slow = head, *fast = head; while(fast &amp;&amp; fast-&gt;next) //注意判断条件 &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if(slow == fast) return true; &#125; return false; &#125;&#125;; 如果存在环，如何判断环的长度呢？方法是，快慢指针相遇后继续移动，直到第二次相遇。两次相遇间的移动次数即为环的长度。 移除链表元素 一道简单题卡了很久…太长时间不做链表果然忘记太多，下面总结一下几点错误 leetcode的链表都没有头节点，head指针直接指向第一个元素，所以如果想要删除第一个的元素的话需要自己建立一个头节点 开始代码写得是return head，如果第一个元素被删除了，那么head后面的指向就断掉了 最开始循环里是这么写的 c++1234 if(p-&gt;next-&gt;val==val)&#123; p-&gt;next=p-&gt;next-&gt;next; p=p-&gt;next;&#125; 这样的话删除后就会跳过一个元素了。 下面代码， 常规 c++12345678910111213141516class Solution &#123;public: ListNode* removeElements(ListNode* head, int val) &#123; if(head==NULL)return NULL; ListNode*q = new ListNode(-1); q-&gt;next = head; ListNode*p = q; while(p-&gt;next!=NULL)&#123; if(p-&gt;next-&gt;val==val) p-&gt;next=p-&gt;next-&gt;next; else p=p-&gt;next; &#125; return q-&gt;next; &#125;&#125;; 递归 c++123456789class Solution &#123;public: ListNode* removeElements(ListNode* head, int val) &#123; if (!head) return head; head-&gt;next = removeElements(head-&gt;next, val); return head-&gt;val == val ? head-&gt;next : head; &#125;&#125;; 判断回文链表 最简单的方法就是用额外的空间把链表存到数组里再来判断，这里讲一下空间复杂度O(1)O(1)O(1)的方法 我们需要先遍历到链表尾再和头结点对比，很容易想到递归，还是需要两个指针 递归的写法就是 先判断之前有没有不相等的点，这个用上层递归的返回值就可以了直接return false。 当前节点不相等return false 剩下就是相等了return true c++12345678910111213141516171819class Solution &#123;public: ListNode *first; bool recursive(ListNode* head)&#123; if(head != NULL)&#123; if(!recursive(head -&gt; next)) return false; if(head -&gt; val != first -&gt; val)&#123; return false; &#125; first = first -&gt; next; &#125; return true; &#125; bool isPalindrome(ListNode* head) &#123; first = head; return recursive(head); &#125;&#125;; 反转链表 一次反转需要用到三个指针(l,r,p),l和r是指向当前要反转的两个节点，而p是保存r的下个节点，因为修改r-&gt;next = l, 下个节点的信息会丢失 注意原链表最后是指向NULL，所以反转的过程开头l也要指向NULL c++1234567891011121314class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; ListNode* l = NULL; ListNode* r = head; while(r)&#123; ListNode* p = r-&gt;next; r-&gt;next = l; l = r; r = p; &#125; return l; &#125;&#125;; 递归 ：注意每层的返回都是原来的尾结点，每一层不需要上一层的信息就可以完成反转 c++123456789101112class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if (head == NULL || head-&gt;next == NULL) &#123; return head; &#125; ListNode* p = reverseList(head-&gt;next); head-&gt;next-&gt;next = head; head-&gt;next = NULL; return p; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python编程(持续更新)]]></title>
    <url>%2F2020%2F03%2F14%2Fpython%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/ImwaterP/article/details/96282230 argmin 该函数主要用来检索数组中最小值的位置，并返回其下标值。同理，argmax()函数就是用来检索最大值的下标 在没有指定axis值的情况下，默认为None。在默认情况下，就相当于将n维的arry平铺在一起。举个简单的例子，当二维arry（[1,2,3],[4,5,6]）平铺开来就是（[1,2,3,4,5,6]）。 当axis = 1时，按照方向来，对于[2,5,6]来说最小值的下标是0，对于[7,6,1]来说最小值的下标是2。所以，最后输出的值就是[0,2]。 当axis = 0时，这时按照方向来，[2,7],[5,6],[6,1]分别在一个轴上，所以检索每个轴上的最小值，并返回下标，最后就可以得到输出值[0,0,1]。 关于切片 在list里面，只存在元素，不存在元素中的元素；list里元素就是最小的成分，不可以再切片。numpy 的array可以切片 例如 python1234a=np.array([[1,5],[2,6],[3,7]])print(a[2]) print(a[2,:])都可以a=[[1,5],[2,6],[3,7]]print(a[2,:])会报错 scipy.spatial.distance.cdist 该函数用于计算两个输入集合的距离，通过metric参数指定计算距离的不同方式得到不同的距离度量值 https://blog.csdn.net/kancy110/article/details/75675574]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>pyton</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux]]></title>
    <url>%2F2020%2F03%2F12%2Flinux%2F</url>
    <content type="text"><![CDATA[共享文件夹there no need 现在本地建立一个文件夹，这里是F:\test然后点击设备–共享文件夹，勾选自动挂载，自动分配， 此处我选择在/mnt下创建一个“share”目录，将刚刚的“gongxiang”目录与“share”目录关联起来。 进入/mnt： Code1cd/mnt 创建share目录： Code1sudo makdir share 将“test”目录与“share”目录进行关联： Code1sudo mount -t vboxsf test /mnt/share 报错对omp_getnum_threads未定义的引用 https://stackoverflow.com/questions/9685377/undefined-reference-to-omp-get-max-threads https://stackoverflow.com/questions/9685377/undefined-reference-to-omp-get-max-threads #更改分辨率 先使用xrandr命令看下分辨率的索引 然后xrandr --size 0 * 0(这是800 * 800的) 多文件编译 g++ -std=c++11 -o test2 truss.h graph.h graph_IO.h dp.h main.cpp ./test2 AstroPh.txt 50 result.txt g++ -std=c++11 fopenmp -o test2 truss.h graph.h graph_IO.h dp.h main.cpp 安装cmake $sudo apt-get install cmake 加入c11 add_definitions(-std=c11) 编译 $cmake .(注意这里有一个空格) $make $./Demo AstroPh.txt 50 result.txt]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[say somethingto myself]]></title>
    <url>%2F2020%2F03%2F10%2Ffor-me%2F</url>
    <content type="text"><![CDATA[该文章已加密, 请输入密码查看。 38cd76bef1cf79f27267863aa0f1e10aff0a55b3032fb665653565d974dcbbb6fb9e335fcb6f2cac947609853f0c56f0dbf7300ebc6e47358c153341a4c18fe59abedea6571c7603dd0c3ebeb08faededad4174f6c6eeda32fe389116f16e28f0210187cfa4a272439508fc90658c1b2309a116992d303d700f05971b0e4855d4f4ff589cfc7838359191bd9ee6077a648cc1789b19943078668c653d9694c0c484aaaa3e126d8a153c6e91c689217e97fdcb7997cda884612bdc08273526ce2ae6489c37d097434752f4027a4af6877]]></content>
  </entry>
  <entry>
    <title><![CDATA[gragh_convolution]]></title>
    <url>%2F2020%2F03%2F08%2Fgragh-convolution%2F</url>
    <content type="text"><![CDATA[graghsage 论文链接：https://arxiv.org/abs/1706.02216 github链接：https://github.com/williamleif/GraphSAGE 官方介绍链接：http://snap.stanford.edu/graphsage/ 优秀介绍： https://blog.csdn.net/yyl424525/article/details/100532849?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task gcn 现存的方法需要图中所有的顶点在训练embedding的时候都出现；这些前人的方法本质上是transductive，不能自然地泛化到未见过的顶点。 GraphSAGE是为了学习一种节点表示方法，即如何通过从一个顶点的局部邻居采样并聚合顶点特征，而不是为每个顶点训练单独的embedding。 GCN虽然能提取图中顶点的embedding，但是存在一些问题： GCN的基本思想： 把一个节点在图中的高纬度邻接信息降维到一个低维的向量表示。 GCN的优点： 可以捕捉graph的全局信息，从而很好地表示node的特征。 GCN的缺点： Transductive learning的方式，需要把所有节点都参与训练才能得到node embedding，无法快速得到新node的embedding。 GCN等transductive的方法，学到的是每个节点的一个唯一确定的embedding； 而GraphSAGE方法学到的node embedding，是根据node的邻居关系的变化而变化的，也就是说，即使是旧的node，如果建立了一些新的link，那么其对应的embedding也会变化，而且也很方便地学到。 算法概述 KKK:K是网络的层数，也代表着每个顶点能够聚合的邻接点的跳数，如K=2的时候每个顶点可以最多根据其2跳邻接点的信息学习其自身的embedding表示。每增加一层可以聚合更远节点的信息 N(v)N_{(v)}N(v)​:GraphSAGE中每一层的节点邻居都是是从上一层网络采样的，并不是所有邻居参与，并且采样的后的邻居的size是固定的 其运行流程如上图所示，可以分为三个步骤： 对图中每个顶点邻居顶点进行采样，因为每个节点的度是不一致的，为了计算高效， 为每个节点采样固定数量的邻居 根据聚合函数聚合邻居顶点蕴含的信息 得到图中各顶点的向量表示供下游任务使用 Neighborhood definition - 采样邻居顶点 出于对计算效率的考虑，对每个顶点采样一定数量的邻居顶点作为待聚合信息的顶点。设需要的邻居数量，即采样数量为SSS，若顶点邻居数少于SSS,则采用有放回的抽样方法，直到采样出SSS个顶点。若顶点邻居数大于SSS，则采用无放回的抽样。(即采用有放回的重采样/负采样方法达到SSS) 当然，若不考虑计算效率，完全可以对每个顶点利用其所有的邻居顶点进行信息聚合，这样是信息无损的。 文中在较大的数据集上实验。因此，统一采样一个固定大小的邻域集，以保持每个batch的计算占用空间是固定的（即 graphSAGE并不是使用全部的相邻节点，而是做了固定size的采样）。 这样固定size的采样，每个节点和采样后的邻居的个数都相同，可以把每个节点和它们的邻居拼成一个batch送到GPU中进行批训练。 论文里说固定长度的随机游走其实就是随机选择了固定数量的邻居 聚合函数的选取## 在图中顶点的邻居是无序的，所以希望构造出的聚合函数是对称的（即也就是对它输入的各种排列，函数的输出结果不变），同时具有较高的表达能力。 聚合函数的对称性（symmetry property）确保了神经网络模型可以被训练且可以应用于任意顺序的顶点邻居特征集合上。 主要有mean embedding，LSTM,pooling 代码理解]]></content>
      <categories>
        <category>图</category>
      </categories>
      <tags>
        <tag>graghsage</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[word2vec]]></title>
    <url>%2F2020%2F03%2F06%2Fskipgram%2F</url>
    <content type="text"><![CDATA[自然语言模型的发展与引出 https://www.cnblogs.com/guoyaohua/p/9240336.html 基于频率或者预测模型：https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/ 语言模型会给一个正常的语句很高的概率 unigram:P(w1,w2...wn)=∏i=1nP(wi)P(w_{1},w_{2}...w_{n})=\prod_{i=1}^{n}P(w_{i})P(w1​,w2​...wn​)=∏i=1n​P(wi​) 然而下一个词很大程度会取决于前面序列的词，这样独立概率会让一些愚蠢的语句也可以得到很大的值，所以引出了 Bigram model:P(w1,w2...wn)=∏i=2nP(wi∣wi−1)P(w_{1},w_{2}...w_{n})=\prod_{i=2}^{n}P(w_{i}|w_{i-1})P(w1​,w2​...wn​)=∏i=2n​P(wi​∣wi−1​) 模型解析 概念 语料(corpus)是指文本所有内容，包括重复的词，词典DDD是从语料中抽取出来的不包括重复词语 one-hot这种表示方式使得每一个词映射到高维空间中都是互相正交的，也就是说one-hot向量空间中词与词之间没有任何关联关系，这显然与实际情况不符合，因为实际中词与词之间有近义、反义等多种关系。Word2vec虽然学习不到反义这种高层次语义信息，但它巧妙的运用了一种思想：“具有相同上下文的词语包含相似的语义”，使得语义相近的词在映射到欧式空间后中具有较高的余弦相似度 其实总体思想还是降维，one-hot表达维度太大了，svd矩阵分解两个低纬度矩阵。 权重矩阵 https://blog.csdn.net/itplus/article/details/37969979 以skipgram为例主要有两个权重矩阵,第一个是中心词的向量表达矩阵VVV,第二个是上下文单词的向量表达矩阵UUU,他们都是D×VD\times VD×V维的 下面总结一下计算过程: 1.首先输入中心词ωt\omega_{t}ωt​的one-hot编码(V×1V\times 1V×1) 2.接着与矩阵VVV运算得到中心词的representation vc=ωt⋅Vv_{c}=\omega_{t}\cdot Vvc​=ωt​⋅V (D×1D\times1D×1) 3.下一步就是中心词向量vcv_{c}vc​与矩阵UUU相乘（u0Tvcu_{0}^{T}v_{c}u0T​vc​,u0u_{0}u0​就是矩阵UUU的某一行，其实这个就是即某个上下文词的one-hot的表达乘以UUU得到representation,u0Tvcu_{0}^{T}v_{c}u0T​vc​这最后得到的就是V×1V\times 1V×1向量的一维) 可以听cs24n的视频讲解 4. 下面用softmax把相似性大小转变为概率 详细的一个例子：https://cloud.tencent.com/developer/article/1591734 输出层 对应一颗二叉树，词典中的词作为叶子节点，根据单词出现次数作为权值，构造huffman树，叶子节点一共∣D∣|D|∣D∣个,每一次分支都是二分类，分到左面是负类，右面是正类，详细过程,https://www.cnblogs.com/neopenx/p/4571996.html 代码 源代码 #构造一个神经网络，输入词语，输出词向量 python123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166import numpy as npimport torchfrom torch import nn, optimimport randomfrom collections import Counterimport matplotlib.pyplot as plt#训练数据#text = "I like dog i like cat i like animal dog cat animal apple cat dog like dog fish milk like dog \#cat eyes like i like apple apple i hate apple i movie book music like cat dog hate cat dog like"with open('/content/text8') as f: #colab上的路径 text = f.read()#参数设置EMBEDDING_DIM = 2 #词向量维度PRINT_EVERY = 1000 #可视化频率EPOCHS = 3 #训练的轮数BATCH_SIZE = 5 #每一批训练数据大小N_SAMPLES = 3 #负样本大小WINDOW_SIZE = 5 #周边词窗口大小FREQ = 0 #词汇出现频率DELETE_WORDS = False #是否删除部分高频词#文本预处理def preprocess(text, FREQ): text = text.lower() words = text.split() #去除低频词 word_counts = Counter(words) trimmed_words = [word for word in words if word_counts[word] &gt; FREQ] return trimmed_wordswords = preprocess(text, FREQ)#构建词典vocab = set(words)vocab2int = &#123;w: c for c, w in enumerate(vocab)&#125;int2vocab = &#123;c: w for c, w in enumerate(vocab)&#125;#将文本转化为数值int_words = [vocab2int[w] for w in words]#计算单词频次int_word_counts = Counter(int_words)total_count = len(int_words)word_freqs = &#123;w: c/total_count for w, c in int_word_counts.items()&#125;#items()方法把字典中每对key和value组成一个元组，并把这些元组放在列表中返回。#去除出现频次高的词汇if DELETE_WORDS: t = 1e-5 prob_drop = &#123;w: 1-np.sqrt(t/word_freqs[w]) for w in int_word_counts&#125; train_words = [w for w in int_words if random.random()&lt;(1-prob_drop[w])]else: train_words = int_words#单词分布word_freqs = np.array(list(word_freqs.values()))unigram_dist = word_freqs / word_freqs.sum()noise_dist = torch.from_numpy(unigram_dist ** (0.75) / np.sum(unigram_dist ** (0.75)))#获取目标词汇def get_target(words, idx, WINDOW_SIZE): target_window = np.random.randint(1, WINDOW_SIZE+1) start_point = idx-target_window if (idx-target_window)&gt;0 else 0 end_point = idx+target_window targets = set(words[start_point:idx]+words[idx+1:end_point+1]) return list(targets)#批次化数据def get_batch(words, BATCH_SIZE, WINDOW_SIZE): n_batches = len(words)//BATCH_SIZE words = words[:n_batches*BATCH_SIZE] for idx in range(0, len(words), BATCH_SIZE): batch_x, batch_y = [],[] batch = words[idx:idx+BATCH_SIZE] for i in range(len(batch)): x = batch[i] y = get_target(batch, i, WINDOW_SIZE) batch_x.extend([x]*len(y)) batch_y.extend(y) yield batch_x, batch_y#定义模型class SkipGramNeg(nn.Module): def __init__(self, n_vocab, n_embed, noise_dist): super().__init__() self.n_vocab = n_vocab self.n_embed = n_embed self.noise_dist = noise_dist #定义词向量层 self.in_embed = nn.Embedding(n_vocab, n_embed) self.out_embed = nn.Embedding(n_vocab, n_embed) #词向量层参数初始化 self.in_embed.weight.data.uniform_(-1, 1) self.out_embed.weight.data.uniform_(-1, 1) #输入词的前向过程 def forward_input(self, input_words): input_vectors = self.in_embed(input_words) return input_vectors #目标词的前向过程 def forward_output(self, output_words): output_vectors = self.out_embed(output_words) return output_vectors #负样本词的前向过程 def forward_noise(self, size, N_SAMPLES): noise_dist = self.noise_dist #从词汇分布中采样负样本 noise_words = torch.multinomial(noise_dist, size * N_SAMPLES, replacement=True) noise_vectors = self.out_embed(noise_words).view(size, N_SAMPLES, self.n_embed) return noise_vectors#定义损失函数class NegativeSamplingLoss(nn.Module): def __init__(self): super().__init__() def forward(self, input_vectors, output_vectors, noise_vectors): BATCH_SIZE, embed_size = input_vectors.shape #将输入词向量与目标词向量作维度转化处理 input_vectors = input_vectors.view(BATCH_SIZE, embed_size, 1) output_vectors = output_vectors.view(BATCH_SIZE, 1, embed_size) #目标词损失 test = torch.bmm(output_vectors, input_vectors) out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log() out_loss = out_loss.squeeze() #负样本损失 noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log() noise_loss = noise_loss.squeeze().sum(1) #综合计算两类损失 return -(out_loss + noise_loss).mean()#模型、损失函数及优化器初始化model = SkipGramNeg(len(vocab2int), EMBEDDING_DIM, noise_dist=noise_dist)criterion = NegativeSamplingLoss()optimizer = optim.Adam(model.parameters(), lr=0.003)#训练steps = 0for e in range(EPOCHS): #获取输入词以及目标词 for input_words, target_words in get_batch(train_words, BATCH_SIZE, WINDOW_SIZE): steps += 1 inputs, targets = torch.LongTensor(input_words), torch.LongTensor(target_words) #输入、输出以及负样本向量 input_vectors = model.forward_input(inputs) output_vectors = model.forward_output(targets) size, _ = input_vectors.shape noise_vectors = model.forward_noise(size, N_SAMPLES) #计算损失 loss = criterion(input_vectors, output_vectors, noise_vectors) #打印损失 if steps%PRINT_EVERY == 0: print("loss：",loss) #梯度回传 optimizer.zero_grad() loss.backward() optimizer.step()#可视化词向量for i, w in int2vocab.items() : vectors = model.state_dict()["in_embed.weight"] x,y = float(vectors[i][0]),float(vectors[i][1]) plt.scatter(x,y) plt.annotate(w, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')plt.show() 评估词向量 可视化 相似度计算（余弦） analogy类比 词向量局限性 一词多义]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>skipgram</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode_day]]></title>
    <url>%2F2020%2F03%2F02%2Fleetcode-day%2F</url>
    <content type="text"><![CDATA[3.1 3.2(链表，迭代，递归) 类似于头插法 c++1234567891011121314151617class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if(head==NULL) return NULL; ListNode* pre=NULL; ListNode* cur=head; while(cur!=NULL) &#123; ListNode* p=cur-&gt;next; cur-&gt;next= pre; pre=cur; cur=p; &#125; return pre; &#125;&#125;; 递归：关键就是理解p是反转后链表的表头 c++12345678910111213class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; if (head == NULL || head-&gt;next == NULL) return head; // 如果当前要反转的节点为 null 或者反转链表为 null // head.next 为 null，即反转链表的尾结点不存在，即反转链表不存在 ListNode *p = reverseList(head-&gt;next);// 节点 p 其实就是反转链表的头节点 head-&gt;next-&gt;next = head; head-&gt;next = NULL; return p; &#125;&#125;; 3.3(数组，双指针) c++12345678910111213141516class Solution &#123;public: void merge(vector&lt;int&gt;&amp; A, int m, vector&lt;int&gt;&amp; B, int n) &#123; int i=m-1; int j=n-1; int index=m+n-1; while(i&gt;=0&amp;&amp;j&gt;=0) &#123; if(B[j]&gt;=A[i]) A[index--]=B[j--]; else A[index--]=A[i--]; &#125; while(j &gt;= 0) A[index--] = B[j--]; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[nlp]]></title>
    <url>%2F2020%2F02%2F28%2Fnlp%2F</url>
    <content type="text"><![CDATA[RNN 如果用标准神经网络来处理序列的话，因为词向量用one hot表示会有很大的维数，这是很庞大的输入层，第一层权重矩阵就会有很多参数 RNN公式：]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[论文整理]]></title>
    <url>%2F2020%2F02%2F25%2Fpaper1%2F</url>
    <content type="text"><![CDATA[论文整理： truss： Efficient Truss Maintenance in Evolving Networks(2014) 1证明了每次插入边后，truss最多加1 2.插入边后，受影响truss的范围 Streaming and Batch Algorithms for Truss(2019) 插入一条边后对不同k值边的更新不会互相影响。 Decomposition core K-core Minimization: An Edge Manipulation Approach(2018) 因为m条里选出b个组合复杂度过高，提出了两个greedy算法，第一个就是对k-core里的每条边删除计算followers，选出b个最优解。第二个算法是对候选集和的优化，只选择k-core图中两个顶点分别为k和大于k的边。]]></content>
      <tags>
        <tag>truss</tag>
        <tag>core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新冠状病毒预测]]></title>
    <url>%2F2020%2F02%2F25%2Fvirus%2F</url>
    <content type="text"><![CDATA[闲来无事，做一个确诊人数的预测吧，希望拐点早日降临。 首先数据就是日期和总确诊人数，走势是平缓到爆发到平缓，所以用logistics函数。总治愈目前处于上升趋势，多项式拟合吧。大体思路就是自变量特征从1到总的天数，然后把数字映射到日期，制图。 附上代码 python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import numpy as npimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom scipy.optimize import curve_fitdef date_encode(date): # '01.24' -&gt; 1 * 100 + 24 = 124 d = date.split('/') return int(d[1]),int(d[2])def date_decode(date): # 124 -&gt; '01.24' return '&#123;&#125;.&#123;&#125;'.format(str(date // 100), str(date % 100))df = pd.read_csv('data.csv')#encoding='utf-8',header=None,sep = '\t'df.drop([33],inplace=True)X = np.array(df.iloc[:,0]) #日期太多显示会重叠，前十天数据很平缓故先忽略掉cur_month,cur_day=date_encode(X[0])y = np.array(df['total_confirmed'])z= np.array(df['new_recoveries'])x = np.arange(len(y))def get_date_list(cur_month,cur_day,days,prediction=7): """ 得到原始数据和预测的日期 """ month_day = [0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31] ans = [] n=days+prediction while n: if cur_day &lt;= month_day[cur_month]: d = "0" + str(cur_day) if cur_day &lt; 10 else str(cur_day) ans += [str(cur_month) + "/" + d] cur_day += 1 n=n-1 else: cur_day = 1 cur_month += 1 n=n-1 return ansans = get_date_list(cur_month,cur_day,len(y),prediction=7)def logistic_function(t, K, P0, r): r=0.27 t0 = 0 exp = np.exp(r * (t - t0)) return (K * exp * P0) / (K + (exp - 1) * P0)def f_3(x, A, B, C, D): return A*x*x*x + B*x*x + C*x + Dpopt, pcov = curve_fit(logistic_function, x, y)popt1, pcov1 = curve_fit(f_3, x, z)predict_x = list(x)+[x[-1] + i for i in range(1, 8)] #数组合并不能直接相加predict_x = np.array(predict_x)predict_y = logistic_function(predict_x, popt[0], popt[1], popt[2])predict_y = [int(i) for i in predict_y]predict_z = f_3(predict_x, popt1[0], popt1[1], popt1[2],popt1[3])predict_z = [int(i) for i in predict_z]#print(ans[-7:],predict_y[-7:])#输出新增确诊new_infected = [predict_y[i]-predict_y[i-1] for i in range(-7,0)] print(ans[-7:],new_infected)#plt.scatter(x,y,color='purple',label='real')#plt.plot(x,y,color='gray')#plt.scatter(predict_x,predict_y,marker='x',color='red',label='predicted data')#plt.xticks(predict_x,ans,rotation=90)#plt.suptitle("Logistic Fitting Curve for 2019-nCov total infected numbers", fontsize=16, fontweight="bold")#输出新增治愈new_cured = [predict_z[i]-predict_z[i-1] for i in range(-7,0)] print(ans[-7:],new_cured)plt.scatter(x,z,color='purple',label='real')plt.plot(x,z,color='gray')plt.scatter(predict_x,predict_z,marker='x',color='red',label='predicted data')plt.xticks(predict_x,ans,rotation=90)plt.suptitle("polynomial regression Fitting Curve for 2019-nCov total cured numbers", fontsize=16, fontweight="bold")plt.xlabel('date', fontsize=14)plt.ylabel('infected number', fontsize=14)plt.show() 预测走势 新增确诊人数： 新增治愈趋势： 新增治愈人数： 导出csv文件 导出文件，list作为列的方法： python123456a = ['2020/2/24', '2020/2/25', '2020/2/26', '2020/2/27', '2020/2/28', '2020/2/29', '2020/3/01']b = [307, 236, 181, 139, 106, 81, 63]c = [2818, 3019, 3229, 3447, 3673, 3909, 4153]data = &#123;'date':a,'new_confirmed':b,'new_recoveries':c&#125;dataframe = pd.DataFrame(data)dataframe.to_csv(r'D:\python\test.csv') 结果 用list导入dataframe是list[[行],[行]] python1234567list=[new_infected[i] for i in range(-7,0)]list1=[predict_z[i] for i in range(-7,0)]list.extend(list1)list=[list]column=['confirmed_day1','confirmed_day2','confirmed_day3','confirmed_day4','confirmed_day5','confirmed_day6','confirmed_day7','recovery_day1','recovery_day2','recovery_day3','recovery_day4','recovery_day5','recovery_day6','recovery_day7'] test=pd.DataFrame(columns=column,data=list,index=['total'])test.to_csv('D:/test1.csv')]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>多项式回归</tag>
        <tag>logistics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划合集]]></title>
    <url>%2F2020%2F02%2F21%2Fleetcode1326%2F</url>
    <content type="text"><![CDATA[动态规划复杂度： 状态数量* 转移的计算量 三角形最小路径和 行就是行，左斜的可以当做列。转移到dp[i][j]就有两种方式,dp[i-1][j]和dp[i-1][j-1] c++12345678910111213141516171819class Solution &#123;public: int minimumTotal(vector&lt;vector&lt;int&gt;&gt;&amp; triangle) &#123; int n=triangle.size(); int dp[n+1][n+1]; memset(dp,0x3f3f3f,sizeof(dp)); dp[1][1]=triangle[0][0]; for(int i=2;i&lt;=n;i++)&#123; for(int j=1;j&lt;=i;j++)&#123; dp[i][j]=min(dp[i-1][j-1],dp[i-1][j])+triangle[i-1][j-1]; &#125; &#125; int res=0x3f3f3f; for(int i=1;i&lt;=n;i++)&#123; res=min(res,dp[n][i]); &#125; return res; &#125;&#125;; 统计全1子矩形 数的时候首先要思路清晰，划好界限不能遗漏，我们把每个右下角为(i,j)时有多少个计算好(设为f(i,j))，然后矩阵挨个位置遍历之后求和就可以了，计算f(i,j),我们首先把要知道每一列从上到下到(i,j)有多少个连续的1，这个需要先计算出来，比较好想，简单的dp就行了，看dp那部分. 然后开始计算f(i,j)从右向左，宽度为1、2、3…分别有几种，比如图中就有12种，这个过程相当于遍历的过程记录最小值。 复杂度on3o_{n^{3}}on3​ dp[i][j]表示以第i行j列的数往上(这一列)有多少个连续的1。 c++123456789101112131415161718192021222324252627282930class Solution &#123;public: int numSubmat(vector&lt;vector&lt;int&gt;&gt;&amp; mat) &#123; int m=mat.size(); int n=mat[0].size(); int dp[m][n]; for(int i=0;i&lt;n;i++)&#123; dp[0][i]=mat[0][i]; &#125; for(int i=1;i&lt;m;i++)&#123; for(int j=0;j&lt;n;j++)&#123; if(mat[i][j]==1) dp[i][j]=1+dp[i-1][j]; else dp[i][j]=0; &#125; &#125; int res=0; for(int i=0;i&lt;m;i++)&#123; for(int j=0;j&lt;n;j++)&#123; int mi=dp[i][j]; for(int k=j;k&gt;=0;k--)&#123; mi=min(mi,dp[i][k]); res+=mi; &#125; &#125; &#125; return res; &#125;&#125;; 优化：单调栈(https://www.bilibili.com/video/BV115411Y7wV) 解码方式 首先分析几个特殊的情况，之后开始dp dp[j]对应s[0]到s[i-1]的译码总数 如果s[i]=0,前一位只能是1或2，dp[j]=dp[j-2]; 如果s[i-1]'1’或者s[i-1]‘2’&amp;&amp;s[i]&lt;=‘6’，这两种情况后两位可以合并或者分开译码s[i-1]和s[i]分开译码就是dp[j-1]，合并译码就是dp[j-2] 其他情况就是只能分开译码了 c++123456789101112131415161718192021222324252627class Solution &#123;public: int numDecodings(string s) &#123; if(s.length()==0) return 0; if(s[0]=='0')return 0; if(s.length()==1) return 1; int dp[s.size()+1]; dp[0]=dp[1]=1; for(int i=1,j=2;i&lt;s.size();i++,j++) &#123; if(s[i]=='0') &#123; if(s[i-1]=='1'||s[i-1]=='2') dp[j]=dp[j-2]; else return 0; &#125; else &#123; if(s[i-1]=='1'||s[i-1]=='2'&amp;&amp;s[i]&lt;='6') dp[j]=dp[j-1]+dp[j-2]; else dp[j]=dp[j-1]; &#125; &#125; return dp[s.size()]; &#125;&#125;; 整数拆分 给定一个正整数 n，将其拆分为至少两个正整数的和，并使这些整数的乘积最大化。 返回你可以获得的最大乘积。 python1234567891011121314class Solution &#123;public: int integerBreak(int n) &#123; vector&lt;int&gt;dp(n+1,0); dp[1]=1; for(int i=2;i&lt;=n;i++) for(int j=i-1;j&gt;=1;j--) &#123; dp[i]=max(dp[i],dp[j]*(i-j)); dp[i]=max(dp[i],j*(i-j)); &#125; return dp[n]; &#125;&#125;; 357.计算各个位数不同的数字个数 python1234567891011121314class Solution &#123;public: int countNumbersWithUniqueDigits(int n) &#123; if(n==0)return 1; //n=0时，数组长度为1，运行到dp[1]会指向空地址 vector&lt;int&gt;dp(n+1,0); dp[0]=1; dp[1]=10; for(int i=2;i&lt;=n;i++) &#123; dp[i]=dp[i-1]+(dp[i-1]-dp[i-2])*(10-(i-1)); 之前的解加上新增的i位数情况，i位数是由i-1位数加上一位数，再加的一位数只有10-(i-1)种情况。 &#125; return dp[n]; &#125;&#125;; 以n=3为例，n=2已经计算了0-99之间不重复的数字了，我们需要判断的是100-999之间不重复的数字，那也就只能用10-99之间的不重复的数去组成三位数，而不能使用0-9之间的不重复的数，因为他们也组成不了3位数。而10-99之间不重复的数等于dp[2]-dp[1]。 当i=2时，说明之前选取的数字只有1位，那么我们只要与这一位不重复即可，所以其实有9(10-1)种情况（比如1，后面可以跟0,2,3,4,5,6,7,8,9）。当i=3时，说明之前选取的数字有2位，那么我们需要与2位不重复，所以剩余的有8（10-2）种（比如12，后面可以跟0,3,4,5,6,7,8,9） 1326.灌溉花园的最少水龙头数目 c++1234567891011121314151617class Solution &#123;public: int dp[10001]; int INF= 0x3f3f3f3f; //定义为无穷大，意味着无法灌溉 int minTaps(int n, vector&lt;int&gt;&amp; ranges) &#123; memset(dp,INF,sizeof(dp)); dp[0] = 0; for(int i = 0; i &lt; ranges.size(); i++)&#123; int L = max(0,i-ranges[i]); int R = min(n,i+ranges[i]); for(int j = L; j &lt;= R; j++)&#123; dp[j] = min(dp[j],dp[L]+1); // &#125; &#125; return dp[n] == INF ? -1 : dp[n]; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alexnet]]></title>
    <url>%2F2020%2F02%2F20%2Fface%2F</url>
    <content type="text"><![CDATA[关键点 imagnet:图像数据集(大量带标签数据) GPU：高性能计算资源 LRN- 创新点 采用relu加速网络训练 采用Overlapping Pooling 提升指标 采用dropout减少过拟合(在fc层)(注意训练和测试阶段数据尺度的变化) 采用LRN提升泛化能力–不太用了(14年有paper讲)–现在采用batch nomlazation 采用随机裁剪翻转以及色彩扰动(论文里用的事pca，现在用pytorch里的colorj函数)增加数据多样性 实验结果分析 卷积核 卷积核呈现不同的频率、方向和颜色 两个gpu还分工学习 特征的相似性 相似图片的第二个全连接层输出特征向量的欧氏距离相近，可以利用Alexnet提取高级特征进行图像检索、图像聚类、图像编码 结构总结 总共8层(5卷积+3全连接层),LRN(1,2),pooling(1,2,5), 参数汇总(以第一个为例):3×(11×11×96)+963\times (11\times 11\times 96) + 963×(11×11×96)+96 代码结构 alexnet_inference.py 1.只接受4D张量(B,C,H,W)=(batch size,3,224,224) 2.弃用LRN 3.卷积核数量改变 代码 注意在安装完torch可能在vs code里还会存在&quot;ModuleNotFoundError: No module named ‘torch’&quot;，这时右键命令面板 搜索 python:select,选择带conda的解析器。 重要函数 python12torchvision.transforms.FiveCrop(size)torchvision.transforms.TenCrop(size, vertical_flip=False) transforms.FiveCrop 就是在原图片的四个角和中心各截取一幅大小为 size 的图片， 而 transforms.TenCrop 就是在 transforms.TenCrop 基础上再进行水平或者竖直翻转（Flip），默认为水平翻转。 2.top k 识别效果]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>Alexnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BFS]]></title>
    <url>%2F2020%2F02%2F13%2FBFS%2F</url>
    <content type="text"><![CDATA[994.腐烂的橘子 腐烂橘子的影响范围是周围一圈的橘子，这就是典型的BFS,类似于拓扑排序，每一轮bfs都记录一下 c++12345678910111213141516171819202122232425262728class Solution &#123;public: int orangesRotting(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int dx[]=&#123;0,0,1,-1&#125;,dy[]=&#123;-1,1,0,0&#125;;//方向数组 int m=grid.size(),n=grid[0].size(); int res=0; queue&lt;pair&lt;int,int&gt;&gt; q; //1、初始化队列：添加烂橘子 for(int i=0;i&lt;m;++i)for(int j=0;j&lt;n;++j)if(grid[i][j]==2)q.push(&#123;i,j&#125;); //2、进行bfs：将每层橘子中四个方向的好橘子感染成烂橘子，并添加到队列中 while(!q.empty())&#123; int span=q.size(); for(int i=0;i&lt;span;++i)&#123; pair&lt;int,int&gt; p=q.front();q.pop(); for(int j=0;j&lt;4;++j)&#123;//将每个烂橘子的4个方向的好橘子感染成烂橘子 int x=p.first+dx[j],y=p.second+dy[j]; if(x&gt;=0&amp;&amp;x&lt;m&amp;&amp;y&gt;=0&amp;&amp;y&lt;n&amp;&amp;grid[x][y]==1)&#123; grid[x][y]=2; q.push(&#123;x,y&#125;); &#125; &#125; &#125; if(!q.empty())res++;//感染完一圈的橘子，res+1 &#125; for(int i=0;i&lt;m;++i)for(int j=0;j&lt;n;++j)if(grid[i][j]==1)return -1; return res; &#125;&#125;; 207.课程表 这道题等价于判断图里有没有环，两种方法一个是拓扑排序，一个是DFS 拓扑排序 c++1234567891011121314151617181920212223242526272829303132class Solution &#123;public: bool canFinish(int numCourses, vector&lt;vector&lt;int&gt;&gt;&amp; prerequisites) &#123; vector&lt;int&gt; degree(numCourses, 0); // map&lt;int,int&gt;degree;for(int i=0;i&lt;numCourses;i++)degree[i]=0; map&lt;int,vector&lt;int&gt;&gt;cur; queue&lt;int&gt;q; for(int i=0;i&lt;prerequisites.size();i++)&#123; cur[prerequisites[i][1]].push_back(prerequisites[i][0]); degree[prerequisites[i][0]]++; &#125; for(int i=0;i&lt;degree.size();i++) //不是cur.size() &#123; if(degree[i]==0) q.push(i); &#125; int ans=0; while(!q.empty()) &#123; int node=q.front(); q.pop(); ans++; for(int i=0;i&lt;cur[node].size();i++) &#123; degree[cur[node][i]]--; if(degree[cur[node][i]]==0) q.push(cur[node][i]); &#125; &#125; if(ans==numCourses)return true; else return false; &#125;&#125;; 在这里我犯了一个错误，找了半天…啊我的时间都去哪了… 对于入度容器我开始设计是C++ map&lt;int,vector&lt;int&gt;&gt;cur这样没有考虑度为0的节点，首先默认节点入度都为0，然后根据图来更新入度，这种情况可以就地改进见注释，或者直接用vector初始化]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>BFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[deep_learning]]></title>
    <url>%2F2020%2F02%2F13%2Fdeep-learning%2F</url>
    <content type="text"><![CDATA[激活函数（Activation functions） 如果不使用激活函数，无论神经网络多少层都会是个线性激活函数 最基本的线性回归函数，一般用在最后一层。 除了二分类问题，不要使用sigmoid，tanh变现总是更好，但这些函数当z很大时，梯度会很小，训练会很慢，所以推荐relu函数。 ReLu函数只要zzz是正值的情况下，导数恒等于1，当是zzz负值的时候，导数恒等于0。从实际上来说，当使用的导数时，zzz=0的导数是没有定义的。但是当编程实现的时候，zzz的取值刚好等于0.00000001，这个值相当小，所以，在实践中，不需要担心这个值，zzz是等于0的时候，假设一个导数是1或者0效果都可以。这里也有另一个版本的Relu被称为Leaky Relu,这个函数通常比Relu激活函数效果要好，尽管在实际中Leaky ReLu使用的并不多. 对于sigmoid函数g(z)=11+e−xg(z)=\frac{1}{1+e^{-x}}g(z)=1+e−x1​,他的导数等于g(z)×(1−g(z))g(z)\times (1-g(z))g(z)×(1−g(z)) 对于tanh函数ex−e−xex+e−x\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}ex+e−xex−e−x​,他的导数等于1−(tanh(z))21-(tanh(z))^{2}1−(tanh(z))2 Relu函数g(z)=max(0,z)g(z)=max(0,z)g(z)=max(0,z),leaky Relu函数g(z)=max(0.01z,z)g(z)=max(0.01z,z)g(z)=max(0.01z,z) 下限为0，无上限 严格递增 sparse activation softmax也可以当作激活函数来看，用在分类问题 矩阵的维数 比如图中的神经网络，第一个隐藏层z[1]=w[1]x+b[1]z^{[1]}=w^{[1]}x+b^{[1]}z[1]=w[1]x+b[1],z[1]z^{[1]}z[1]是3×1的矩阵，xxx是2×1的矩阵，所以w[1]w^{[1]}w[1]是3×2的，总结起来就是w[L]w^{[L]}w[L]是n[L]×n[L−1]n^{[L]}\times n^{[L-1]}n[L]×n[L−1]的，对dwdwdw也是一样的，b[L]b^{[L]}b[L]就是n[L]×1n^{[L]}\times1n[L]×1的，见图片右半部分 之后可以将z[1]z^{[1]}z[1]叠加起来，m为样本数量 参数随机初始化（Random+Initialization） W[1]=np.random.rando(2,2)⋅0.01,b=np.zeros((2,1))W^{[1]}=np.random.rando(2,2) \cdot 0.01,b=np.zeros((2,1))W[1]=np.random.rando(2,2)⋅0.01,b=np.zeros((2,1)) 为什么是0.01，而不是100或者1000。我们通常倾向于初始化为很小的随机数。因为如果你用tanh或者sigmoid激活函数，或者说只在输出层有一个Sigmoid，如果WWW很大，ZZZ就会很大或者很小，因此这种情况下你很可能停在tanh/sigmoid函数的平坦的地方(见图3.8.2)，这些地方梯度很小也就意味着梯度下降会很慢，因此学习也就很慢。 正则化（Regularization） 1.为什么只正则化参数www？为什么不再加上参数bbb呢？你可以这么做，只是我习惯省略不写，因为通常是一个高维参数矢量，已经可以表达高偏差问题，可能包含有很多参数，我们不可能拟合所有参数，而bbb只是单个数字，所以www几乎涵盖所有参数，而不是bbb，如果加了参数bbb，其实也没太大影响，因为只是众多参数中的一个，所以我通常省略不计，如果你想加上这个参数，完全没问题。 2.为什么正则化会有用？当λ\lambdaλ增大，www接近于0，会减少很多隐藏单元的影响，网络会变得简单，接近于逻辑回归，zzz也会很小(z[l]=w[l]a[l−1]+b[l]z^{[l]}=w^{[l]}a^{[l-1]}+b^{[l]}z[l]=w[l]a[l−1]+b[l]),会呈线性。 3.其他正则化方法：数据扩增（比如图片翻转、裁剪、扭曲），early stop early stop无法将降低损失函数和过拟合独立处理，会很复杂，所以更倾向L2正则化，虽然要尝试很多不同的λ\lambdaλ，计算代价会很大 归一化 为什么要归一化？代价函数看起来会更对称，无论从哪个位置开始都能更直接的找到最小值，可以使用较大的步长。 padding 普通的卷积两个缺点，第一个缺点是每次做卷积操作，你的图像就会缩小，从6×6缩小到4×4，你可能做了几次之后，你的图像就会变得很小了，可能会缩小到只有1×1的大小。你可不想让你的图像在每次识别边缘或其他特征时都缩小，这就是第一个缺点。第二个缺点时，如果你注意角落边缘的像素，这个像素点只被一个输出所触碰或者使用，因为它位于这个3×3的区域的一角。但如果是在中间的像素点，就会有许多3×3的区域与之重叠。所以那些在角落或者边缘区域的像素点在输出中采用较少，意味着你丢掉了图像边缘位置的许多信息。 对于N×N/N \times N/N×N/的图像，f×ff \times ff×f的filter（通常为奇数），paddy为p，步长stride为2，最后得到的矩阵为[n+2p−fs+1]×[n+2p−fs+1][\frac{n+2p-f}{s}+1] \times [\frac{n+2p-f}{s}+1][sn+2p−f​+1]×[sn+2p−f​+1],如果这个不是整数，我们向下取整， 损失函数 argmin1T∑tL(f(x(t);θ),y(t))+λΩ(θ)argmin \frac{1}{T}\sum_{t}^{}L(f(x^{(t)};\theta ),y^{(t)})+\lambda \Omega (\theta )argminT1​∑t​L(f(x(t);θ),y(t))+λΩ(θ) 反向传播(BP)]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[knn_application]]></title>
    <url>%2F2020%2F02%2F10%2Fknn-application%2F</url>
    <content type="text"><![CDATA[python counter类: python12345&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; s = "hello pinsily"&gt;&gt;&gt; d = Counter(s)&gt;&gt;&gt; dCounter(&#123;'l': 3, 'i': 2, 'h': 1, 'e': 1, 'o': 1, ' ': 1, 'p': 1, 'n': 1, 's': 1, 'y': 1&#125;) most_common(n) 返回数量最多的前 n 个元素 python12&gt;&gt;&gt; d.most_common(3)[('l', 3), ('i', 2), ('h', 1)] 代码实现： python12345678910111213141516171819202122232425262728293031import numpy as np from math import sqrtimport matplotlib.pyplot as pltimport warningsfrom matplotlib import stylefrom collections import Counterstyle.use('fivethirtyeight')dataset = &#123;'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]&#125;new_features = [5,7]for i in dataset: for ii in dataset[i]: plt.scatter(ii[0],ii[1],s=100,color=i)def k_nearest_neighbors(data, predict, k=3): if len(data) &gt;= k: warnings.warn('K is set to a value less than total voting groups!') distances = [] for group in data: for features in data[group]: euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict)) #欧几里得距离 distances.append([euclidean_distance,group]) votes = [i[1] for i in sorted(distances)[:k]] vote_result = Counter(votes).most_common(1)[0][0] #不使用[0][0],得到的是[('r', 3)]. [0][0]得到元组中第一个元素 return vote_resultresult = k_nearest_neighbors(dataset,new_features,k=3)print(result)plt.scatter(new_features[0],new_features[1],s=50,color=result)#预测的数据用小红点表示plt.show() 运行结果： 然后用这个代码来跑下癌症预测，代码如下 python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import numpy as npimport matplotlib.pyplot as pltfrom matplotlib import styleimport warningsfrom collections import Counterimport pandas as pdimport randomdef k_nearest_neighbors(data, predict, k=3): if len(data) &gt;= k: warnings.warn('K is set to a value less than total voting groups!') distances = [] for group in data: for features in data[group]: euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict)) distances.append([euclidean_distance,group]) votes = [i[1] for i in sorted(distances)[:k]] vote_result = Counter(votes).most_common(1)[0][0] #不使用[0][0],得到的是[('r', 3)]. [0][0]得到元组中第一个元素 return vote_resultdf = pd.read_csv('breast-cancer-wisconsin.txt')df.replace('?',-99999,inplace=True)df.drop(['id'],1,inplace=True)full_data = df.astype(float).values.tolist()test_size = 0.2train_set = &#123;2:[], 4:[]&#125;#良性恶性两个labletest_set = &#123;2:[], 4:[]&#125;train_data = full_data[:-int(test_size*len(full_data))]test_data = full_data[-int(test_size*len(full_data)):] #最后20%correct = 0total = 0for i in train_data: train_set[i[-1]].append(i[:-1]) #去掉label，将属性填入for i in test_data: test_set[i[-1]].append(i[:-1])for group in test_set: for data in test_set[group]: vote = k_nearest_neighbors(train_set, data, k=5) if group == vote: correct += 1 total += 1print('Accuracy:', correct/total) 准确度很高！]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>KNN</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode113]]></title>
    <url>%2F2020%2F02%2F08%2Fdfs%2F</url>
    <content type="text"><![CDATA[LCP 07. 首先用邻接存储每个人可以传送到的人。然后可以使用深度优先搜索，找出所有可能的传递方案。枚举每一轮传递玩家的编号和被传递玩家的编号。若当前是最后一轮且信息位于k 处，则方案总数加1。 c++123456789101112131415161718192021222324class Solution &#123;public: int res=0; map&lt;int,vector&lt;int&gt;&gt;g; int numWays(int n, vector&lt;vector&lt;int&gt;&gt;&amp; relation, int k) &#123; for(int i=0;i&lt;relation.size();i++)&#123; g[relation[i][0]].push_back(relation[i][1]); &#125; dfs(0,0,k,n); return res; &#125; void dfs(int i,int count,int k,int n)&#123; if(i==n-1&amp;&amp;count==k)&#123; res++; return; &#125; if(count&gt;k)return; if(g[i].size()==0)return; for(int j=0;j&lt;g[i].size();j++)&#123; dfs(g[i][j],count+1,k,n); &#125; &#125;&#125;; 括号生成 c++1234567891011121314151617181920212223242526class Solution &#123;public: vector&lt;string&gt; generateParenthesis(int n) &#123; vector&lt;string&gt;res; string cur="("; dfs(cur,n,res,1,0); return res; &#125; void dfs(string &amp;cur,int n,vector&lt;string&gt;&amp;res,int left,int right)&#123; if(cur.size()==2*n)&#123; res.push_back(cur); return; &#125; if(left&lt;n)&#123; cur=cur+'('; dfs(cur,n,res,left+1,right); cur.pop_back(); &#125; if(right&lt;left)&#123; cur=cur+')'; dfs(cur,n,res,left,right+1); cur.pop_back(); &#125; &#125;&#125;; 面试题13. 机器人的运动范围 c++123456789101112131415161718192021222324class Solution &#123;public: int res=0; int get(int n)&#123; int sums=0; while(n!=0)&#123; sums+=n%10; n/=10; &#125; return sums; &#125; int movingCount(int m, int n, int k) &#123; vector&lt;vector&lt;int&gt;&gt; cur(m, vector&lt;int&gt;(n, 0)); dfs(0,0,m,n,k,cur); return res; &#125; void dfs(int x,int y,int m, int n, int k,vector&lt;vector&lt;int&gt; &gt;&amp;cur) &#123; if(x&gt;=m||y&gt;=n||x&lt;0||y&lt;0||cur[x][y]==1||get(x)+get(y)&gt;k)return; res++; cur[x][y]=1; dfs(x+1,y,m,n,k,cur); dfs(x,y+1,m,n,k,cur); &#125;&#125;; python123456789101112131415161718class Solution &#123;public: int diameterOfBinaryTree(TreeNode* root) &#123; int res=0; dfs(root,res); return res; &#125; int dfs(TreeNode* root,int &amp;res)&#123; if(root==NULL)return 0; else &#123; int leftdepth=dfs(root-&gt;left,res); int rightdepth=dfs(root-&gt;right,res); res= max(res,leftdepth+rightdepth); return max(leftdepth,rightdepth)+1; &#125; &#125;&#125;; 给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。 c++123456789class Solution &#123;public: bool hasPathSum(TreeNode* root, int sum) &#123; if(root==NULL)return false; sum=sum-root-&gt;val; if(root-&gt;left==NULL&amp;&amp;root-&gt;right==NULL&amp;&amp;sum==0)return true; return hasPathSum(root-&gt;left,sum)||hasPathSum(root-&gt;right,sum); &#125;&#125;; 对于113题，做一点思考，看下面两段代码： c++12345678910111213141516171819202122232425262728293031class Solution &#123; vector&lt;vector&lt;int&gt;&gt;res; vector&lt;int&gt;path;public: vector&lt;vector&lt;int&gt;&gt; pathSum(TreeNode* root, int sum) &#123; if(!root) return res; DFS(path,root,sum); return res; &#125; void DFS(vector&lt;int&gt;&amp;path,TreeNode* root, int sum) &#123; if(root==NULL) return; path.push_back(root-&gt;val); sum=sum-root-&gt;val; if(root-&gt;left==NULL&amp;&amp;root-&gt;right==NULL&amp;&amp;sum==0)res.push_back(path); else &#123; if(root-&gt;left) &#123; DFS(path,root-&gt;left,sum); path.pop_back(); &#125; if(root-&gt;right) &#123; DFS(path,root-&gt;right,sum); path.pop_back(); &#125; &#125; &#125;&#125;; c++123456789101112131415161718192021222324252627282930 class Solution &#123; vector&lt;vector&lt;int&gt;&gt;res; vector&lt;int&gt;path;public: vector&lt;vector&lt;int&gt;&gt; pathSum(TreeNode* root, int sum) &#123;//!!!!!! if(!root) return res; DFS(path,root,sum); return res; &#125; void DFS(vector&lt;int&gt;path,TreeNode* root, int sum) &#123; if(root==NULL) return; path.push_back(root-&gt;val); sum=sum-root-&gt;val; if(sum==0&amp;&amp;root-&gt;left==NULL&amp;&amp;root-&gt;right==NULL)res.push_back(path); else &#123; if(root-&gt;left) &#123; DFS(path,root-&gt;left,sum); //!!!!!! &#125; if(root-&gt;right) &#123; DFS(path,root-&gt;right,sum);//!!!!!! &#125; &#125; &#125;&#125;;![](2.png) 区别主要是，第一种每层递归函数都使用的一个容器，所以要加上引用，递归返回需要弹出之前的元素，而第二种是每次递归函数都复制一个容器。 17.电话号码的字母组合 c++12345678910111213141516171819202122232425262728class Solution &#123;public: map&lt;char,string&gt; mp=&#123;&#123;'2',"abc"&#125;,&#123;'3',"def"&#125;,&#123;'4',"ghi"&#125;,&#123;'5',"jkl"&#125;,&#123;'6',"mno"&#125;,&#123;'7',"pqrs"&#125;,&#123;'8',"tuv"&#125;,&#123;'9',"wxyz"&#125;&#125;; vector&lt;string&gt;res; void DFS(string cur,string next_word) &#123; if(next_word.size()==0) res.push_back(cur); else &#123; char digit=next_word[0]; string letters=mp[digit]; for(int i=0;i&lt;letters.size();i++) &#123; cur=cur+letters.substr(i,1); next_word=next_word.substr(1); DFS(cur,next_word); &#125; &#125; &#125; vector&lt;string&gt; letterCombinations(string digits)&#123; if(digits.size()==0) return &#123;&#125;; else DFS("",digits); return res; &#125;&#125;; 93.复原IP地址 python123456789101112131415161718192021222324252627282930313233343536class Solution &#123;public: vector&lt;string&gt; res; vector&lt;string&gt; restoreIpAddresses(string s) &#123; string temp; dfs(s,temp,0); return res; &#125; void dfs(string s,string &amp;temp,int num) &#123; if(num==4)&#123; if(s.empty())res.push_back(temp); &#125; else&#123; if(num&gt;0)temp+='.'; for(int i=1;i&lt;4&amp;&amp; i &lt;= s.length();i++)&#123; if(valid(s.substr(0,i))) &#123; temp=temp+s.substr(0,i); dfs(s.substr(i,s.length()-i),temp,num+1); temp.erase(temp.length()-i,i); &#125; &#125; temp.pop_back(); &#125; &#125; bool valid(const string&amp; s)&#123; if(s.empty() || (s[0] == '0' &amp;&amp; s.size()&gt;1) ) return false; int val = stoi(s); if(val &gt;= 0 &amp;&amp; val &lt;= 255) return true; return false; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>DFS</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pagerank]]></title>
    <url>%2F2020%2F02%2F07%2Fpagerank%2F</url>
    <content type="text"><![CDATA[The web as a graph pagerank是谷歌用来计算网页重要性的算法，我们把网页想象成节点，超链接想象成边，这就形成了一张有向图。 当然我们只考虑静态网页，不考虑防火墙拦截、无法访问这些情况。 两种有向图： 1.强连通图Strongly connected graphs：任意节点可以到达任意节点。 2.有向无环图Directed Acyclic Graph (DAG):首先没有环，u能达到v，但v不能达到u。 求strongly connected components (SCCs):对给定节点分别求入度和出度的BFS,然后对两个集合求交集 Bowtie structure of the web graph Broder et al. (1999) took a large snapshot of the web and tried to understand how the SCCs in the web graph fit together as a DAG 这张图Here the starting nodes are sorted by the number of nodes that BFS visits when starting from that node 图中蓝色节点只能访问一小部分节点，紫红色节点可以访问很多节点 通过这个我们可以得出网络中的图组成 PageRank - Ranking nodes on the graph 核心想法是吧links当作votes，一个节点的重要性是由被所指向的其他节点决定的 公式为rj=∑i→jridir_{j}= \sum _ {i \rightarrow j}\frac{r_{i}}{d_{i}}rj​=∑i→j​di​ri​​ Matrix formulation 这种计算方法需要N个式子，需要很长的时间。所以我们用邻接矩阵M来代替，M的每个列的和为1ifj→i,thenWij=1djif j \rightarrow i,then W_{^{ij}}=\frac{1}{d_{j}}ifj→i,thenWij​=dj​1​,则r=Mrr=Mrr=Mr，如下图的计算过程 之后进行不断地迭代，M(M...(M(Mr)M(M...(M(Mr)M(M...(M(Mr)直到∣r−r′∣&lt;ε|r-r^{&#x27;}|&lt; \varepsilon∣r−r′∣&lt;ε PageRank: Problems 1.dead ends:没有out-links 2.Spider traps：节点发出的边只有自环，最终会吸收所有的重要性，比如图中b会聚集所有的重要性，a会没有重要性 解决方法是random teleportation或者random jumps 当一次随机游走完成，下次网上冲浪有两种选择，有概率β\betaβ跟随link，1−β1-\beta1−β跳到其它网页,跳到其他的网页节点有相同的可能性，β\betaβ 通常设定在0.8到0.9 综合起来就是:rj=∑i→jridi+(1−β)1Nr_{j}= \sum _ {i\rightarrow j}\frac{r_{i}}{d_{i}}+(1-\beta )\frac{1}{N}rj​=∑i→j​di​ri​​+(1−β)N1​ 下面可以定义谷歌矩阵 A=β×M+(1−β)[1N]N×NA= \beta \times M+(1-\beta )[\frac{1}{N}]_ {N \times N}A=β×M+(1−β)[N1​]N×N​，r=A×rr=A \times rr=A×r 注意这个公式假设M没有dead ends。我们可以提前处理矩阵M去除dead ends或者使用概率为1的随机random teleports Computing PageRank: Sparse matrix formulation 但是这样对于节点太多的话，存储矩阵A(N×N)A(N\times N)A(N×N)需要大量的空间，我们可以这样来计算：r=βM×r+1−βNr=\beta M \times r+\frac{1-\beta }{N}r=βM×r+N1−β​ , 1−βN\frac{1-\beta }{N}N1−β​是一个向量，因为这样M是个稀疏矩阵，与向量乘机就没有那么大的计算量了 下面给出完整的算法流程]]></content>
      <categories>
        <category>图</category>
      </categories>
      <tags>
        <tag>pagerank</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gragh representation learning(图的表征学习)]]></title>
    <url>%2F2020%2F02%2F06%2Frepresentation-learning%2F</url>
    <content type="text"><![CDATA[核心思想：map each node in a network into a low-dimensional space把每个节点映射到低维空间 在学习一个网络表示的时候需要注意的几个性质： 适应性，网络表示必须能适应网络的变化。网络是一个动态的图，不断地会有新的节点和边添加进来，网络表示需要适应网络的正常演化。 属于同一个社区的节点有着类似的表示。网络中往往会出现一些特征相似的点构成的团状结构，这些节点表示成向量后必须相似。 低维。代表每个顶点的向量维数不能过高，过高会有过拟合的风险，对网络中有缺失数据的情况处理能力较差。 连续性。低维的向量应该是连续的。 Embedding Nodes node embedding的目标是在原网络的similarity近似于embedding space的相似度（内积） 1.定义一个encoder(i.e., a mapping from nodes to embeddings) 2.定义相似度函数（原始网络中的相似度） 3.优化encoder的参数，使得原始网络中u，v的相似度近似于embedding的点积 deep walk given a graph and a starting point, we select a neighbor of it at random, and move to this neighbor; then we select a neighbor of this point at random, and move to it, etc. The (random) sequence of points selected this way is a random walk on the graph. So similarity(u,v)similarity(u,v)similarity(u,v) is defined as the probability that u and v co-occur on a random walk over a network. 思想来源于语言模型，我们想要在所有训练短语中最大化概率Pr(wn∣w0,w1,....,wn−1)Pr(w_{n}|w_{0},w_{1},....,w_{n-1})Pr(wn​∣w0​,w1​,....,wn−1​)，The direct analog is to estimate the likelihood of observing vertex vi given all the previous vertices visited so far in the random walk. deep walk中算法主要包括两个部分，一个是random walk gengerator，第二个是更新程序. deep walk 论文笔记 random-walk embeddings有如下几步： 1.Estimate probability of visiting node v on a random walk starting from node u using some random walk strategy R. The simplest idea is just to run fixed-length, unbiased random walks starting from each node i.e., DeepWalk from Perozzi et al., 2013 2.Optimize embeddings to encode these random walk statistics, so the similarity between embeddings (e.g., dot product) encodes Random Walk similarity. deep walk配置 首先克隆代码到本地，进入目录CodeC:\Users\Administrator\Downloads\deepwalk-master```12. 执行```pip install -r requirements.txt 执行pythonsetup.py install```14. 执行```deepwalk --input example_graphs/karate.adjlist --output karate.embeddings embedding结果： 代码的解读：https://blog.csdn.net/github_36326955/article/details/82702379 Random walk optimization and Negative Sampling 待更新 Node2vec 考虑灵活变长的random walk，可以权衡网络的局部和全局的结构，有两种策略BFS,DFS 定义两个参数，p为返回之前节点的概率，q来调节DFS，BFS 算法： 1.估算random walk概率 2.对于每个节点u模拟r次长度为l的random walk 3.使用随机梯度下降进行更新]]></content>
      <categories>
        <category>图</category>
      </categories>
      <tags>
        <tag>embedding</tag>
        <tag>负采样，deep walk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hashtbale]]></title>
    <url>%2F2020%2F02%2F04%2Fhashtbale%2F</url>
    <content type="text"><![CDATA[题目49 给定一个字符串数组，将字母异位词组合在一起。字母异位词指字母相同，但排列不同的字符串。 思路：哈希表，对排序后的单词作为索引。 c++12345678910111213141516class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; vector&lt;vector&lt;string&gt;&gt;res; map&lt;string,vector&lt;string&gt;&gt;cur; for(auto str:strs) &#123; string s=str; sort(s.begin(),s.end()); cur[s].push_back(str); &#125; for(auto it=cur.begin();it!=cur.end();it++) res.push_back(it-&gt;second); return res; &#125;&#125;; 题目169 给定一个大小为 n 的数组，找到其中的多数元素。多数元素是指在数组中出现次数大于 ⌊ n/2 ⌋ 的元素。 c++123456789101112131415161718public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; map&lt;int,int&gt;res; int max=0,ans=0; for(int i=0;i&lt;nums.size();i++) &#123; res[nums[i]]++; if(res[nums[i]]&gt;max) &#123; max= res[nums[i]]; ans=nums[i]; &#125; &#125; return ans; &#125;&#125;; 方法二:因为出现最多的数出现超过了一半，所以随机选一个会很大概率是他 c++123456789101112131415class Solution &#123;public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; while (true) &#123; int candidate = nums[rand() % nums.size()]; int count = 0; for (int num : nums) if (num == candidate) ++count; if (count &gt; nums.size() / 2) return candidate; &#125; return -1; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>字符串</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++编程总结(持续更新)]]></title>
    <url>%2F2020%2F02%2F03%2FC%2F</url>
    <content type="text"><![CDATA[字符串 删除末尾字符 1.str = str.substr(0, str.length() - 1); 2.str.erase(str.end() - 1); 3.str.pop_back(); 判断字符串里面是否含有某个字符串？ c++123456string a="abcdefghigklmn";string b="def";string::size_type idx;idx=a.find(b);//在a中查找b.if(idx == string::npos )//不存在。cout &lt;&lt; "not found\n"; 字符串替换 string.replace(起始index,结束index,代替字符串) c++1text.replace(i,j-i+1, dist[s]); leetcode1410 反转字符串 c++1reverse(s.begin(), s.end()) 分割字符串 python12345split(sep, num)string = "www.gziscas.com.cn" # 以'.'为分隔符print(string.split('.'))['www', 'gziscas', 'com', 'cn']#不写参数时，默认表示用 空格，\n，\t 分隔字符串 分割英文句子为单词并保存 c++12345678910vector&lt;string&gt;res; for(int i=0;i&lt;sentence.size()-1;i++)&#123; for(int j=i+1;j&lt;sentence.size();j++)&#123; if(sentence[j]==' ')&#123; res.push_back(sentence.substr(i,j-i)); i=j; break; &#125; &#125; &#125; 判断A是不是B的前缀 B.substr(0,A.size())==A substr超过也不会报错，比如A.size&gt;B.size，就会取B 字母专题 isalpha isalpha()用来判断一个字符是否为字母，如果是字符则返回非零，否则返回零。 c++12cout &lt;&lt; isalpha('a');//返回非零cout &lt;&lt; isalpha('2');//返回0 容器 vector获取值对应的索引 c++12vector&lt;int&gt;::iterator p=find(cur.begin(),cur.end(),queries[i]);auto index = std::distance(std::begin(cur), p); vector指定位置插入 c++1b.insert(b.begin(),q); 在首部插入 将一个vector s1插入到另一个vector s2 c++1s2.insert(s2.end(),s1.begin(),s1.end()) int转string algorithm头文件 string to_string (int val); 图编程 1.以u为顶点出发寻找与u，v能构成三角形的顶点w是，需要遍历u的临边，要注意过跳过v，添加if（v==w）continue 2.变量的作用域重叠，导致后来定义会覆盖掉之前的，应定义新的变量 3.入队出队寻找followers时，忘记对访问过的边做已访问标记，导致队列不会走空，进入无限循环，运行时间很久，诊断发现内存不断增加。 max_element() 和 min_element() 在头文件 #include 中，返回的是迭代器，所以输出值的话要在前面加* 例子： c++12vector&lt;int&gt;a;return *max_element(a.begin(),a.end()) VS使用 开启诊断 alt+ctrl+f2 2.找不到 #include &lt;graphics.h&gt;，下载easyx https://easyx.cn/ DFS与BFS DFS --stack–O(h)(根据树的高度)–不具最短路–恢复现场（恢复到之前的状态）–剪枝（可行性剪枝、最优性剪枝） BFS --queue–O(2h2^{h}2h)(宽度)–最短路 DFS：经典题目：排练数字、N-皇后]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.3]]></title>
    <url>%2F2020%2F02%2F03%2F2-3%2F</url>
    <content type="text"><![CDATA[题目402：给定一个以字符串表示的非负整数 num，移除这个数中的 k 位数字，使得剩下的数字最小。 测试用例 112, 思路要想使移除k个元素后的数最小，则应该移除最靠左的k个相邻逆序对，包括在一次移除后形成的新的逆序对. c++1234567891011121314151617181920class Solution &#123;public: string removeKdigits(string num, int k) &#123; string res; int n = num.size(), m = n - k; for (char c : num) &#123; while (k &amp;&amp; res.size() &amp;&amp; res.back() &gt; c) &#123; res.pop_back(); --k; &#125; res.push_back(c); &#125; res.resize(m); //去除前导0， 如10200，k = 1 while (!res.empty() &amp;&amp; res[0] == '0') &#123; res.erase(res.begin()); &#125; return res.empty() ? "0" : res; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>贪婪算法</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现regression]]></title>
    <url>%2F2020%2F02%2F01%2Fregression%2F</url>
    <content type="text"><![CDATA[两个error：bias,variance What to do with large bias? 1.Add more features as input 2.模型更复杂 What to do with large variance? 1.更多数据 2.增加正则化 梯度下降 学习率和损失函数的关系： 学习率大容易错过loss的最低点，学习率小下降慢 随着我们更新次数的增大，我们是希望我们的学习率越来越慢，因为分母是累加梯度的平方，到后面累加的比较大。因为我们认为在学习率的最初阶段，我们是距离损失函数最优解很远的，随着更新的次数的增多，我们认为越来越接近最优解，于是学习速率也随之变慢。 梯度下降理论 实际是用泰勒函数的近似 python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from statistics import meanimport numpy as npimport randomimport matplotlib.pyplot as pltfrom matplotlib import stylestyle.use('ggplot')def create_dataset(hm,variance,step=2,correlation=False): val = 1 ys = [] for i in range(hm): y = val + random.randrange(-variance,variance) ys.append(y) if correlation and correlation == 'pos': val+=step elif correlation and correlation == 'neg': val-=step xs = [i for i in range(len(ys))] return np.array(xs, dtype=np.float64),np.array(ys,dtype=np.float64)def best_fit_slope_and_intercept(xs,ys): m = (mean(xs)*mean(ys)-mean(xs*ys)) / (mean(xs)*mean(xs)-mean(xs*xs)) b= mean(ys)-m*mean(xs) return m,bdef squared_error(ys_orig,ys_line): return sum((ys_line - ys_orig) * (ys_line - ys_orig))def coefficient_of_determination(ys_orig,ys_line): y_mean_line = [mean(ys_orig) for y in ys_orig] squared_error_regr = sum((ys_line - ys_orig) * (ys_line - ys_orig)) squared_error_y_mean = sum((y_mean_line - ys_orig) * (y_mean_line - ys_orig)) print(squared_error_regr) print(squared_error_y_mean) r_squared = 1 - (squared_error_regr/squared_error_y_mean) return r_squaredxs, ys = create_dataset(40,40,2,correlation='pos')m, b = best_fit_slope_and_intercept(xs,ys)regression_line = [(m*x)+b for x in xs]r_squared = coefficient_of_determination(ys,regression_line)print(r_squared)plt.scatter(xs,ys,color='#003F72', label = 'data')plt.plot(xs, regression_line, label = 'regression line')plt.legend(loc=4)plt.show() R-square：分子是预测数据与原始数据均值之差的平方和，分母是原始数据和均值之差的平方和 R-square=0.5288792849075254]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[station]]></title>
    <url>%2F2020%2F02%2F01%2Fstation%2F</url>
    <content type="text"><![CDATA[134.加油站 解法一：On2 c++12345678910111213141516171819202122class Solution &#123;public: int canCompleteCircuit(vector&lt;int&gt;&amp; gas, vector&lt;int&gt;&amp; cost) &#123; for(int i=0;i&lt;gas.size();i++) &#123; int sum=0; int flag=0; if(cost[i]&gt;gas[i])continue; for(int j=i;;j++) &#123; if(j==gas.size())j=0; if(j==i)flag++; //起始结束，i`j两次重合 if(flag==2)return i; //第二次回到原点 sum+=gas[j]-cost[j]; if(sum&lt;0)break; &#125; &#125; return -1; &#125;&#125;; 解法二]]></content>
      <tags>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国加油！]]></title>
    <url>%2F2020%2F01%2F28%2Fchina%2F</url>
    <content type="text"><![CDATA[时代的一粒灰，落在个人头上，就是一座山。]]></content>
  </entry>
  <entry>
    <title><![CDATA[博客报错总结]]></title>
    <url>%2F2020%2F01%2F21%2Ferror%2F</url>
    <content type="text"><![CDATA[github解决端口22不能连接错误 报错内容：ssh: connect to host github.com port 22: Connection timed out 解决方法： 打开这个文件C:\Program Files\Git\etc\ssh\ssh_config 添加以下内容：Host github.com User xxxxx@email.com Hostname ssh.github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa Port 443 报错内容： 出现了npm ERR! Error: EPERM: operation not permitted, open 'C:\Users\Administrator，npm-v显示bash: npm-v: command not found， 解决方法： 输入npm install hexo-deployer-git --save。]]></content>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gragh]]></title>
    <url>%2F2020%2F01%2F21%2Fgragh%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[linear regression实战（股票预测）]]></title>
    <url>%2F2020%2F01%2F14%2Fmachine-learning%2F</url>
    <content type="text"><![CDATA[从quandl获取股票数据(Open：开盘价Close：收盘价High：最高价Low：最低价Volume：成交量),留下有用的feature python12345678import pandas as pdimport quandldf =quandl.get("WIKI/GOOGL")df =df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]df['HL_PCT'] = (df['Adj. High'] - df['Adj. Low']) / df['Adj. Close'] * 100.0df['PCT_change']=(df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]print(df.head()) Adj. Close HL_PCT PCT_change Adj. Volume Date 2004-08-19 50.322842 8.072956 0.324968 44659000.0 2004-08-20 54.322689 7.921706 7.227007 22834300.0 2004-08-23 54.869377 4.049360 -1.227880 18256100.0 2004-08-24 52.597363 7.657099 -5.726357 15247300.0 fillna() 函数：有一个inplace参数，默认为false，不会对原来dataframe中进行替换，为True时候会修改原来的 python1234567forecast_col='Adj.Close'df.fillna(value=-9999,inplace=true)forecast_out = int(math.ceil(0.01 * len(df)))#比如现在有100天的数据，去预测未来一天的x=np.array(df.drop(['lable',1]) #当你要删除某一行或者某一列时，用drop函数，它不改变原有的df中的数据，而是返回另一个dataframe来存放删除后的数据y=np..array(df['labble'])X=preprocessing.scale(X) #特征在[-1,1] Fit(): Method calculates the parameters μ and σ and saves them as internal objects. 解释：简单来说，就是求得训练集X的均值啊，方差啊，最大值啊，最小值啊这些训练集X固有的属性。可以理解为一个训练过程 Transform(): Method using these calculated parameters apply the transformation to a particular dataset. 解释：在Fit的基础上，进行标准化，降维，归一化等操作（看具体用的是哪个工具，如PCA，StandardScaler等）。 Fit_transform(): joins the fit() and transform() method for transformation of dataset. 解释：fit_transform是fit和transform的组合，既包括了训练又包含了转换。 python12345678910111213141516171819202122232425262728X_lately = X[-forecast_out:]X_lately=X[-forecast_out:]y = np.array(df['label'])print(len(X), len(y))X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)clf = svm.SVR()#kernel='poly'clf.fit(X_train, y_train)confidence = clf.score(X_test, y_test)forecast_set = clf.predict(X_lately)print(confidence,forecast_set)df['Forecast'] = np.nanlast_date = df.iloc[-1].name #iloc,loc:https://www.jianshu.com/p/f430d4f1b33flast_unix = last_date.timestamp() #转化为时间戳one_day = 86400next_unix = last_unix + one_dayfor i in forecast_set: next_date = datetime.datetime.fromtimestamp(next_unix) next_unix += 86400 df.loc[next_date]= [np.nan for _ in range(len(df.columns)-1)]+[i]df['Adj. Close'].plot()df['Forecast'].plot()plt.legend(loc=4)plt.xlabel('Date')plt.ylabel('Price')plt.show()]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>regression</tag>
        <tag>应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dp]]></title>
    <url>%2F2019%2F12%2F06%2Fdp%2F</url>
    <content type="text"><![CDATA[后无效性原则：当前啊状态只与上一个状态有关 0/1背包问题（组合问题求最优解） 一、 问题描述：有N件物品和一个容量为V的背包。第i件物品的费用（即体积，下同）是w[i]，价值是val[i]。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 二、 解题思路：用动态规划的思路，阶段就是“物品的件数”，状态就是“背包剩下的容量”，那么很显然f[i,v]f[i ,v]f[i,v] 就设为从前 i 件物品中选择放入容量为 v 的背包最大的价值。那么有两种情况： 第i个物品大于背包容量，那么无法放入，dp[i][j]=dp[i−1][j]dp[i][j]=dp[i-1][j]dp[i][j]=dp[i−1][j] 第i个物品小于等于背包容量，可以放入，则比较两种情况即放入和不放入，如果不放入i，最大价值就和 i 无关，就是 dp[i-1][j] , 如果放入第 i 个物品，价值就是 dp[i−1][j−w[i]]+val[i]dp[i-1][j-w[i]]+val[i]dp[i−1][j−w[i]]+val[i]，我们只需取最大值即可,选择最优解dp[i][j]=maxdp[i−1][j],dp[i−1][j−w[i]]+val[i]dp[i][j]=max{ dp[i-1][j],dp[i-1][j-w[i]]+val[i]}dp[i][j]=maxdp[i−1][j],dp[i−1][j−w[i]]+val[i]。 c++1234if j&lt;w[i] dp[i][j]=dp[i-1][j]else dp[i][j]=max(dp[i-1][j],dp[i-1][j-w[i]]+val[i]) 三、优化 即对二维dp表优化 动态规划的一个原则： 后无效性原则：当前的状态只与上一个状态有关,即二维dp表中只与上一行的数据有关，所以只留一行即可，每次刷新这个一维数组的值 c++12if j&gt;=w[i] dp[j]=max(dp[j],dp[j-w[i]]+val[i]) 注意要从后往前推，也即是循环从j=m到j=1,因为从前往后会覆盖数据，从后往前就可以用上轮的数据了 数位成本和为目标值的最大数字 体积：cost[i] 价值： 位数最多 字典序最大 面试题 17.16. 按摩师 最开始写的代码： c++123456789101112131415class Solution &#123;public: int massage(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0)return 0; if(nums.size()==1) return nums[0]; if(nums.size()==2) return max(nums[0],nums[1]); vector&lt;int&gt;dp(nums.size(),0); dp[0]=nums[0]; dp[1]=max(nums[0],nums[1]); for(int i =2;i&lt;nums.size();i++)&#123; dp[i]=max(dp[i-2]+nums[i],dp[i-1]); &#125; return dp[nums.size()-1]; &#125;&#125;; 这种情况没有考虑到休息两天的，比如[2,1,1,2] 300. 最长上升组序列 转移方程 dp[i]=max(dp[i],dp[j]+1)if(nums[i]&gt;nums[j]) python1234567891011121314class Solution &#123;public: int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; int n =nums.size(); if (n == 0) return 0; vector&lt;int&gt;dp(n,1); for(int i =1;i&lt;n;i++) for(int j=0;j&lt;i;j++)&#123; if(nums[i]&gt;nums[j]) dp[i]=max(dp[j]+1,dp[i]); &#125; return *max_element(dp.begin(), dp.end()); &#125;&#125;; 方法二： 维护一个 最大子序和 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 示例: 输入: [-2,1,-3,4,-1,2,1,-5,4], 输出: 6 解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。 c++123456789101112131415class Solution &#123;public: int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; int dp=0,result=nums[0]; for(int i=0;i&lt;nums.size();i++)&#123; if(dp&gt;0) dp=dp+nums[i]; else dp=nums[i]; result=max(result,dp); &#125; return result; &#125;&#125;; 2.最小路径和 给定一个包含非负整数的 m x n 网格，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。 说明：每次只能向下或者向右移动一步。 示例: 输入: [ [1,3,1], [1,5,1], [4,2,1] ] 输出: 7 解释: 因为路径 1→3→1→1→1 的总和最小。 c++1234567891011121314151617181920class Solution &#123;public: int minPathSum(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; if(grid.empty())return 0; int dp[grid.size()][grid[0].size()]; for(int i=0;i&lt;grid.size();i++)&#123; for(int j=0;j&lt;grid[0].size();j++) &#123; if(i==0&amp;&amp;j==0) dp[0][0]=grid[0][0]; else if(i==0) dp[i][j]= dp[i][j-1]+grid[i][j]; else if(j==0) dp[i][j]= dp[i-1][j]+grid[i][j]; else dp[i][j]=min(dp[i-1][j],dp[i][j-1])+grid[i][j]; &#125; &#125; return dp[grid.size()-1][grid[0].size()-1]; &#125;&#125;; 买卖股票的最佳时机 前i天的最大收益 = max{前i-1天的最大收益，第i天的价格-前i-1天中的最小价格} python123456789101112class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int res = 0; int min_val = 0x3f3f3f; //无穷大 for (int i = 0; i &lt; prices.size(); i++) &#123; min_val = min(min_val, prices[i]); res = max(res, prices[i] - min_val); &#125; return res; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node Classification]]></title>
    <url>%2F2019%2F11%2F05%2Fclassify%2F</url>
    <content type="text"><![CDATA[Node Classification 主要解决问题：给定一个网络，部分节点有标签，我们如何预测其它节点的标签。 例子：反欺诈案例，一些节点是欺诈者，一些节点是合法客户，我们怎么找到其它的欺诈者和合法客户。 补充： 图算法应用的任务有： node focused，以节点为主体，预测节点的标签等，比如上面的反欺诈的例子； edge focused，以边为主体，预测边的标签，比如推荐系统中 用户与商品是否发生关联（即用户是否购买商品），对这种关联关系是否发生进行预测； graph focused，以整个图为主题，预测图的标签等，比如化学分子的类别预测，整个化学分子是一副完整的图，其节点是不同的化学原子； 这节课主要讲节点分类的问题，也是目前图算法应用较多的领域，我们熟悉的gcn就是属于解决node focused任务的gnn的变体结构之一。 Collective Classification is an umbrella term describing how we assign labels to all nodes in the network together. We then propagate the information from these labels around the network and attempt to come up with stable assignments for each node. We are able to do these tasks because networks have special properties, specifically, correlations between nodes, that we can leverage to build our predictor. Essentially, collective classification relies on the Markov Assumption that the labely YiY_{i}Yi​ of one node depends on the labels of its neighbors, which can be mathematically written as:P(Yi∣i)=P(Yi∣Ni)P(Y_{i}|i)=P(Y_{i}|N_{i})P(Yi​∣i)=P(Yi​∣Ni​) The three main techniques that are used are Relational Classification, Iterative Classification, and Belief Classification, roughly ordered byhow advanced these methods are. Correlations in a Network Homophily Homophily generally refers to the tendency of individuals to associate and bond with similar others. Similarities, for instance in a social network, can include a variety of attributes, including age, gender, organizational affiliation, taste, and more. Influence Another example of why networks may demonstrate correlations is Influence. Under these circumstances, the links and edges formed can influence the behavior of the node itself Confounding Confounding variables can cause nodes to exhibit similar characteristics. For instance, the environment we are raised in may influence our similarity in multiple dimensions, from the language we speak, to our music tastes, to our political preferences. collective classification Whether or not a particular node X receives a particular label may depend on a variety of factors. In our context, those most commonly include: 未知样本的标签取决于： 这个未知样本O的特征； 这个未知样本O的相邻节点； 这个未知样本O的相邻节点的特征； 实际上如果仅仅考虑第一个条件就回到了我们传统的机器学习算法的范畴里了； 主要思想： 节点的标签是由其邻居的标签决定的 对于有标签的节点，就用ground-truth就好，没有标签的随机初始化，对于所有节点用随机的顺序更新直到收敛或者达到最大迭代次数 但是这种方法的问题在于： 1、无法保证一定能收敛（就是可能收敛也可能不收敛）（这里讲课的大佬给了一个经验法则，如果不收敛，但是随着时间的推移，不收敛的程度没有变大而是周期性的变动，那么这个时候我们也可以结束迭代） 2、模型仅仅使用的是节点的标签信息，但是没有用到节点的属性信息（特征）； Iterative Classification 第一种方案 relational classifiers 仅仅根据标签进行迭代，完全浪费了节点的属性信息，显然如果节点之间的属性非常相似，那么节点的标签也很可能是一样的，所以iterative classification 的思路就是同时利用节点的属性（特征矩阵）和标签； 其过程是： 为每一个节点创建一个向量形式（这里的意思应该是根据每个节点的属性得到一个特征向量） 使用分类器对得到的特征矩阵结合标签进行训练； 对于一个标签可能拥有许多的邻居，因此我们可以对其邻居的节点进行各类统计指标的计算加入特征中作为衍生特征，例如count计数、mode 求众数、proportion求占比、均值、是否存在的bool特征等； 这里详细介绍了iterative classifiers的整个过程： 首先是bootstrap phase，先使用特征矩阵来训练一个传统的机器学习模型比如svm、knn，然后预测标签，还是伪标签的思路； 然后是iteration phase，进入迭代步骤，对于每一个节点i都重复： 1. 更新特征向量ai； 2. 重新训练并且预测得到新的标签yi 一直到预测的概率整体不再变化或者变动不大或是达到了最大迭代次数； 同样，收敛也是无法保证的。 （这里补充了一点使用的知识，就是这类迭代的算法怎么去确定其停止条件，一个就是输出的值的收敛，理想状态是输出基本不发生改变，如果始终不收敛就看输出的差值的波动情况，如果是周期性在某个范围内波动而其差值不随迭代次数继续增大则可以选择输出差值较低的结果作为最终的收敛状态；另一个思路就比较简单了，设定最大迭代次数） Message Passing/Belief Propagation This equation summarizes our task: to calculate the message from i to j, we will sum over all of our states the label-label potential multiplied by our prior, multiplied by the product of all the messages sent by neighbors from the previous rounds. To initialize, we set all of our messages equal to 1. Then, we calculate our message from i to j, using the formula described above. We will repeat this for each node until we reach convergence, and then we can calculate our final assignment, i’s belief of being in state YiY_{i}Yi​ or b(Yi)b(Y_{i})b(Yi​)]]></content>
      <categories>
        <category>图</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[leetcode1]]></title>
    <url>%2F2019%2F07%2F31%2Fleetcode1%2F</url>
    <content type="text"><![CDATA[2.两数相加 给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。 如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。 您可以假设除了数字 0 之外，这两个数都不会以 0 开头。 示例： 输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) 输出：7 -&gt; 0 -&gt; 8 原因：342 + 465 = 807 c++12345678910111213141516171819202122232425class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode *answer = new ListNode(0); ListNode *curr= answer; int sum=0; int carry=0; while(l1!=NULL||l2!=NULL) &#123; int x=(l1!=NULL)?l1-&gt;val:0; int y=(l2!=NULL)?l2-&gt;val:0; sum=x+y+carry; curr-&gt;next= new ListNode(sum%10); curr=curr-&gt;next; carry=sum/10; if(l1!=NULL) l1=l1-&gt;next; if(l2!=NULL) l2=l2-&gt;next; &#125; if (carry &gt; 0) curr-&gt;next = new ListNode(carry); return answer-&gt;next; &#125;&#125;; 9.回文数 c++1234567class Solution(object): def isPalindrome(self, x): """ :type x: int :rtype: bool """ return str(x)==str(x)[::-1] 11盛水最多的容器 c++12345678910111213141516class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int i=0,j=height.size()-1; int result=0; while(i&lt;j) &#123; result=max(result,(j-i)*min(height[i],height[j])); if(height[i]&gt;=height[j]) j--; else i++; &#125; return result; &#125;&#125;; 14.最长公共前缀 方法一： c++12345678910111213141516171819class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; if (strs.size()==0) return ""; string str; for (int i=0;i&lt;strs[0].size();i++)&#123; for(int k=0;k&lt;strs.size()-1;k++) &#123; if (strs[k][i]!=strs[k+1][i]) &#123; return str; &#125; &#125; str=str+strs[0][i]; &#125; return str; &#125;&#125;; 方法二： c++123class Solution: def longestCommonPrefix(self, strs: List[str]) -&gt; str: return os.path.commonprefix(strs) 方法三： c++123456789class Solution: def longestCommonPrefix(self, strs): if not strs: return "" s1 = min(strs) s2 = max(strs) for i,x in enumerate(s1): if x != s2[i]: return s2[:i] return s1 14.三数之和 c++123456789101112131415161718192021222324class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; int target; vector&lt;vector&lt;int&gt;&gt; ans; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size(); i++) &#123; if ((target = nums[i]) &gt; 0) break; if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; int l = i + 1, r = nums.size() - 1; while (l &lt; r) &#123; if (nums[l] + nums[r] + target &lt; 0) ++l; else if (nums[l] + nums[r] + target &gt; 0) --r; else &#123; ans.push_back(&#123;target, nums[l], nums[r]&#125;); ++l, --r; while (l &lt; r &amp;&amp; nums[l] == nums[l - 1]) ++l; while (l &lt; r &amp;&amp; nums[r] == nums[r + 1]) --r; &#125; &#125; &#125; return ans; &#125;&#125;; 16最近接的三数值和 c++123456789101112131415161718192021222324252627class Solution &#123; public: int threeSumClosest(vector&lt;int&gt;&amp; nums, int target) &#123; sort(nums.begin(),nums.end()); int a=nums[0]+nums[1]+nums[2]; for(int i=0;i&lt;nums.size()-2;i++) &#123; if(i&gt;0&amp;&amp;nums[i]==nums[i-1])continue; int l=i+1; int r=nums.size()-1; while(l&lt;r) &#123; int sum=nums[i]+nums[l]+nums[r]; if(abs(sum-target)&lt;abs(a-target)) a=sum; if(sum&gt;target) r--; else if(sum&lt;target) l++; else if(sum==target) return sum; &#125; &#125; return a; &#125;&#125;; 19删除链表倒数第N个节点 快慢指针，相差n c++123456789101112131415161718192021class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; ListNode*p1=head; ListNode*p2=head; while(n!=0) &#123; p1=p1-&gt;next; n--; &#125; if(p1==NULL)return head-&gt;next; while((p1-&gt;next)!=NULL) &#123; p1=p1-&gt;next; p2=p2-&gt;next; &#125; p2-&gt;next=p2-&gt;next-&gt;next; return head; &#125;&#125;; 20.有效括号 c++1234567891011121314151617181920212223242526class Solution &#123;public: bool isValid(string s) &#123; stack&lt;char&gt;a; if(s.size()%2!=0)return 0; else&#123; for(auto i:s) &#123; if(i=='['||i=='&#123;'||i=='(') a.push(i); else if(a.size()==0&amp;&amp;(i==']'||i=='&#125;'||i==')')) return 0; else if((i==']'&amp;&amp;a.top()!='[')||(i=='&#125;'&amp;&amp;a.top()!='&#123;')||(i==')'&amp;&amp;a.top()!='(')) return 0; else a.pop(); &#125; &#125; if(a.size()!=0) return 0; else return 1; &#125;&#125;; 26删除排序数组中的重复项 双指针 c++1234567891011121314class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; int i=0; for(int j=0;j&lt;nums.size();j++) if(nums[i]!=nums[j]) &#123; nums[i+1]=nums[j]; i++; &#125; return i+1; &#125;&#125;; 28实现strSTR() c++1234567891011121314class Solution &#123;public: int strStr(string haystack, string needle) &#123; if (needle.size() == 0) return 0; if (needle.size() &gt; haystack.size()) return -1; if (needle==haystack)return 0; int len=needle.size(); for(int i=0;i&lt;haystack.size()-len+1;i++) &#123; if(needle==haystack.substr(i,len))return i; &#125; return -1; &#125;&#125;; 88.合并两个有序数组 从后向前插入数。 c++1234567891011121314151617class Solution &#123;public: void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) &#123; int i=m-1; int j=n-1; int len=m+n-1; while(i&gt;=0&amp;&amp;j&gt;=0) &#123; if(nums1[i]&gt;nums2[j]) nums1[len--]=nums1[i--]; else nums1[len--]=nums2[j--]; &#125; while(j&gt;=0) nums1[len--]=nums2[j--]; &#125;&#125;; 颜色分类 方法一： c++12345678910111213141516171819202122class Solution &#123;public: void sortColors(vector&lt;int&gt;&amp; nums) &#123; int a=0,b=0,c=0; for(int i=0;i&lt;nums.size();i++) &#123; if(nums[i]==0) a++; if(nums[i]==1) b++; if(nums[i]==2) c++; &#125; int j=0; for(;j&lt;a;j++) nums[j]=0; for(;j&lt;b+a;j++) nums[j]=1; for(;j&lt;a+b+c;j++) nums[j]=2; &#125;&#125;; 方法二：荷兰国旗问题： https://en.wikipedia.org/wiki/Dutch_national_flag_problem c++1234567891011121314151617181920212223class Solution &#123;public: void sortColors(vector&lt;int&gt;&amp; nums) &#123; int p0=0,p2=nums.size()-1; int cur=0; while(cur&lt;=p2) &#123; if(nums[cur]==2) &#123; swap(nums[p2],nums[cur]); p2--; &#125; else if(nums[cur]==1) cur++; else if(nums[cur]==0) &#123; swap(nums[p0],nums[cur]); p0++,cur++; &#125; &#125; &#125;&#125;; 17.电话号码的字母组合 c++12345678910111213141516171819202122232425262728class Solution &#123;public: map&lt;char,string&gt; mp=&#123;&#123;'2',"abc"&#125;,&#123;'3',"def"&#125;,&#123;'4',"ghi"&#125;,&#123;'5',"jkl"&#125;,&#123;'6',"mno"&#125;,&#123;'7',"pqrs"&#125;,&#123;'8',"tuv"&#125;,&#123;'9',"wxyz"&#125;&#125;; vector&lt;string&gt;res; void DFS(string cur,string next_word) &#123; if(next_word.size()==0) res.push_back(cur); else &#123; char digit=next_word[0]; string letters=mp[digit]; for(int i=0;i&lt;letters.size();i++) &#123; cur=cur+letters.substr(i,1); next_word=next_word.substr(1); DFS(cur,next_word); &#125; &#125; &#125; vector&lt;string&gt; letterCombinations(string digits)&#123; if(digits.size()==0) return &#123;&#125;; else DFS("",digits); return res; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[python数据可视化]]></title>
    <url>%2F2019%2F07%2F22%2Fpython-1%2F</url>
    <content type="text"><![CDATA[数据可视化是指通过可视化表示来搜索数据，与数据挖掘仅仅相关 一、安装matplotlib 进入命令行，输入pip install matplotlib便会自动安装。 二、绘制简单曲线 #coding=gbk import matplotlib.pyplot as plt import numpy as np squares=[1,4,9,16,25] plt.plot(squares,linewidth=5) #设置标题以及坐标标签 plt.title("Square Numbers",fontsize=24) plt.xlabel("Value",fontsize=14) plt.ylabel("Square of Value",fontsize=14) #设置刻度标记的大小 plt.tick_params(axis='both',labelsize=14) plt.show() ![](/images/图形1.jpg)]]></content>
  </entry>
  <entry>
    <title><![CDATA[heart]]></title>
    <url>%2F2019%2F05%2F03%2Fheart%2F</url>
    <content type="text"><![CDATA[该文章已加密, 请输入密码查看。 f9de2626922d11a4972db23cd0441146f601e8577a1934c355d1600e0fb79a07d19aa6c9b1b0ccbde383fa6097b432f33ebbb5116571d2b77d91e554d4ce27b339161eaac67137ce327f7b86c456e804c7134c9e2f4c068abdcd37ea663dd6b94ce11669707ad73e75985c7e82a2794b403a16a9fea6a483e5267ee5567dd2847f977a80438812a98d7e752e7f5078b23b3f124372fd2d92fe1801022d17e62b1433f6f5be7433da3ccf9f469f6170dbe9b8829ed5e198bb904cc55438cc7e5947d111347d1e78b7e328f15fcdb903fc2f25693a490d1d1131272f31dd113875]]></content>
      <categories>
        <category>心里话</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[记录一下]]></title>
    <url>%2F2019%2F04%2F28%2Fwanqing%2F</url>
    <content type="text"><![CDATA[哎]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[k_means]]></title>
    <url>%2F2019%2F03%2F20%2Fk-means%2F</url>
    <content type="text"><![CDATA[简介 k-means algorithm算法是一个聚类算法，把n的对象根据他们的属性分为k个分割，k &lt; n。假设对象属性来自于空间向量，并且目标是使各个群组内部的均方误差总和最小。通过迭代的方式将样本分到K个簇。 基本方法 选取K个点做为初始聚集的簇心（也可选择非样本点）; 分别计算每个样本点到 K个簇核心的距离（这里的距离一般取欧氏距离或余弦距离），找到离该点最近的簇核心，将它归属到对应的簇； 所有点都归属到簇之后， M个点就分为了 K个簇。之后重新计算每个簇的重心（平均距离中心），将其定为新的“簇核心”； 反复迭代 2 - 3 步骤，直到达到某个中止条件 sklearn实现 python1234567891011121314151617181920212223242526import matplotlib.pyplot as pltfrom sklearn.datasets import make_blobsfrom sklearn.cluster import KMeans#产生数据k=4X,Y = make_blobs(n_samples=100, n_features=2, centers=k)#构建模型km = KMeans(n_clusters=k, init='k-means++', max_iter=300)km.fit(X)# 获取簇心centroids = km.cluster_centers_# 获取归集后的样本所属簇对应值y_kmean = km.predict(X)print(y_kmean)# 呈现未归集前的数据plt.scatter(X[:, 0], X[:, 1], s=50)plt.yticks(())plt.show()plt.scatter(X[:, 0], X[:, 1], c=y_kmean, s=50, cmap='viridis')plt.scatter(centroids[:, 0], centroids[:, 1], c='black', s=100, alpha=0.5)plt.show() 手工实现 python12345678910111213141516171819202122232425262728293031323334353637383940414243444546import numpy as npfrom sklearn.datasets import make_blobsfrom math import sqrtimport randomimport matplotlib.pyplot as pltfrom scipy import spatial#产生数据k=4X,Y = make_blobs(n_samples=100, n_features=2, centers=k)def calcuDistance(vec1, vec2): # 步骤1：定义欧式距离的公式 # 计算两个向量之间的欧式距离：根号下[(x_1-x_2)^2+(y_1-y_2)^2+...+(x_n-y_n)^2] # ver1 - ver2：表示两个向量的对应元素相减 return np.sqrt(np.sum(np.square(vec1 - vec2))) #注意这里的减号def k_means(data,k,Y): m, n = data.shape # m：样本数量，n：每个样本的属性值个数 cores = data[np.random.choice(np.arange(m), k, replace=False)] # 从m个数据样本中不重复地随机选择k个样本作为质心 print(cores) while True: # 迭代计算 #d = np.square(np.repeat(data, k, axis=0).reshape(m, k, n) - cores) #distance = np.sqrt(np.sum(d, axis=2)) # ndarray(m, k)，每个样本距离k个质心的距离，共有m行 distance = spatial.distance.cdist(data, cores,metric='euclidean') index_min = np.argmin(distance, axis=1) # 每个样本距离最近的质心索引序号 if (index_min == Y).all(): # 如果样本聚类没有改变 return Y, cores # 则返回聚类结果和质心数据 Y[:] = index_min # 重新分类 for i in range(k): # 遍历质心集 items = Y==i # 找出对应当前质心的子样本集 ，对应的items为[True,false......] cores[i] = np.mean(data[items], axis=0) # 以子样本集的均值作为当前质心的位置 result,cores=k_means(X,k,Y)plt.scatter(X[:, 0], X[:, 1], s=50)plt.yticks(())plt.show()print(Y)plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap='viridis')plt.scatter(cores[:, 0], cores[:, 1], c='black', s=100, alpha=0.5)plt.show() k-means的改进 k-means改进的一个路线就是尽可能加快收敛速度，这个方向有几个思路： 1.质心初始化：选择初始质心之间有一些策略比如尽量远离，有助于反应数据的分布，加快收敛。 2.改进k-means的迭代过程，有几个方向，一个改进复杂度，比如数据的访问用KD树来索引，一个是改进目标函数（原始目标函数就是使同一类的离质心距离最小），有一个思路是时刻更新质心，比如移动一个样本到最近的类别，就立刻更新相应的两个类质心，这样改变了每轮都要对所有样本更新label的繁琐过程。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>K-means</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2013年浙江大学复试机试模拟题]]></title>
    <url>%2F2019%2F03%2F15%2Foj%2F</url>
    <content type="text"><![CDATA[题目描述 Xiao Ming’s parents visit ZJU and Xiao Ming want to take them to look around the campus.They will start from the stone with two famous question raised by President Zhu Kezhen and end at largest dining room in Asia.They want to visit every place exactly once in ZJU’s campus,including the stone and dining room. 输入 The input consists of multiple test cases. The first line contains an integer n(n&lt;=20),which means the number of place in ZJU’s campus.We give numbers(from 1 to n ) to the places,especailly,1 means the stone with two famous question and n means the largest dining room. The second line contains an integer m,which means the number of roads between two place. Then follows m lines,each line contain two integer,which means there is a road between these two place.The road will not repeat more than one time. 输出 For each test case, you should output one line.If the path exists,you should output 1.Otherwise,you should output 0. 样例输入 5 4 1 2 1 3 1 4 2 5 6 6 1 3 3 2 1 2 3 4 4 5 5 6 样例输出 0 1 来源 2013年浙江大学复试机试模拟题 #include&lt;stdio.h&gt; #include&lt;string.h&gt; int n,m,ok; int vis[22],Map[22][22]; //搜索，已经访问count个地方现在处于location点 void DFS(int location,int count) { int i; //已经全部访问完 if(count == n){ //到达目的地n if(location == n){ ok = 1; } return; } //没有访问完，访问下一处 for(i = 1;i &lt;= n;i++){ //i点没访问过且能访问则去i点 if(Map[location][i] == 1&amp;&amp; vis[i] == 0){ //标记i已经访问过 vis[i]=1; //递归下一处 DFS(i,count+1); if(ok == 1){ return; } //取消标记 vis[i] = 0; } } } //初始化 void Init() { int i,j,start,end; //初始化地图 for(i = 1;i &lt;= n;i++){ for(j = 1;j &lt;= n;j++){ Map[i][j]=0; } } //添加路况 for(i = 0;i &lt; m;i++){ scanf(&quot;%d %d&quot;,&amp;start,&amp;end); //end和start之间联通 Map[start][end]=1; Map[end][start]=1; } memset(vis,0,sizeof(vis)); ok = 0; //1为出发点 vis[1]=1; } int main() { while(scanf(&quot;%d %d&quot;,&amp;n,&amp;m)!=EOF){ Init(); DFS(1,1); printf(&quot;%d\n&quot;,ok); } return 0; }]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
  </entry>
</search>
