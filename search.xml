<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[leetcode113]]></title>
    <url>%2F2020%2F02%2F08%2Fleetcode113%2F</url>
    <content type="text"><![CDATA[112.给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。c++123456789class Solution &#123;public: bool hasPathSum(TreeNode* root, int sum) &#123; if(root==NULL)return false; sum=sum-root-&gt;val; if(root-&gt;left==NULL&amp;&amp;root-&gt;right==NULL&amp;&amp;sum==0)return true; return hasPathSum(root-&gt;left,sum)||hasPathSum(root-&gt;right,sum); &#125;&#125;; 对于113题，做一点思考，看下面两段代码：c++12345678910111213141516171819202122232425262728293031class Solution &#123; vector&lt;vector&lt;int&gt;&gt;res; vector&lt;int&gt;path;public: vector&lt;vector&lt;int&gt;&gt; pathSum(TreeNode* root, int sum) &#123; if(!root) return res; DFS(path,root,sum); return res; &#125; void DFS(vector&lt;int&gt;&amp;path,TreeNode* root, int sum) &#123; if(root==NULL) return; path.push_back(root-&gt;val); sum=sum-root-&gt;val; if(root-&gt;left==NULL&amp;&amp;root-&gt;right==NULL&amp;&amp;sum==0)res.push_back(path); else &#123; if(root-&gt;left) &#123; DFS(path,root-&gt;left,sum); path.pop_back(); &#125; if(root-&gt;right) &#123; DFS(path,root-&gt;right,sum); path.pop_back(); &#125; &#125; &#125;&#125;; c++123456789101112131415161718192021222324252627282930 class Solution &#123; vector&lt;vector&lt;int&gt;&gt;res; vector&lt;int&gt;path;public: vector&lt;vector&lt;int&gt;&gt; pathSum(TreeNode* root, int sum) &#123;//!!!!!! if(!root) return res; DFS(path,root,sum); return res; &#125; void DFS(vector&lt;int&gt;path,TreeNode* root, int sum) &#123; if(root==NULL) return; path.push_back(root-&gt;val); sum=sum-root-&gt;val; if(sum==0&amp;&amp;root-&gt;left==NULL&amp;&amp;root-&gt;right==NULL)res.push_back(path); else &#123; if(root-&gt;left) &#123; DFS(path,root-&gt;left,sum); //!!!!!! &#125; if(root-&gt;right) &#123; DFS(path,root-&gt;right,sum);//!!!!!! &#125; &#125; &#125;&#125;;![](2.png) 区别主要是，第一种每层递归函数都使用的一个容器，所以要加上引用，递归返回需要弹出之前的元素，而第二种是每次递归函数都复制一个容器。]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>DFS</tag>
        <tag>树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pagerank]]></title>
    <url>%2F2020%2F02%2F07%2Fpagerank%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[gragh representation learning(图的表征学习)]]></title>
    <url>%2F2020%2F02%2F06%2Frepresentation-learning%2F</url>
    <content type="text"><![CDATA[核心思想：map each node in a network into a low-dimensional space把每个节点映射到低维空间在学习一个网络表示的时候需要注意的几个性质：1.适应性，网络表示必须能适应网络的变化。网络是一个动态的图，不断地会有新的节点和边添加进来，网络表示需要适应网络的正常演化。2.属于同一个社区的节点有着类似的表示。网络中往往会出现一些特征相似的点构成的团状结构，这些节点表示成向量后必须相似。3.低维。代表每个顶点的向量维数不能过高，过高会有过拟合的风险，对网络中有缺失数据的情况处理能力较差。4.连续性。低维的向量应该是连续的。 Embedding Nodesnode embedding的目标是在原网络的similarity近似于embedding space的相似度（内积）1.定义一个encoder(i.e., a mapping from nodes to embeddings)2.定义相似度函数（原始网络中的相似度）3.优化encoder的参数，使得原始网络中u，v的相似度近似于embedding的点积 deep walkgiven a graph and a starting point, we select a neighbor of it at random, and move to this neighbor; then we select a neighbor of this point at random, and move to it, etc. The (random) sequence of points selected this way is a random walk on the graph. So $similarity(u,v)$ is defined as the probability thatu and v co-occur on a random walk over a network. 思想来源于语言模型，我们想要在所有训练短语中最大化概率$Pr(w_{n}|w_{0},w_{1},….,w_{n-1})$，The direct analog is to estimate the likelihood of observing vertex vi given all the previous vertices visited so far in the random walk.deep walk中算法主要包括两个部分，一个是random walk gengerator，第二个是更新程序.deep walk 论文笔记 random-walk embeddings有如下几步：1.Estimate probability of visiting node v on a random walk starting from node u using some random walk strategy R. The simplest idea is just to run fixed-length, unbiased random walks starting from each node i.e., DeepWalk from Perozzi et al., 20132.Optimize embeddings to encode these random walk statistics, so the similarity between embeddings (e.g., dot product) encodes Random Walk similarity. Random walk optimization and Negative Sampling待更新 Node2vec考虑灵活变长的random walk，可以权衡网络的局部和全局的结构，有两种策略BFS,DFS定义两个参数，p为返回之前节点的概率，q来调节DFS，BFS算法：1.估算random walk概率2.对于每个节点u模拟r次长度为l的random walk3.使用随机梯度下降进行更新]]></content>
      <categories>
        <category>图</category>
      </categories>
      <tags>
        <tag>embedding</tag>
        <tag>负采样</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hashtbale]]></title>
    <url>%2F2020%2F02%2F04%2Fhashtbale%2F</url>
    <content type="text"><![CDATA[题目49给定一个字符串数组，将字母异位词组合在一起。字母异位词指字母相同，但排列不同的字符串。 思路：哈希表，对排序后的单词作为索引。c++12345678910111213141516class Solution &#123;public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) &#123; vector&lt;vector&lt;string&gt;&gt;res; map&lt;string,vector&lt;string&gt;&gt;cur; for(auto str:strs) &#123; string s=str; sort(s.begin(),s.end()); cur[s].push_back(str); &#125; for(auto it=cur.begin();it!=cur.end();it++) res.push_back(it-&gt;second); return res; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>字符串</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++编程总结(持续更新)]]></title>
    <url>%2F2020%2F02%2F03%2FC%2F</url>
    <content type="text"><![CDATA[字符串删除末尾字符1.str = str.substr(0, str.length() - 1);2.str.erase(str.end() - 1);3.str.pop_back(); 图编程1.以u为顶点出发寻找与u，v能构成三角形的顶点w是，需要遍历u的临边，要注意过跳过v，添加if（v==w）continue2.变量的作用域重叠，导致后来定义会覆盖掉之前的，应定义新的变量3.入队出队寻找followers时，忘记对访问过的边做已访问标记，导致队列不会走空，进入无限循环，运行时间很久，诊断发现内存不断增加。]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.3]]></title>
    <url>%2F2020%2F02%2F03%2F2-3%2F</url>
    <content type="text"><![CDATA[题目402：给定一个以字符串表示的非负整数 num，移除这个数中的 k 位数字，使得剩下的数字最小。测试用例 112,思路要想使移除k个元素后的数最小，则应该移除最靠左的k个相邻逆序对，包括在一次移除后形成的新的逆序对. c++1234567891011121314151617181920class Solution &#123;public: string removeKdigits(string num, int k) &#123; string res; int n = num.size(), m = n - k; for (char c : num) &#123; while (k &amp;&amp; res.size() &amp;&amp; res.back() &gt; c) &#123; res.pop_back(); --k; &#125; res.push_back(c); &#125; res.resize(m); //去除前导0， 如10200，k = 1 while (!res.empty() &amp;&amp; res[0] == '0') &#123; res.erase(res.begin()); &#125; return res.empty() ? "0" : res; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>贪婪算法</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[knn应用（癌症判断）]]></title>
    <url>%2F2020%2F02%2F03%2Fknn%2F</url>
    <content type="text"><![CDATA[癌症数据下载链接 属性信息： Sample code number: id number Clump Thickness: 1 - 10 Uniformity of Cell Size: 1 - 10 Uniformity of Cell Shape: 1 - 10 Marginal Adhesion: 1 - 10 Single Epithelial Cell Size: 1 - 10 Bare Nuclei: 1 - 10 Bland Chromatin: 1 - 10 Normal Nucleoli: 1 - 10 Mitoses: 1 - 10 Class: (2 for benign, 4 for malignant) 为数据添加label，在第一行加入id,clump_thickness,uniform_cell_size,uniform_cell_shape,marginal_adhesion,single_epi_cell_size,bare_nuclei,bland_chromation,normal_nucleoli,mitoses,class 数据样式： clumb_thickness unif_cell_size unif_cell_shape marg_adhesion single_epith_cell_size bare_nuclei bland_chrom norm_nucleoli mitoses class0 5 1 1 1 2 1 3 1 1 21 5 4 4 5 7 10 3 2 1 22 3 1 1 1 2 2 3 1 1 23 6 8 8 1 3 4 3 7 1 24 4 1 1 3 2 1 3 1 1 2 python12345678910111213141516171819202122232425262728293031import numpy as npfrom sklearn import preprocessing ,model_selection,neighborsfrom sklearn.linear_model import LinearRegressionimport pandas as pddf = pd.read_csv('breast-cancer-wisconsin.txt')#encoding='utf-8',header=None,sep = '\t'df.replace('?',-99999, inplace=True)#print([column for column in df])df.drop(['id'], 1, inplace=True) #df.drop returns a new dataframe with our chosen column(s) dropped.#df=df.iloc[:,1:]#.iloc使用全是以0开头的行号和列号，不能直接用其它索引哦。而.loc使用的实际设置的索引和列名。 这就是.loc和.iloc的区别。在实际运用中，我还发现一点区别，.iloc只能选取数据表里实际有的行和列，而.loc可以选取没有的行和列，赋值后就可以添加新行或者列。X = np.array(df.drop(['class'],1))y = np.array(df['class'])X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)#print([column for column in df])#clf = LinearRegression(n_jobs=-1)#SVM.svr() kernel='poly'clf = neighbors.KNeighborsClassifier()clf.fit(X_train,y_train)accuracy = clf.score(X_test,y_test)print(accuracy)print(df.head())#example_measures = np.array([4,2,1,1,1,2,3,2,1]) #一个sample#example_measures = example_measures.reshape(1, -1) #Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sampleexample_measures = np.array([[4,2,1,1,1,2,3,2,1],[4,2,1,1,1,2,3,2,1]])#测试用例example_measures = example_measures.reshape(len(example_measures), -1)prediction = clf.predict(example_measures)print(prediction) accuracy:0.9714285714285714预测结果：prediction[2 2]]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>KNN</tag>
        <tag>应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[knn_application]]></title>
    <url>%2F2020%2F02%2F03%2Fknn-application%2F</url>
    <content type="text"><![CDATA[python counter类:python12345&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; s = "hello pinsily"&gt;&gt;&gt; d = Counter(s)&gt;&gt;&gt; dCounter(&#123;'l': 3, 'i': 2, 'h': 1, 'e': 1, 'o': 1, ' ': 1, 'p': 1, 'n': 1, 's': 1, 'y': 1&#125;) most_common(n)返回数量最多的前 n 个元素python12&gt;&gt;&gt; d.most_common(3)[('l', 3), ('i', 2), ('h', 1)] 代码实现：python12345678910111213141516171819202122232425262728293031import numpy as np from math import sqrtimport matplotlib.pyplot as pltimport warningsfrom matplotlib import stylefrom collections import Counterstyle.use('fivethirtyeight')dataset = &#123;'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]&#125;new_features = [5,7]for i in dataset: for ii in dataset[i]: plt.scatter(ii[0],ii[1],s=100,color=i)def k_nearest_neighbors(data, predict, k=3): if len(data) &gt;= k: warnings.warn('K is set to a value less than total voting groups!') distances = [] for group in data: for features in data[group]: euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict)) #欧几里得距离 distances.append([euclidean_distance,group]) votes = [i[1] for i in sorted(distances)[:k]] vote_result = Counter(votes).most_common(1)[0][0] #不使用[0][0],得到的是[('r', 3)]. [0][0]得到元组中第一个元素 return vote_resultresult = k_nearest_neighbors(dataset,new_features,k=3)print(result)plt.scatter(new_features[0],new_features[1],s=50,color=result)#预测的数据用小红点表示plt.show() 运行结果：]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>KNN</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实现regression]]></title>
    <url>%2F2020%2F02%2F01%2Fregression%2F</url>
    <content type="text"><![CDATA[两个error：bias,varianceWhat to do with large bias?1.Add more features as input2.模型更复杂What to do with large variance?1.更多数据2.增加正则化 梯度下降学习率和损失函数的关系：学习率大容易错过loss的最低点，学习率小下降慢 随着我们更新次数的增大，我们是希望我们的学习率越来越慢，因为分母是累加梯度的平方，到后面累加的比较大。因为我们认为在学习率的最初阶段，我们是距离损失函数最优解很远的，随着更新的次数的增多，我们认为越来越接近最优解，于是学习速率也随之变慢。 梯度下降理论.pdf)实际是用泰勒函数的近似 python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253from statistics import meanimport numpy as npimport randomimport matplotlib.pyplot as pltfrom matplotlib import stylestyle.use('ggplot')def create_dataset(hm,variance,step=2,correlation=False): val = 1 ys = [] for i in range(hm): y = val + random.randrange(-variance,variance) ys.append(y) if correlation and correlation == 'pos': val+=step elif correlation and correlation == 'neg': val-=step xs = [i for i in range(len(ys))] return np.array(xs, dtype=np.float64),np.array(ys,dtype=np.float64)def best_fit_slope_and_intercept(xs,ys): m = (mean(xs)*mean(ys)-mean(xs*ys)) / (mean(xs)*mean(xs)-mean(xs*xs)) b= mean(ys)-m*mean(xs) return m,bdef squared_error(ys_orig,ys_line): return sum((ys_line - ys_orig) * (ys_line - ys_orig))def coefficient_of_determination(ys_orig,ys_line): y_mean_line = [mean(ys_orig) for y in ys_orig] squared_error_regr = sum((ys_line - ys_orig) * (ys_line - ys_orig)) squared_error_y_mean = sum((y_mean_line - ys_orig) * (y_mean_line - ys_orig)) print(squared_error_regr) print(squared_error_y_mean) r_squared = 1 - (squared_error_regr/squared_error_y_mean) return r_squaredxs, ys = create_dataset(40,40,2,correlation='pos')m, b = best_fit_slope_and_intercept(xs,ys)regression_line = [(m*x)+b for x in xs]r_squared = coefficient_of_determination(ys,regression_line)print(r_squared)plt.scatter(xs,ys,color='#003F72', label = 'data')plt.plot(xs, regression_line, label = 'regression line')plt.legend(loc=4)plt.show() R-square：分子是预测数据与原始数据均值之差的平方和，分母是原始数据和均值之差的平方和R-square=0.5288792849075254]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国加油！]]></title>
    <url>%2F2020%2F01%2F28%2Fchina%2F</url>
    <content type="text"><![CDATA[时代的一粒灰，落在个人头上，就是一座山。]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode1326]]></title>
    <url>%2F2020%2F01%2F26%2Fleetcode1326%2F</url>
    <content type="text"><![CDATA[1326.灌溉花园的最少水龙头数目 c++1234567891011121314151617class Solution &#123;public: int dp[10001]; int INF= 0x3f3f3f3f; //定义为无穷大，意味着无法灌溉 int minTaps(int n, vector&lt;int&gt;&amp; ranges) &#123; memset(dp,INF,sizeof(dp)); dp[0] = 0; for(int i = 0; i &lt; ranges.size(); i++)&#123; int L = max(0,i-ranges[i]); int R = min(n,i+ranges[i]); for(int j = L; j &lt;= R; j++)&#123; dp[j] = min(dp[j],dp[L]+1); // &#125; &#125; return dp[n] == INF ? -1 : dp[n]; &#125;&#125;;]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客报错总结]]></title>
    <url>%2F2020%2F01%2F21%2Ferror%2F</url>
    <content type="text"><![CDATA[github解决端口22不能连接错误报错内容：ssh: connect to host github.com port 22: Connection timed out 解决方法：打开这个文件C:\Program Files\Git\etc\ssh\ssh_config 添加以下内容：Host github.comUser xxxxx@email.comHostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 443 报错内容： 出现了npm ERR! Error: EPERM: operation not permitted, open ‘C:\Users\Administrator，npm-v显示bash: npm-v: command not found，解决方法： 输入npm install hexo-deployer-git –save。]]></content>
  </entry>
  <entry>
    <title><![CDATA[gragh]]></title>
    <url>%2F2020%2F01%2F21%2Fgragh%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[linear regression实战（股票预测）]]></title>
    <url>%2F2020%2F01%2F14%2Fmachine-learning%2F</url>
    <content type="text"><![CDATA[从quandl获取股票数据(Open：开盘价Close：收盘价High：最高价Low：最低价Volume：成交量),留下有用的featurepython12345678import pandas as pdimport quandldf =quandl.get("WIKI/GOOGL")df =df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]df['HL_PCT'] = (df['Adj. High'] - df['Adj. Low']) / df['Adj. Close'] * 100.0df['PCT_change']=(df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]print(df.head()) Adj. Close HL_PCT PCT_change Adj. Volume Date2004-08-19 50.322842 8.072956 0.324968 44659000.02004-08-20 54.322689 7.921706 7.227007 22834300.02004-08-23 54.869377 4.049360 -1.227880 18256100.02004-08-24 52.597363 7.657099 -5.726357 15247300.0 fillna() 函数：有一个inplace参数，默认为false，不会对原来dataframe中进行替换，为True时候会修改原来的 python1234567forecast_col='Adj.Close'df.fillna(value=-9999,inplace=true)forecast_out = int(math.ceil(0.01 * len(df)))#比如现在有100天的数据，去预测未来一天的x=np.array(df.drop(['lable',1]) #当你要删除某一行或者某一列时，用drop函数，它不改变原有的df中的数据，而是返回另一个dataframe来存放删除后的数据y=np..array(df['labble'])X=preprocessing.scale(X) #特征在[-1,1] Fit(): Method calculates the parameters μ and σ and saves them as internal objects.解释：简单来说，就是求得训练集X的均值啊，方差啊，最大值啊，最小值啊这些训练集X固有的属性。可以理解为一个训练过程 Transform(): Method using these calculated parameters apply the transformation to a particular dataset.解释：在Fit的基础上，进行标准化，降维，归一化等操作（看具体用的是哪个工具，如PCA，StandardScaler等）。 Fit_transform(): joins the fit() and transform() method for transformation of dataset.解释：fit_transform是fit和transform的组合，既包括了训练又包含了转换。 python12345678910111213141516171819202122232425262728X_lately = X[-forecast_out:]X_lately=X[-forecast_out:]y = np.array(df['label'])print(len(X), len(y))X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)clf = svm.SVR()#kernel='poly'clf.fit(X_train, y_train)confidence = clf.score(X_test, y_test)forecast_set = clf.predict(X_lately)print(confidence,forecast_set)df['Forecast'] = np.nanlast_date = df.iloc[-1].name #iloc,loc:https://www.jianshu.com/p/f430d4f1b33flast_unix = last_date.timestamp() #转化为时间戳one_day = 86400next_unix = last_unix + one_dayfor i in forecast_set: next_date = datetime.datetime.fromtimestamp(next_unix) next_unix += 86400 df.loc[next_date]= [np.nan for _ in range(len(df.columns)-1)]+[i]df['Adj. Close'].plot()df['Forecast'].plot()plt.legend(loc=4)plt.xlabel('Date')plt.ylabel('Price')plt.show()]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>应用</tag>
        <tag>regression</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dp]]></title>
    <url>%2F2019%2F12%2F06%2Fdp%2F</url>
    <content type="text"><![CDATA[1.最大子序和给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。 示例:输入: [-2,1,-3,4,-1,2,1,-5,4],输出: 6解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。c++123456789101112131415class Solution &#123;public: int maxSubArray(vector&lt;int&gt;&amp; nums) &#123; int dp=0,result=nums[0]; for(int i=0;i&lt;nums.size();i++)&#123; if(dp&gt;0) dp=dp+nums[i]; else dp=nums[i]; result=max(result,dp); &#125; return result; &#125;&#125;; 2.最小路径和给定一个包含非负整数的 m x n 网格，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。 说明：每次只能向下或者向右移动一步。 示例: 输入:[ [1,3,1], [1,5,1], [4,2,1]]输出: 7解释: 因为路径 1→3→1→1→1 的总和最小。c++1234567891011121314151617181920class Solution &#123;public: int minPathSum(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; if(grid.empty())return 0; int dp[grid.size()][grid[0].size()]; for(int i=0;i&lt;grid.size();i++)&#123; for(int j=0;j&lt;grid[0].size();j++) &#123; if(i==0&amp;&amp;j==0) dp[0][0]=grid[0][0]; else if(i==0) dp[i][j]= dp[i][j-1]+grid[i][j]; else if(j==0) dp[i][j]= dp[i-1][j]+grid[i][j]; else dp[i][j]=min(dp[i-1][j],dp[i][j-1])+grid[i][j]; &#125; &#125; return dp[grid.size()-1][grid[0].size()-1]; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[classify]]></title>
    <url>%2F2019%2F11%2F05%2Fclassify%2F</url>
    <content type="text"><![CDATA[Node ClassificationNode Classification is the process of assigning labels to nodes within a graph, given a set of existing node labels. This setting corresponds to a semi-supervised setting. While it would be nice to be able to collect the true label values of every node, oftentimes, in real world settings, it is extremely expensive to collect those labels. Consequently, we rely on random sampling to obtain these labels. Then we use that small sample of labels to develop models that generate trustworthy node label predictions for our graph. Collective Classification is an umbrella term describing how we assign labels to all nodes in the network together. We then propagate the information from these labels around the network and attempt to come up with stable assignments for each node. We are able to do these tasks because networks have special properties, specifically, correlations between nodes, that we can leverage to build our predictor. Essentially, collective classification relies on the Markov Assumption that the labely $Y_{i}$ of one node depends on the labels of its neighbors, which can be mathematically written as:$P(Y_{i}|i)=P(Y_{i}|N_{i})$ The three main techniques that are used are Relational Classification, Iterative Classification, and Belief Classification, roughly ordered byhow advanced these methods are. Correlations in a NetworkHomophilyHomophily generally refers to the tendency of individuals to associate and bond with similar others. Similarities, for instance in a social network, can include a variety of attributes, including age, gender, organizational affiliation, taste, and more. InfluenceAnother example of why networks may demonstrate correlations is Influence. Under these circumstances, the links and edges formed can influence the behavior of the node itself ConfoundingConfounding variables can cause nodes to exhibit similar characteristics. For instance, the environment we are raised in may influence our similarity in multiple dimensions, from the language we speak, to our music tastes, to our political preferences. Leveraging Network Correlations for Classification of Network DataWhether or not a particular node X receives a particular label may depend on a variety of factors. In our context, those most commonly include:X的featrue X邻居的featureX邻居的lable我们也要考虑网络的拓扑结构。Collective classification包括三个部分 A local classifier初始化节点lable -根据节点的属性和特征，不考虑拓扑结构A relational classifier is useful because it allows us to capture correlations (e.g. the homophily, influence) between nodes in the network. -This classifier predicts the label of one node based on the labels and features of its neighbors. -This classifier predicts the label of one node based on the labels and features of its neighbors. Collective inference propagates the correlations through the network. 经过多次传递，得到邻居点间的contribution -当节点和邻点之间的差异最小或者到达最大递归次数停止 -节点结构对最终预测有很大的影响 To make those predictions, we will use a Probabilistic Relational Classifier, the basic idea of which is that the class probability of $Y_{i}$ is a weighted average of the class probabilities of its neighbors. To initialize, we will use the ground-truth labels of our labeled nodes, and for the unlabeled nodes, we will initialize Y uniformly。使用随机的序列 week points:不能保证收敛，模型没有使用node feature Iterative ClassificationThis is very similar to what we did before with the relational classifier, the key difference being that we now use the feature vector and once again, convergence is not guaranteed. Message Passing/Belief PropagationThis equation summarizes our task: to calculate the message from i to j, we will sum over all of our states the label-label potential multiplied by our prior, multiplied by the product of all the messages sent by neighbors from the previous rounds. To initialize, we set all of our messages equal to 1. Then, we calculate our message from i to j, using the formula described above. We will repeat this for each node until we reach convergence, and then we can calculate our final assignment, i’s belief of being in state $Y_{i}$ or $b(Y_{i})$]]></content>
      <categories>
        <category>图</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[leetcode1]]></title>
    <url>%2F2019%2F07%2F31%2Fleetcode1%2F</url>
    <content type="text"><![CDATA[2.两数相加给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。您可以假设除了数字 0 之外，这两个数都不会以 0 开头。示例：输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)输出：7 -&gt; 0 -&gt; 8原因：342 + 465 = 807c++12345678910111213141516171819202122232425class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode *answer = new ListNode(0); ListNode *curr= answer; int sum=0; int carry=0; while(l1!=NULL||l2!=NULL) &#123; int x=(l1!=NULL)?l1-&gt;val:0; int y=(l2!=NULL)?l2-&gt;val:0; sum=x+y+carry; curr-&gt;next= new ListNode(sum%10); curr=curr-&gt;next; carry=sum/10; if(l1!=NULL) l1=l1-&gt;next; if(l2!=NULL) l2=l2-&gt;next; &#125; if (carry &gt; 0) curr-&gt;next = new ListNode(carry); return answer-&gt;next; &#125;&#125;; 9.回文数c++1234567class Solution(object): def isPalindrome(self, x): """ :type x: int :rtype: bool """ return str(x)==str(x)[::-1] 11盛水最多的容器c++12345678910111213141516class Solution &#123;public: int maxArea(vector&lt;int&gt;&amp; height) &#123; int i=0,j=height.size()-1; int result=0; while(i&lt;j) &#123; result=max(result,(j-i)*min(height[i],height[j])); if(height[i]&gt;=height[j]) j--; else i++; &#125; return result; &#125;&#125;; 14.最长公共前缀方法一：c++12345678910111213141516171819class Solution &#123;public: string longestCommonPrefix(vector&lt;string&gt;&amp; strs) &#123; if (strs.size()==0) return ""; string str; for (int i=0;i&lt;strs[0].size();i++)&#123; for(int k=0;k&lt;strs.size()-1;k++) &#123; if (strs[k][i]!=strs[k+1][i]) &#123; return str; &#125; &#125; str=str+strs[0][i]; &#125; return str; &#125;&#125;; 方法二：c++123class Solution: def longestCommonPrefix(self, strs: List[str]) -&gt; str: return os.path.commonprefix(strs) 方法三：c++123456789class Solution: def longestCommonPrefix(self, strs): if not strs: return "" s1 = min(strs) s2 = max(strs) for i,x in enumerate(s1): if x != s2[i]: return s2[:i] return s1 14.三数之和c++123456789101112131415161718192021222324class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; int target; vector&lt;vector&lt;int&gt;&gt; ans; sort(nums.begin(), nums.end()); for (int i = 0; i &lt; nums.size(); i++) &#123; if ((target = nums[i]) &gt; 0) break; if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue; int l = i + 1, r = nums.size() - 1; while (l &lt; r) &#123; if (nums[l] + nums[r] + target &lt; 0) ++l; else if (nums[l] + nums[r] + target &gt; 0) --r; else &#123; ans.push_back(&#123;target, nums[l], nums[r]&#125;); ++l, --r; while (l &lt; r &amp;&amp; nums[l] == nums[l - 1]) ++l; while (l &lt; r &amp;&amp; nums[r] == nums[r + 1]) --r; &#125; &#125; &#125; return ans; &#125;&#125;; 16最近接的三数值和c++123456789101112131415161718192021222324252627class Solution &#123; public: int threeSumClosest(vector&lt;int&gt;&amp; nums, int target) &#123; sort(nums.begin(),nums.end()); int a=nums[0]+nums[1]+nums[2]; for(int i=0;i&lt;nums.size()-2;i++) &#123; if(i&gt;0&amp;&amp;nums[i]==nums[i-1])continue; int l=i+1; int r=nums.size()-1; while(l&lt;r) &#123; int sum=nums[i]+nums[l]+nums[r]; if(abs(sum-target)&lt;abs(a-target)) a=sum; if(sum&gt;target) r--; else if(sum&lt;target) l++; else if(sum==target) return sum; &#125; &#125; return a; &#125;&#125;; 19删除链表倒数第N个节点快慢指针，相差nc++123456789101112131415161718192021class Solution &#123;public: ListNode* removeNthFromEnd(ListNode* head, int n) &#123; ListNode*p1=head; ListNode*p2=head; while(n!=0) &#123; p1=p1-&gt;next; n--; &#125; if(p1==NULL)return head-&gt;next; while((p1-&gt;next)!=NULL) &#123; p1=p1-&gt;next; p2=p2-&gt;next; &#125; p2-&gt;next=p2-&gt;next-&gt;next; return head; &#125;&#125;; 20.有效括号c++1234567891011121314151617181920212223242526class Solution &#123;public: bool isValid(string s) &#123; stack&lt;char&gt;a; if(s.size()%2!=0)return 0; else&#123; for(auto i:s) &#123; if(i=='['||i=='&#123;'||i=='(') a.push(i); else if(a.size()==0&amp;&amp;(i==']'||i=='&#125;'||i==')')) return 0; else if((i==']'&amp;&amp;a.top()!='[')||(i=='&#125;'&amp;&amp;a.top()!='&#123;')||(i==')'&amp;&amp;a.top()!='(')) return 0; else a.pop(); &#125; &#125; if(a.size()!=0) return 0; else return 1; &#125;&#125;; 26删除排序数组中的重复项双指针c++1234567891011121314class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; int i=0; for(int j=0;j&lt;nums.size();j++) if(nums[i]!=nums[j]) &#123; nums[i+1]=nums[j]; i++; &#125; return i+1; &#125;&#125;; 28实现strSTR()c++1234567891011121314class Solution &#123;public: int strStr(string haystack, string needle) &#123; if (needle.size() == 0) return 0; if (needle.size() &gt; haystack.size()) return -1; if (needle==haystack)return 0; int len=needle.size(); for(int i=0;i&lt;haystack.size()-len+1;i++) &#123; if(needle==haystack.substr(i,len))return i; &#125; return -1; &#125;&#125;; 88.合并两个有序数组从后向前插入数。c++1234567891011121314151617class Solution &#123;public: void merge(vector&lt;int&gt;&amp; nums1, int m, vector&lt;int&gt;&amp; nums2, int n) &#123; int i=m-1; int j=n-1; int len=m+n-1; while(i&gt;=0&amp;&amp;j&gt;=0) &#123; if(nums1[i]&gt;nums2[j]) nums1[len--]=nums1[i--]; else nums1[len--]=nums2[j--]; &#125; while(j&gt;=0) nums1[len--]=nums2[j--]; &#125;&#125;; 颜色分类方法一：c++12345678910111213141516171819202122class Solution &#123;public: void sortColors(vector&lt;int&gt;&amp; nums) &#123; int a=0,b=0,c=0; for(int i=0;i&lt;nums.size();i++) &#123; if(nums[i]==0) a++; if(nums[i]==1) b++; if(nums[i]==2) c++; &#125; int j=0; for(;j&lt;a;j++) nums[j]=0; for(;j&lt;b+a;j++) nums[j]=1; for(;j&lt;a+b+c;j++) nums[j]=2; &#125;&#125;; 方法二：荷兰国旗问题：https://en.wikipedia.org/wiki/Dutch_national_flag_problemc++1234567891011121314151617181920212223class Solution &#123;public: void sortColors(vector&lt;int&gt;&amp; nums) &#123; int p0=0,p2=nums.size()-1; int cur=0; while(cur&lt;=p2) &#123; if(nums[cur]==2) &#123; swap(nums[p2],nums[cur]); p2--; &#125; else if(nums[cur]==1) cur++; else if(nums[cur]==0) &#123; swap(nums[p0],nums[cur]); p0++,cur++; &#125; &#125; &#125;&#125;; 17.电话号码的字母组合c++12345678910111213141516171819202122232425262728class Solution &#123;public: map&lt;char,string&gt; mp=&#123;&#123;'2',"abc"&#125;,&#123;'3',"def"&#125;,&#123;'4',"ghi"&#125;,&#123;'5',"jkl"&#125;,&#123;'6',"mno"&#125;,&#123;'7',"pqrs"&#125;,&#123;'8',"tuv"&#125;,&#123;'9',"wxyz"&#125;&#125;; vector&lt;string&gt;res; void DFS(string cur,string next_word) &#123; if(next_word.size()==0) res.push_back(cur); else &#123; char digit=next_word[0]; string letters=mp[digit]; for(int i=0;i&lt;letters.size();i++) &#123; cur=cur+letters.substr(i,1); next_word=next_word.substr(1); DFS(cur,next_word); &#125; &#125; &#125; vector&lt;string&gt; letterCombinations(string digits)&#123; if(digits.size()==0) return &#123;&#125;; else DFS("",digits); return res; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[python数据可视化]]></title>
    <url>%2F2019%2F07%2F22%2Fpython-1%2F</url>
    <content type="text"><![CDATA[数据可视化是指通过可视化表示来搜索数据，与数据挖掘仅仅相关一、安装matplotlib进入命令行，输入pip install matplotlib便会自动安装。二、绘制简单曲线`python #coding=gbkimport matplotlib.pyplot as pltimport numpy as npsquares=[1,4,9,16,25]plt.plot(squares,linewidth=5) #设置标题以及坐标标签plt.title(“Square Numbers”,fontsize=24)plt.xlabel(“Value”,fontsize=14)plt.ylabel(“Square of Value”,fontsize=14) #设置刻度标记的大小plt.tick_params(axis=’both’,labelsize=14)plt.show()]]></content>
  </entry>
  <entry>
    <title><![CDATA[heart]]></title>
    <url>%2F2019%2F05%2F03%2Fheart%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>心里话</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[记录一下]]></title>
    <url>%2F2019%2F04%2F28%2Fwanqing%2F</url>
    <content type="text"><![CDATA[哎]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[2013年浙江大学复试机试模拟题]]></title>
    <url>%2F2019%2F03%2F15%2Foj%2F</url>
    <content type="text"><![CDATA[题目描述 Xiao Ming’s parents visit ZJU and Xiao Ming want to take them to look around the campus.They will start from the stone with two famous question raised by President Zhu Kezhen and end at largest dining room in Asia.They want to visit every place exactly once in ZJU’s campus,including the stone and dining room. 输入The input consists of multiple test cases.The first line contains an integer n(n&lt;=20),which means the number of place in ZJU’s campus.We give numbers(from 1 to n ) to the places,especailly,1 means the stone with two famous question and n means the largest dining room.The second line contains an integer m,which means the number of roads between two place.Then follows m lines,each line contain two integer,which means there is a road between these two place.The road will not repeat more than one time. 输出For each test case, you should output one line.If the path exists,you should output 1.Otherwise,you should output 0. 样例输入5 4 1 2 1 3 1 4 2 5 6 6 1 3 3 2 1 2 3 4 4 5 5 6 样例输出0 1 来源2013年浙江大学复试机试模拟题 #include&lt;stdio.h&gt; #include&lt;string.h&gt;int n,m,ok;int vis[22],Map[22][22]; //搜索，已经访问count个地方现在处于location点void DFS(int location,int count){ int i; //已经全部访问完 if(count == n){ //到达目的地n if(location == n){ ok = 1; } return; } //没有访问完，访问下一处 for(i = 1;i &lt;= n;i++){ //i点没访问过且能访问则去i点 if(Map[location][i] == 1&amp;&amp; vis[i] == 0){ //标记i已经访问过 vis[i]=1; //递归下一处 DFS(i,count+1); if(ok == 1){ return; } //取消标记 vis[i] = 0; } }}//初始化void Init(){ int i,j,start,end; //初始化地图 for(i = 1;i &lt;= n;i++){ for(j = 1;j &lt;= n;j++){ Map[i][j]=0; } } //添加路况 for(i = 0;i &lt; m;i++){ scanf(“%d %d”,&amp;start,&amp;end); //end和start之间联通 Map[start][end]=1; Map[end][start]=1; } memset(vis,0,sizeof(vis)); ok = 0; //1为出发点 vis[1]=1;}int main(){ while(scanf(“%d %d”,&amp;n,&amp;m)!=EOF){ Init(); DFS(1,1); printf(“%d\n”,ok); } return 0;}]]></content>
      <categories>
        <category>算法编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[准备复试]]></title>
    <url>%2F2019%2F02%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[复试加油，相信自己！]]></content>
      <categories>
        <category>life</category>
      </categories>
  </entry>
</search>
